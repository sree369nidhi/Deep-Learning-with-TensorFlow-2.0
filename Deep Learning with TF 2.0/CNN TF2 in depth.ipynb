{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tfguide.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-wx3SL0rJ6hR","colab_type":"code","outputId":"30b2f271-4055-4b87-a020-be4526eaf9cb","executionInfo":{"status":"ok","timestamp":1573906970615,"user_tz":-330,"elapsed":2287,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","\n","const = tf.constant('Hello')\n","\n","with tf.Session() as sess:\n","  op = sess.run(const)\n","  print(op)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["b'Hello'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eIsJsoX7Kg6m","colab_type":"code","outputId":"607d045c-7a6f-4013-9e1e-bb416f99efa5","executionInfo":{"status":"ok","timestamp":1573909223388,"user_tz":-330,"elapsed":3542,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def run():\n","    output = None\n","    logit_data = [2.0, 1.0, 0.1]\n","    logits = tf.placeholder(tf.float32)\n","    \n","    # TODO: Calculate the softmax of the logits\n","    softmax =  tf.nn.softmax(logits)  \n","    \n","    with tf.Session() as sess:\n","        # TODO: Feed in the logit data\n","        output = sess.run(softmax, feed_dict={logits: logit_data})\n","\n","    return output\n","print(run())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0.6590012 0.242433  0.0985659]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dQkE_40kTKZh","colab_type":"code","outputId":"f8e34939-98a1-4294-a76b-437dc0cc1eb8","executionInfo":{"status":"ok","timestamp":1573909341957,"user_tz":-330,"elapsed":824,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["from sklearn import preprocessing\n","import numpy as np\n","\n","# Example labels\n","labels = np.array([1,5,3,2,1,4,2,1,3])\n","\n","# Create the encoder\n","lb = preprocessing.LabelBinarizer()\n","\n","# Here the encoder finds the classes and assigns one-hot vectors \n","lb.fit(labels)\n","\n","# And finally, transform the labels into one-hot encoded vectors\n","a = lb.transform(labels)\n","a"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 0, 0, 0, 0],\n","       [0, 0, 0, 0, 1],\n","       [0, 0, 1, 0, 0],\n","       [0, 1, 0, 0, 0],\n","       [1, 0, 0, 0, 0],\n","       [0, 0, 0, 1, 0],\n","       [0, 1, 0, 0, 0],\n","       [1, 0, 0, 0, 0],\n","       [0, 0, 1, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"KqQ3BqZdTh56","colab_type":"code","outputId":"8551d6ac-2aa7-4c4b-8982-a4a0d9c59ec6","executionInfo":{"status":"ok","timestamp":1573909796366,"user_tz":-330,"elapsed":1003,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["softmax_data = [0.7, 0.2, 0.1]\n","one_hot_data = [1.0, 0.0, 0.0]\n","\n","softmax = tf.placeholder(tf.float32)\n","one_hot = tf.placeholder(tf.float32)\n","\n","cross_entropy = -tf.reduce_sum(tf.multiply(one_hot, tf.log(softmax)))\n","# TODO: Print cross entropy from session\n","with tf.Session() as sess:\n","  _ = sess.run(cross_entropy, feed_dict={softmax: softmax_data, one_hot: one_hot_data})\n","  print(_)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.35667497\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ipJzJ26fVTUe","colab_type":"code","outputId":"5121ab31-9e29-4bee-f339-e46214b028d1","executionInfo":{"status":"ok","timestamp":1573909969652,"user_tz":-330,"elapsed":991,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["a = 1000000000\n","for i in range(1000000):\n","    a = a + 1e-6\n","print(a - 1000000000)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.95367431640625\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VvvqnmXMWDZi","colab_type":"code","outputId":"db77e59a-612b-4aac-a9e1-1554591fd7fc","executionInfo":{"status":"ok","timestamp":1573910721876,"user_tz":-330,"elapsed":1836,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":530}},"source":["from tensorflow.examples.tutorials.mnist import input_data\n","import tensorflow as tf\n","\n","n_input = 784  # MNIST data input (img shape: 28*28)\n","n_classes = 10  # MNIST total classes (0-9 digits)\n","\n","# Import MNIST data\n","mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n","\n","# The features are already scaled and the data is shuffled\n","train_features = mnist.train.images\n","test_features = mnist.test.images\n","\n","train_labels = mnist.train.labels.astype(np.float32)\n","test_labels = mnist.test.labels.astype(np.float32)\n","\n","# Weights & bias\n","weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n","bias = tf.Variable(tf.random_normal([n_classes]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-11-6b6310431953>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fHQWfFZqY6zw","colab_type":"code","colab":{}},"source":["features = tf.placeholder(tf.float32, [None, n_input])\n","labels = tf.placeholder(tf.float32, [None, n_classes])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OwWwjpZQZMLQ","colab_type":"code","outputId":"358003e8-c74f-42e4-c989-7fb9b2ceea8f","executionInfo":{"status":"ok","timestamp":1573910969846,"user_tz":-330,"elapsed":982,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["def batches(batch_size, features, labels):\n","    \"\"\"\n","    Create batches of features and labels\n","    :param batch_size: The batch size\n","    :param features: List of features\n","    :param labels: List of labels\n","    :return: Batches of (Features, Labels)\n","    \"\"\"\n","    assert len(features) == len(labels)\n","    # TODO: Implement batching\n","    output_batches = []\n","    \n","    sample_size = len(features)\n","    for start_i in range(0, sample_size, batch_size):\n","        end_i = start_i + batch_size\n","        batch = [features[start_i:end_i], labels[start_i:end_i]]\n","        output_batches.append(batch)\n","        \n","    return output_batches\n","\n","from pprint import pprint\n","\n","# 4 Samples of features\n","example_features = [\n","    ['F11','F12','F13','F14'],\n","    ['F21','F22','F23','F24'],\n","    ['F31','F32','F33','F34'],\n","    ['F41','F42','F43','F44']]\n","# 4 Samples of labels\n","example_labels = [\n","    ['L11','L12'],\n","    ['L21','L22'],\n","    ['L31','L32'],\n","    ['L41','L42']]\n","\n","# PPrint prints data structures like 2d arrays, so they are easier to read\n","pprint(batches(3, example_features, example_labels))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[[['F11', 'F12', 'F13', 'F14'],\n","   ['F21', 'F22', 'F23', 'F24'],\n","   ['F31', 'F32', 'F33', 'F34']],\n","  [['L11', 'L12'], ['L21', 'L22'], ['L31', 'L32']]],\n"," [[['F41', 'F42', 'F43', 'F44']], [['L41', 'L42']]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"49To7JDtZ3kF","colab_type":"code","outputId":"6544d65a-a83f-472f-92f4-a7675d982b51","executionInfo":{"status":"ok","timestamp":1573911230553,"user_tz":-330,"elapsed":3092,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["import math\n","def batches(batch_size, features, labels):\n","    \"\"\"\n","    Create batches of features and labels\n","    :param batch_size: The batch size\n","    :param features: List of features\n","    :param labels: List of labels\n","    :return: Batches of (Features, Labels)\n","    \"\"\"\n","    assert len(features) == len(labels)\n","    outout_batches = []\n","    \n","    sample_size = len(features)\n","    for start_i in range(0, sample_size, batch_size):\n","        end_i = start_i + batch_size\n","        batch = [features[start_i:end_i], labels[start_i:end_i]]\n","        outout_batches.append(batch)\n","        \n","    return outout_batches\n","\n","from tensorflow.examples.tutorials.mnist import input_data\n","import tensorflow as tf\n","import numpy as np\n","\n","learning_rate = 0.001\n","n_input = 784  # MNIST data input (img shape: 28*28)\n","n_classes = 10  # MNIST total classes (0-9 digits)\n","\n","# Import MNIST data\n","mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n","\n","# The features are already scaled and the data is shuffled\n","train_features = mnist.train.images\n","test_features = mnist.test.images\n","\n","train_labels = mnist.train.labels.astype(np.float32)\n","test_labels = mnist.test.labels.astype(np.float32)\n","\n","# Features and Labels\n","features = tf.placeholder(tf.float32, [None, n_input])\n","labels = tf.placeholder(tf.float32, [None, n_classes])\n","\n","# Weights & bias\n","weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n","bias = tf.Variable(tf.random_normal([n_classes]))\n","\n","# Logits - xW + b\n","logits = tf.add(tf.matmul(features, weights), bias)\n","\n","# Define loss and optimizer\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n","\n","# Calculate accuracy\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","\n","# TODO: Set batch size\n","batch_size = 128\n","assert batch_size is not None, 'You must set the batch size'\n","\n","init = tf.global_variables_initializer()\n","\n","with tf.Session() as sess:\n","    sess.run(init)\n","    \n","    # TODO: Train optimizer on all batches\n","    for batch_features, batch_labels in batches(batch_size, train_features, train_labels):\n","        sess.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n","\n","    # Calculate accuracy for test dataset\n","    test_accuracy = sess.run(\n","        accuracy,\n","        feed_dict={features: test_features, labels: test_labels})\n","\n","print('Test Accuracy: {}'.format(test_accuracy))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n","Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n","Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n","Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From <ipython-input-15-078cb61fbdca>:51: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","Test Accuracy: 0.08030000329017639\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"82eXJUNPaPju","colab_type":"code","outputId":"85753839-051f-4c31-a06d-0b946cb77413","executionInfo":{"status":"ok","timestamp":1573911919406,"user_tz":-330,"elapsed":84403,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from tensorflow.examples.tutorials.mnist import input_data\n","import tensorflow as tf\n","import numpy as np\n","\n","import math\n","def batches(batch_size, features, labels):\n","    \"\"\"\n","    Create batches of features and labels\n","    :param batch_size: The batch size\n","    :param features: List of features\n","    :param labels: List of labels\n","    :return: Batches of (Features, Labels)\n","    \"\"\"\n","    assert len(features) == len(labels)\n","    outout_batches = []\n","    \n","    sample_size = len(features)\n","    for start_i in range(0, sample_size, batch_size):\n","        end_i = start_i + batch_size\n","        batch = [features[start_i:end_i], labels[start_i:end_i]]\n","        outout_batches.append(batch)\n","        \n","    return outout_batches\n","\n","\n","def print_epoch_stats(epoch_i, sess, last_features, last_labels):\n","    \"\"\"\n","    Print cost and validation accuracy of an epoch\n","    \"\"\"\n","    current_cost = sess.run(\n","        cost,\n","        feed_dict={features: last_features, labels: last_labels})\n","    valid_accuracy = sess.run(\n","        accuracy,\n","        feed_dict={features: valid_features, labels: valid_labels})\n","    print('Epoch: {:<4} - Cost: {:<8.3} Valid Accuracy: {:<5.3}'.format(\n","        epoch_i,\n","        current_cost,\n","        valid_accuracy))\n","\n","n_input = 784  # MNIST data input (img shape: 28*28)\n","n_classes = 10  # MNIST total classes (0-9 digits)\n","\n","# Import MNIST data\n","mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n","\n","# The features are already scaled and the data is shuffled\n","train_features = mnist.train.images\n","valid_features = mnist.validation.images\n","test_features = mnist.test.images\n","\n","train_labels = mnist.train.labels.astype(np.float32)\n","valid_labels = mnist.validation.labels.astype(np.float32)\n","test_labels = mnist.test.labels.astype(np.float32)\n","\n","# Features and Labels\n","features = tf.placeholder(tf.float32, [None, n_input])\n","labels = tf.placeholder(tf.float32, [None, n_classes])\n","\n","# Weights & bias\n","weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n","bias = tf.Variable(tf.random_normal([n_classes]))\n","\n","# Logits - xW + b\n","logits = tf.add(tf.matmul(features, weights), bias)\n","\n","# Define loss and optimizer\n","learning_rate = tf.placeholder(tf.float32)\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n","\n","# Calculate accuracy\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","init = tf.global_variables_initializer()\n","\n","batch_size = 128\n","epochs = 100\n","learn_rate = 0.001\n","\n","train_batches = batches(batch_size, train_features, train_labels)\n","\n","with tf.Session() as sess:\n","    sess.run(init)\n","\n","    # Training cycle\n","    for epoch_i in range(epochs):\n","\n","        # Loop over all batches\n","        for batch_features, batch_labels in train_batches:\n","            train_feed_dict = {\n","                features: batch_features,\n","                labels: batch_labels,\n","                learning_rate: learn_rate}\n","            sess.run(optimizer, feed_dict=train_feed_dict)\n","\n","        # Print cost and validation accuracy of an epoch\n","        print_epoch_stats(epoch_i, sess, batch_features, batch_labels)\n","\n","    # Calculate accuracy for test dataset\n","    test_accuracy = sess.run(\n","        accuracy,\n","        feed_dict={features: test_features, labels: test_labels})\n","\n","print('Test Accuracy: {}'.format(test_accuracy))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n","Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n","Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n","Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n","Epoch: 0    - Cost: 11.3     Valid Accuracy: 0.0656\n","Epoch: 1    - Cost: 10.5     Valid Accuracy: 0.079\n","Epoch: 2    - Cost: 9.99     Valid Accuracy: 0.0942\n","Epoch: 3    - Cost: 9.54     Valid Accuracy: 0.105\n","Epoch: 4    - Cost: 9.14     Valid Accuracy: 0.116\n","Epoch: 5    - Cost: 8.78     Valid Accuracy: 0.129\n","Epoch: 6    - Cost: 8.43     Valid Accuracy: 0.141\n","Epoch: 7    - Cost: 8.11     Valid Accuracy: 0.155\n","Epoch: 8    - Cost: 7.8      Valid Accuracy: 0.17 \n","Epoch: 9    - Cost: 7.51     Valid Accuracy: 0.184\n","Epoch: 10   - Cost: 7.23     Valid Accuracy: 0.199\n","Epoch: 11   - Cost: 6.97     Valid Accuracy: 0.216\n","Epoch: 12   - Cost: 6.71     Valid Accuracy: 0.234\n","Epoch: 13   - Cost: 6.48     Valid Accuracy: 0.252\n","Epoch: 14   - Cost: 6.25     Valid Accuracy: 0.269\n","Epoch: 15   - Cost: 6.03     Valid Accuracy: 0.287\n","Epoch: 16   - Cost: 5.83     Valid Accuracy: 0.306\n","Epoch: 17   - Cost: 5.63     Valid Accuracy: 0.318\n","Epoch: 18   - Cost: 5.44     Valid Accuracy: 0.332\n","Epoch: 19   - Cost: 5.26     Valid Accuracy: 0.347\n","Epoch: 20   - Cost: 5.09     Valid Accuracy: 0.36 \n","Epoch: 21   - Cost: 4.93     Valid Accuracy: 0.371\n","Epoch: 22   - Cost: 4.77     Valid Accuracy: 0.383\n","Epoch: 23   - Cost: 4.62     Valid Accuracy: 0.396\n","Epoch: 24   - Cost: 4.48     Valid Accuracy: 0.406\n","Epoch: 25   - Cost: 4.35     Valid Accuracy: 0.416\n","Epoch: 26   - Cost: 4.22     Valid Accuracy: 0.425\n","Epoch: 27   - Cost: 4.1      Valid Accuracy: 0.434\n","Epoch: 28   - Cost: 3.98     Valid Accuracy: 0.441\n","Epoch: 29   - Cost: 3.87     Valid Accuracy: 0.45 \n","Epoch: 30   - Cost: 3.77     Valid Accuracy: 0.457\n","Epoch: 31   - Cost: 3.67     Valid Accuracy: 0.463\n","Epoch: 32   - Cost: 3.58     Valid Accuracy: 0.471\n","Epoch: 33   - Cost: 3.49     Valid Accuracy: 0.479\n","Epoch: 34   - Cost: 3.41     Valid Accuracy: 0.489\n","Epoch: 35   - Cost: 3.33     Valid Accuracy: 0.497\n","Epoch: 36   - Cost: 3.25     Valid Accuracy: 0.504\n","Epoch: 37   - Cost: 3.18     Valid Accuracy: 0.513\n","Epoch: 38   - Cost: 3.11     Valid Accuracy: 0.517\n","Epoch: 39   - Cost: 3.05     Valid Accuracy: 0.524\n","Epoch: 40   - Cost: 2.99     Valid Accuracy: 0.53 \n","Epoch: 41   - Cost: 2.93     Valid Accuracy: 0.537\n","Epoch: 42   - Cost: 2.87     Valid Accuracy: 0.543\n","Epoch: 43   - Cost: 2.82     Valid Accuracy: 0.548\n","Epoch: 44   - Cost: 2.76     Valid Accuracy: 0.553\n","Epoch: 45   - Cost: 2.72     Valid Accuracy: 0.557\n","Epoch: 46   - Cost: 2.67     Valid Accuracy: 0.562\n","Epoch: 47   - Cost: 2.62     Valid Accuracy: 0.567\n","Epoch: 48   - Cost: 2.58     Valid Accuracy: 0.573\n","Epoch: 49   - Cost: 2.54     Valid Accuracy: 0.577\n","Epoch: 50   - Cost: 2.5      Valid Accuracy: 0.581\n","Epoch: 51   - Cost: 2.46     Valid Accuracy: 0.583\n","Epoch: 52   - Cost: 2.43     Valid Accuracy: 0.588\n","Epoch: 53   - Cost: 2.39     Valid Accuracy: 0.594\n","Epoch: 54   - Cost: 2.36     Valid Accuracy: 0.6  \n","Epoch: 55   - Cost: 2.33     Valid Accuracy: 0.603\n","Epoch: 56   - Cost: 2.3      Valid Accuracy: 0.606\n","Epoch: 57   - Cost: 2.27     Valid Accuracy: 0.61 \n","Epoch: 58   - Cost: 2.24     Valid Accuracy: 0.613\n","Epoch: 59   - Cost: 2.21     Valid Accuracy: 0.618\n","Epoch: 60   - Cost: 2.19     Valid Accuracy: 0.621\n","Epoch: 61   - Cost: 2.16     Valid Accuracy: 0.624\n","Epoch: 62   - Cost: 2.14     Valid Accuracy: 0.628\n","Epoch: 63   - Cost: 2.12     Valid Accuracy: 0.631\n","Epoch: 64   - Cost: 2.09     Valid Accuracy: 0.634\n","Epoch: 65   - Cost: 2.07     Valid Accuracy: 0.636\n","Epoch: 66   - Cost: 2.05     Valid Accuracy: 0.638\n","Epoch: 67   - Cost: 2.03     Valid Accuracy: 0.64 \n","Epoch: 68   - Cost: 2.01     Valid Accuracy: 0.644\n","Epoch: 69   - Cost: 2.0      Valid Accuracy: 0.647\n","Epoch: 70   - Cost: 1.98     Valid Accuracy: 0.651\n","Epoch: 71   - Cost: 1.96     Valid Accuracy: 0.653\n","Epoch: 72   - Cost: 1.95     Valid Accuracy: 0.657\n","Epoch: 73   - Cost: 1.93     Valid Accuracy: 0.659\n","Epoch: 74   - Cost: 1.91     Valid Accuracy: 0.661\n","Epoch: 75   - Cost: 1.9      Valid Accuracy: 0.664\n","Epoch: 76   - Cost: 1.89     Valid Accuracy: 0.667\n","Epoch: 77   - Cost: 1.87     Valid Accuracy: 0.667\n","Epoch: 78   - Cost: 1.86     Valid Accuracy: 0.669\n","Epoch: 79   - Cost: 1.85     Valid Accuracy: 0.671\n","Epoch: 80   - Cost: 1.83     Valid Accuracy: 0.674\n","Epoch: 81   - Cost: 1.82     Valid Accuracy: 0.675\n","Epoch: 82   - Cost: 1.81     Valid Accuracy: 0.678\n","Epoch: 83   - Cost: 1.8      Valid Accuracy: 0.68 \n","Epoch: 84   - Cost: 1.79     Valid Accuracy: 0.682\n","Epoch: 85   - Cost: 1.78     Valid Accuracy: 0.683\n","Epoch: 86   - Cost: 1.77     Valid Accuracy: 0.685\n","Epoch: 87   - Cost: 1.76     Valid Accuracy: 0.687\n","Epoch: 88   - Cost: 1.75     Valid Accuracy: 0.689\n","Epoch: 89   - Cost: 1.74     Valid Accuracy: 0.69 \n","Epoch: 90   - Cost: 1.73     Valid Accuracy: 0.693\n","Epoch: 91   - Cost: 1.72     Valid Accuracy: 0.695\n","Epoch: 92   - Cost: 1.71     Valid Accuracy: 0.697\n","Epoch: 93   - Cost: 1.7      Valid Accuracy: 0.698\n","Epoch: 94   - Cost: 1.69     Valid Accuracy: 0.7  \n","Epoch: 95   - Cost: 1.68     Valid Accuracy: 0.702\n","Epoch: 96   - Cost: 1.68     Valid Accuracy: 0.705\n","Epoch: 97   - Cost: 1.67     Valid Accuracy: 0.707\n","Epoch: 98   - Cost: 1.66     Valid Accuracy: 0.708\n","Epoch: 99   - Cost: 1.65     Valid Accuracy: 0.71 \n","Test Accuracy: 0.7138000130653381\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lb2ic0FkbvIe","colab_type":"code","outputId":"f0d83877-061d-4e94-8cb7-74a6ed1be50d","executionInfo":{"status":"ok","timestamp":1573920297259,"user_tz":-330,"elapsed":1018,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import tensorflow as tf\n","\n","output = None\n","hidden_layer_weights = [\n","    [0.1, 0.2, 0.4],\n","    [0.4, 0.6, 0.6],\n","    [0.5, 0.9, 0.1],\n","    [0.8, 0.2, 0.8]]\n","out_weights = [\n","    [0.1, 0.6],\n","    [0.2, 0.1],\n","    [0.7, 0.9]]\n","\n","# Weights and biases\n","weights = [\n","    tf.Variable(hidden_layer_weights),\n","    tf.Variable(out_weights)]\n","biases = [\n","    tf.Variable(tf.zeros(3)),\n","    tf.Variable(tf.zeros(2))]\n","\n","# Input\n","features = tf.Variable([[1.0, 2.0, 3.0, 4.0], [-1.0, -2.0, -3.0, -4.0], [11.0, 12.0, 13.0, 14.0]])\n","\n","hidden_ly = tf.add(tf.matmul(features, weights[0]), bias[0])\n","hidden_ly = tf.nn.relu(hidden_ly)\n","\n","logits = tf.add(tf.matmul(hidden_ly, weights[1]), bias[1])\n","\n","with tf.Session() as sess:\n","  sess.run(tf.global_variables_initializer())\n","  _ = sess.run(logits)\n","  print(_)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[ 3.1864047  6.549398 ]\n"," [-1.9785838 -1.9785838]\n"," [22.086405  36.3494   ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vSEj4t_19ck4","colab_type":"code","outputId":"8f6d8ad8-7bf2-4d25-856e-dd8d9deb1ce9","executionInfo":{"status":"ok","timestamp":1573920711938,"user_tz":-330,"elapsed":1333,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","Extracting ./train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","Extracting ./train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting ./t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting ./t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cosXBkKB_B8C","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","# Parameters\n","learning_rate = 0.001\n","training_epochs = 20\n","batch_size = 128  # Decrease batch size if you don't have enough memory\n","display_step = 1\n","\n","n_input = 784  # MNIST data input (img shape: 28*28)\n","n_classes = 10  # MNIST total classes (0-9 digits)\n","n_hidden_layer = 256 # layer number of features\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BdT9ItIN_FTe","colab_type":"code","colab":{}},"source":["# Store layers weight & bias\n","weights = {\n","    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n","    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n","}\n","biases = {\n","    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n","    'out': tf.Variable(tf.random_normal([n_classes]))\n","}\n","\n","# tf Graph input\n","x = tf.placeholder(\"float\", [None, 28, 28, 1])\n","y = tf.placeholder(\"float\", [None, n_classes])\n","\n","x_flat = tf.reshape(x, [-1, n_input])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EhkP-JTAAJvO","colab_type":"code","colab":{}},"source":["# Hidden layer with RELU activation\n","layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer']),\\\n","    biases['hidden_layer'])\n","layer_1 = tf.nn.relu(layer_1)\n","# Output layer with linear activation\n","logits = tf.add(tf.matmul(layer_1, weights['out']), biases['out'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTnd9YwhAfxI","colab_type":"code","colab":{}},"source":["# Define loss and optimizer\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RU8oZjgtHYy7","colab_type":"code","colab":{}},"source":["# Initializing the variables\n","init = tf.global_variables_initializer()\n","\n","\n","# Launch the graph\n","with tf.Session() as sess:\n","    sess.run(init)\n","    # Training cycle\n","    for epoch in range(training_epochs):\n","        total_batch = int(mnist.train.num_examples/batch_size)\n","        # Loop over all batches\n","        for i in range(total_batch):\n","            batch_x, batch_y = mnist.train.next_batch(batch_size)\n","            # Run optimization op (backprop) and cost op (to get loss value)\n","            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQc9PKERHiRN","colab_type":"code","outputId":"ee07c3cb-a801-4b3b-8e88-5b8892bb19da","executionInfo":{"status":"ok","timestamp":1573923118697,"user_tz":-330,"elapsed":1313,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["import tensorflow as tf\n","\n","# The file path to save the data\n","save_file = './model.ckpt'\n","\n","# Two Tensor Variables: weights and bias\n","weights = tf.Variable(tf.truncated_normal([2, 3]))\n","bias = tf.Variable(tf.truncated_normal([3]))\n","\n","# Class used to save and/or restore Tensor Variables\n","saver = tf.train.Saver()\n","\n","with tf.Session() as sess:\n","    # Initialize all the Variables\n","    sess.run(tf.global_variables_initializer())\n","\n","    # Show the values of weights and bias\n","    print('Weights:')\n","    print(sess.run(weights))\n","    print('Bias:')\n","    print(sess.run(bias))\n","\n","    # Save the model\n","    saver.save(sess, save_file)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Weights:\n","[[ 0.86581475  0.20752715  0.6481302 ]\n"," [-0.09491592  0.34161222 -0.59946585]]\n","Bias:\n","[ 1.2837073  -0.09462225  0.03620739]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AQtCCa2xKDAi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mMvSuebPINhy","colab_type":"code","outputId":"1ba4b67d-753b-46ac-9f32-7cdb347c98f8","executionInfo":{"status":"error","timestamp":1573923607343,"user_tz":-330,"elapsed":747,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Remove the previous weights and bias\n","tf.reset_default_graph()\n","\n","# Two Variables: weights and bias\n","weights = tf.Variable(tf.truncated_normal([2, 3]))\n","bias = tf.Variable(tf.truncated_normal([3]))\n","\n","# Class used to save and/or restore Tensor Variables\n","saver = tf.train.Saver()\n","\n","with tf.Session() as sess:\n","    # Load the weights and bias\n","    saver.restore(sess, save_file)\n","\n","    # Show the values of weights and bias\n","    print('Weight:')\n","    print(sess.run(weights))\n","    print('Bias:')\n","    print(sess.run(bias))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ./model.ckpt\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [3] rhs shape= [10]\n\t [[{{node save/Assign_1}}]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1290\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1291\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [3] rhs shape= [10]\n\t [[node save/Assign_1 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'save/Assign_1':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-51e46af4c600>\", line 5, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 828, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 350, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saving/saveable_object_util.py\", line 73, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/state_ops.py\", line 227, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_state_ops.py\", line 66, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-51e46af4c600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Load the weights and bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Show the values of weights and bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0;31m# We add a more reasonable error message here to help users (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1326\u001b[0;31m           err, \"a mismatch between the current graph and the graph\")\n\u001b[0m\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [3] rhs shape= [10]\n\t [[node save/Assign_1 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'save/Assign_1':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-51e46af4c600>\", line 5, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 828, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 350, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saving/saveable_object_util.py\", line 73, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/state_ops.py\", line 227, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_state_ops.py\", line 66, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"]}]},{"cell_type":"code","metadata":{"id":"9ij0ue1HJrQw","colab_type":"code","outputId":"8cba2a2d-0077-4fc7-c9d4-933c1c335a93","executionInfo":{"status":"ok","timestamp":1573926092409,"user_tz":-330,"elapsed":1928,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Remove previous Tensors and Operations\n","tf.reset_default_graph()\n","\n","from tensorflow.examples.tutorials.mnist import input_data\n","import numpy as np\n","\n","learning_rate = 0.001\n","n_input = 784  # MNIST data input (img shape: 28*28)\n","n_classes = 10  # MNIST total classes (0-9 digits)\n","\n","# Import MNIST data\n","mnist = input_data.read_data_sets('.', one_hot=True)\n","\n","# Features and Labels\n","features = tf.placeholder(tf.float32, [None, n_input])\n","labels = tf.placeholder(tf.float32, [None, n_classes])\n","\n","# Weights & bias\n","weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n","bias = tf.Variable(tf.random_normal([n_classes]))\n","\n","# Logits - xW + b\n","logits = tf.add(tf.matmul(features, weights), bias)\n","\n","# Define loss and optimizer\n","cost = tf.reduce_mean(\\\n","    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n","    .minimize(cost)\n","\n","# Calculate accuracy\n","correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Extracting ./train-images-idx3-ubyte.gz\n","Extracting ./train-labels-idx1-ubyte.gz\n","Extracting ./t10k-images-idx3-ubyte.gz\n","Extracting ./t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t4nLT1uhTjXu","colab_type":"code","outputId":"0b5fe20a-4783-482e-e116-59520012a5a5","executionInfo":{"status":"ok","timestamp":1573926203973,"user_tz":-330,"elapsed":83909,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["import math\n","\n","save_file = './train_model_mnist.ckpt'\n","batch_size = 128\n","n_epochs = 100\n","\n","saver = tf.train.Saver()\n","\n","# Launch the graph\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","\n","    # Training cycle\n","    for epoch in range(n_epochs):\n","        total_batch = math.ceil(mnist.train.num_examples / batch_size)\n","\n","        # Loop over all batches\n","        for i in range(total_batch):\n","            batch_features, batch_labels = mnist.train.next_batch(batch_size)\n","            sess.run(\n","                optimizer,\n","                feed_dict={features: batch_features, labels: batch_labels})\n","\n","        # Print status for every 10 epochs\n","        if epoch % 10 == 0:\n","            valid_accuracy = sess.run(\n","                accuracy,\n","                feed_dict={\n","                    features: mnist.validation.images,\n","                    labels: mnist.validation.labels})\n","            print('Epoch {:<3} - Validation Accuracy: {}'.format(\n","                epoch,\n","                valid_accuracy))\n","\n","    # Save the model\n","    saver.save(sess, save_file)\n","    print('Trained Model Saved.')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 0   - Validation Accuracy: 0.10499999672174454\n","Epoch 10  - Validation Accuracy: 0.23559999465942383\n","Epoch 20  - Validation Accuracy: 0.3970000147819519\n","Epoch 30  - Validation Accuracy: 0.492000013589859\n","Epoch 40  - Validation Accuracy: 0.5641999840736389\n","Epoch 50  - Validation Accuracy: 0.6114000082015991\n","Epoch 60  - Validation Accuracy: 0.6489999890327454\n","Epoch 70  - Validation Accuracy: 0.6758000254631042\n","Epoch 80  - Validation Accuracy: 0.6941999793052673\n","Epoch 90  - Validation Accuracy: 0.7139999866485596\n","Trained Model Saved.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sGyKtwkJTqnC","colab_type":"code","outputId":"c005b916-3d2a-43bb-fce2-759cc258bede","executionInfo":{"status":"ok","timestamp":1573926318570,"user_tz":-330,"elapsed":2192,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["saver = tf.train.Saver()\n","\n","# Launch the graph\n","with tf.Session() as sess:\n","    saver.restore(sess, save_file)\n","\n","    test_accuracy = sess.run(\n","        accuracy,\n","        feed_dict={features: mnist.test.images, labels: mnist.test.labels})\n","\n","print('Test Accuracy: {}'.format(test_accuracy))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ./train_model_mnist.ckpt\n","Test Accuracy: 0.7199000120162964\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5kQuk8uLUaiF","colab_type":"code","outputId":"af19277d-f85e-4bd9-dae5-e8b8fe2089ab","executionInfo":{"status":"error","timestamp":1573927121162,"user_tz":-330,"elapsed":1146,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import tensorflow as tf\n","\n","# Remove the previous weights and bias\n","tf.reset_default_graph()\n","\n","save_file = 'train_model_mnist.ckpt'\n","\n","# Two Tensor Variables: weights and bias\n","weights = tf.Variable(tf.truncated_normal([2, 3]))\n","bias = tf.Variable(tf.truncated_normal([3]))\n","\n","saver = tf.train.Saver()\n","\n","# Print the name of Weights and Bias\n","print('Save Weights: {}'.format(weights.name))\n","print('Save Bias: {}'.format(bias.name))\n","\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    saver.save(sess, save_file)\n","\n","# Remove the previous weights and bias\n","tf.reset_default_graph()\n","\n","# Two Variables: weights and bias\n","bias = tf.Variable(tf.truncated_normal([3]))\n","weights = tf.Variable(tf.truncated_normal([2, 3]))\n","\n","saver = tf.train.Saver()\n","\n","# Print the name of Weights and Bias\n","print('Load Weights: {}'.format(weights.name))\n","print('Load Bias: {}'.format(bias.name))\n","\n","with tf.Session() as sess:\n","    # Load the weights and bias - ERROR\n","    saver.restore(sess, save_file)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Save Weights: Variable:0\n","Save Bias: Variable_1:0\n","Load Weights: Variable_1:0\n","Load Bias: Variable:0\n","INFO:tensorflow:Restoring parameters from train_model_mnist.ckpt\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[{{node save/Assign_1}}]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1290\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1291\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[node save/Assign_1 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'save/Assign_1':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-7967caef2a0e>\", line 29, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 828, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 350, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saving/saveable_object_util.py\", line 73, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/state_ops.py\", line 227, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_state_ops.py\", line 66, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-7967caef2a0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Load the weights and bias - ERROR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0;31m# We add a more reasonable error message here to help users (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1326\u001b[0;31m           err, \"a mismatch between the current graph and the graph\")\n\u001b[0m\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [2,3] rhs shape= [3]\n\t [[node save/Assign_1 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'save/Assign_1':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-7967caef2a0e>\", line 29, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 828, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 350, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saving/saveable_object_util.py\", line 73, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/state_ops.py\", line 227, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_state_ops.py\", line 66, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"]}]},{"cell_type":"code","metadata":{"id":"fek07s4GXeuu","colab_type":"code","outputId":"d75ef45a-0491-4df7-8f74-5eaa92bd253c","executionInfo":{"status":"ok","timestamp":1573927222235,"user_tz":-330,"elapsed":913,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["import tensorflow as tf\n","\n","tf.reset_default_graph()\n","\n","save_file = 'train_model_mnist.ckpt'\n","\n","# Two Tensor Variables: weights and bias\n","weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n","bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n","\n","saver = tf.train.Saver()\n","\n","# Print the name of Weights and Bias\n","print('Save Weights: {}'.format(weights.name))\n","print('Save Bias: {}'.format(bias.name))\n","\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    saver.save(sess, save_file)\n","\n","# Remove the previous weights and bias\n","tf.reset_default_graph()\n","\n","# Two Variables: weights and bias\n","bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n","weights = tf.Variable(tf.truncated_normal([2, 3]) ,name='weights_0')\n","\n","saver = tf.train.Saver()\n","\n","# Print the name of Weights and Bias\n","print('Load Weights: {}'.format(weights.name))\n","print('Load Bias: {}'.format(bias.name))\n","\n","with tf.Session() as sess:\n","    # Load the weights and bias - No Error\n","    saver.restore(sess, save_file)\n","\n","print('Loaded Weights and Bias successfully.')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Save Weights: weights_0:0\n","Save Bias: bias_0:0\n","Load Weights: weights_0:0\n","Load Bias: bias_0:0\n","INFO:tensorflow:Restoring parameters from train_model_mnist.ckpt\n","Loaded Weights and Bias successfully.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2G_OdsWEX3dw","colab_type":"code","outputId":"a656b9a1-808c-435d-96e7-9fea518b04e2","executionInfo":{"status":"ok","timestamp":1573931298166,"user_tz":-330,"elapsed":964,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import tensorflow as tf\n","\n","hidden_layer_weights = [\n","    [0.1, 0.2, 0.4],\n","    [0.4, 0.6, 0.6],\n","    [0.5, 0.9, 0.1],\n","    [0.8, 0.2, 0.8]]\n","out_weights = [\n","    [0.1, 0.6],\n","    [0.2, 0.1],\n","    [0.7, 0.9]]\n","\n","# Weights and biases\n","weights = [\n","    tf.Variable(hidden_layer_weights),\n","    tf.Variable(out_weights)]\n","biases = [\n","    tf.Variable(tf.zeros(3)),\n","    tf.Variable(tf.zeros(2))]\n","\n","# Input\n","features = tf.Variable([[0.0, 2.0, 3.0, 4.0], [0.1, 0.2, 0.3, 0.4], [11.0, 12.0, 13.0, 14.0]])\n","keep_prob = tf.placeholder(tf.float32)\n","hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n","hidden_layer = tf.nn.relu(hidden_layer)\n","hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n","\n","logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n","\n","# TODO: Print logits from a session\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    print(sess.run(logits, feed_dict={keep_prob: 0.5}))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[1.8800001  0.94000006]\n"," [0.         0.        ]\n"," [0.         0.        ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_kCRZDhSmLMO","colab_type":"code","outputId":"b3e545ea-2e15-407f-a0d8-0abbfde43706","executionInfo":{"status":"ok","timestamp":1573931160303,"user_tz":-330,"elapsed":866,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["import tensorflow as tf\n","\n","hidden_layer_weights = [\n","    [0.1, 0.2, 0.4],\n","    [0.4, 0.6, 0.6],\n","    [0.5, 0.9, 0.1],\n","    [0.8, 0.2, 0.8]]\n","out_weights = [\n","    [0.1, 0.6],\n","    [0.2, 0.1],\n","    [0.7, 0.9]]\n","\n","# Weights and biases\n","weights = [\n","    tf.Variable(hidden_layer_weights),\n","    tf.Variable(out_weights)]\n","biases = [\n","    tf.Variable(tf.zeros(3)),\n","    tf.Variable(tf.zeros(2))]\n","\n","# Input\n","features = tf.Variable([[0.0, 2.0, 3.0, 4.0], [0.1, 0.2, 0.3, 0.4], [11.0, 12.0, 13.0, 14.0]])\n","\n","# TODO: Create Model with Dropout\n","keep_prob = tf.placeholder(tf.float32)\n","hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n","hidden_layer = tf.nn.relu(hidden_layer)\n","hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n","\n","logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n","\n","# TODO: Print logits from a session\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    print(sess.run(logits, feed_dict={keep_prob: 0.5}))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-39-47c2376b8623>:28: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","[[ 7.68       15.059999  ]\n"," [ 0.112       0.67200005]\n"," [14.280001   33.100002  ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t6JO565C3GxL","colab_type":"code","outputId":"044f3253-818e-4823-e713-14ba41450582","executionInfo":{"status":"ok","timestamp":1573935415442,"user_tz":-330,"elapsed":1556,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n","\n","import tensorflow as tf\n","\n","# Parameters\n","learning_rate = 0.00001\n","epochs = 10\n","batch_size = 128\n","\n","# Number of samples to calculate validation and accuracy\n","# Decrease this if you're running out of memory to calculate accuracy\n","test_valid_size = 256\n","\n","# Network Parameters\n","n_classes = 10  # MNIST total classes (0-9 digits)\n","dropout = 0.75  # Dropout, probability to keep units"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Extracting ./train-images-idx3-ubyte.gz\n","Extracting ./train-labels-idx1-ubyte.gz\n","Extracting ./t10k-images-idx3-ubyte.gz\n","Extracting ./t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HveUUY573KDH","colab_type":"code","colab":{}},"source":["# Store layers weight & bias\n","weights = {\n","    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n","    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n","    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n","    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n","\n","biases = {\n","    'bc1': tf.Variable(tf.random_normal([32])),\n","    'bc2': tf.Variable(tf.random_normal([64])),\n","    'bd1': tf.Variable(tf.random_normal([1024])),\n","    'out': tf.Variable(tf.random_normal([n_classes]))}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XaSOU20n3M1a","colab_type":"code","colab":{}},"source":["def conv2d(x, W, b, strides=1):\n","    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n","    x = tf.nn.bias_add(x, b)\n","    return tf.nn.relu(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_fMcz4v3Pga","colab_type":"code","colab":{}},"source":["def maxpool2d(x, k=2):\n","    return tf.nn.max_pool(\n","        x,\n","        ksize=[1, k, k, 1],\n","        strides=[1, k, k, 1],\n","        padding='SAME')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzjqZG8vm45v","colab_type":"code","colab":{}},"source":["def conv_net(x, weights, biases, dropout):\n","    # Layer 1 - 28*28*1 to 14*14*32\n","    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n","    conv1 = maxpool2d(conv1, k=2)\n","\n","    # Layer 2 - 14*14*32 to 7*7*64\n","    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n","    conv2 = maxpool2d(conv2, k=2)\n","\n","    # Fully connected layer - 7*7*64 to 1024\n","    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n","    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n","    fc1 = tf.nn.relu(fc1)\n","    fc1 = tf.nn.dropout(fc1, dropout)\n","\n","    # Output Layer - class prediction - 1024 to 10\n","    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LVUYEsEm21ol","colab_type":"code","outputId":"1d6b82fe-80ae-4f23-eb49-09f40853f198","executionInfo":{"status":"ok","timestamp":1573935560533,"user_tz":-330,"elapsed":103354,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# tf Graph input\n","x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n","y = tf.placeholder(tf.float32, [None, n_classes])\n","keep_prob = tf.placeholder(tf.float32)\n","\n","# Model\n","logits = conv_net(x, weights, biases, keep_prob)\n","\n","# Define loss and optimizer\n","cost = tf.reduce_mean(\\\n","    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n","    .minimize(cost)\n","\n","# Accuracy\n","correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","\n","# Initializing the variables\n","init = tf. global_variables_initializer()\n","\n","# Launch the graph\n","with tf.Session() as sess:\n","    sess.run(init)\n","\n","    for epoch in range(epochs):\n","        for batch in range(mnist.train.num_examples//batch_size):\n","            batch_x, batch_y = mnist.train.next_batch(batch_size)\n","            sess.run(optimizer, feed_dict={\n","                x: batch_x,\n","                y: batch_y,\n","                keep_prob: dropout})\n","\n","            # Calculate batch loss and accuracy\n","            loss = sess.run(cost, feed_dict={\n","                x: batch_x,\n","                y: batch_y,\n","                keep_prob: 1.})\n","            valid_acc = sess.run(accuracy, feed_dict={\n","                x: mnist.validation.images[:test_valid_size],\n","                y: mnist.validation.labels[:test_valid_size],\n","                keep_prob: 1.})\n","\n","            print('Epoch {:>2}, Batch {:>3} -'\n","                  'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n","                epoch + 1,\n","                batch + 1,\n","                loss,\n","                valid_acc))\n","\n","    # Calculate Test Accuracy\n","    test_acc = sess.run(accuracy, feed_dict={\n","        x: mnist.test.images[:test_valid_size],\n","        y: mnist.test.labels[:test_valid_size],\n","        keep_prob: 1.})\n","    print('Testing Accuracy: {}'.format(test_acc))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch  1, Batch   1 -Loss: 73196.5312 Validation Accuracy: 0.156250\n","Epoch  1, Batch   2 -Loss: 55644.9648 Validation Accuracy: 0.148438\n","Epoch  1, Batch   3 -Loss: 46816.5508 Validation Accuracy: 0.148438\n","Epoch  1, Batch   4 -Loss: 41266.9531 Validation Accuracy: 0.152344\n","Epoch  1, Batch   5 -Loss: 38985.3359 Validation Accuracy: 0.148438\n","Epoch  1, Batch   6 -Loss: 31786.6895 Validation Accuracy: 0.140625\n","Epoch  1, Batch   7 -Loss: 34869.3281 Validation Accuracy: 0.132812\n","Epoch  1, Batch   8 -Loss: 31305.7188 Validation Accuracy: 0.140625\n","Epoch  1, Batch   9 -Loss: 27129.8281 Validation Accuracy: 0.144531\n","Epoch  1, Batch  10 -Loss: 25902.2031 Validation Accuracy: 0.148438\n","Epoch  1, Batch  11 -Loss: 22767.3125 Validation Accuracy: 0.144531\n","Epoch  1, Batch  12 -Loss: 24499.5508 Validation Accuracy: 0.148438\n","Epoch  1, Batch  13 -Loss: 21776.9609 Validation Accuracy: 0.144531\n","Epoch  1, Batch  14 -Loss: 19264.5938 Validation Accuracy: 0.152344\n","Epoch  1, Batch  15 -Loss: 21270.4023 Validation Accuracy: 0.160156\n","Epoch  1, Batch  16 -Loss: 18225.5312 Validation Accuracy: 0.144531\n","Epoch  1, Batch  17 -Loss: 18320.6602 Validation Accuracy: 0.171875\n","Epoch  1, Batch  18 -Loss: 17979.9844 Validation Accuracy: 0.156250\n","Epoch  1, Batch  19 -Loss: 15605.0000 Validation Accuracy: 0.164062\n","Epoch  1, Batch  20 -Loss: 14181.8525 Validation Accuracy: 0.195312\n","Epoch  1, Batch  21 -Loss: 15261.8438 Validation Accuracy: 0.207031\n","Epoch  1, Batch  22 -Loss: 12704.6680 Validation Accuracy: 0.230469\n","Epoch  1, Batch  23 -Loss: 14493.0635 Validation Accuracy: 0.230469\n","Epoch  1, Batch  24 -Loss: 12496.0195 Validation Accuracy: 0.234375\n","Epoch  1, Batch  25 -Loss: 11230.0488 Validation Accuracy: 0.242188\n","Epoch  1, Batch  26 -Loss: 11961.1895 Validation Accuracy: 0.261719\n","Epoch  1, Batch  27 -Loss: 12088.8350 Validation Accuracy: 0.253906\n","Epoch  1, Batch  28 -Loss:  9769.0361 Validation Accuracy: 0.281250\n","Epoch  1, Batch  29 -Loss: 10973.0234 Validation Accuracy: 0.269531\n","Epoch  1, Batch  30 -Loss: 10224.9580 Validation Accuracy: 0.257812\n","Epoch  1, Batch  31 -Loss:  9484.7666 Validation Accuracy: 0.296875\n","Epoch  1, Batch  32 -Loss: 10610.9375 Validation Accuracy: 0.296875\n","Epoch  1, Batch  33 -Loss: 11093.5332 Validation Accuracy: 0.312500\n","Epoch  1, Batch  34 -Loss: 10621.9521 Validation Accuracy: 0.308594\n","Epoch  1, Batch  35 -Loss: 12985.3262 Validation Accuracy: 0.316406\n","Epoch  1, Batch  36 -Loss:  9531.7158 Validation Accuracy: 0.320312\n","Epoch  1, Batch  37 -Loss:  9940.6963 Validation Accuracy: 0.328125\n","Epoch  1, Batch  38 -Loss:  9748.3477 Validation Accuracy: 0.304688\n","Epoch  1, Batch  39 -Loss:  9346.2871 Validation Accuracy: 0.304688\n","Epoch  1, Batch  40 -Loss: 11484.6709 Validation Accuracy: 0.308594\n","Epoch  1, Batch  41 -Loss: 10132.3203 Validation Accuracy: 0.328125\n","Epoch  1, Batch  42 -Loss:  9230.1973 Validation Accuracy: 0.324219\n","Epoch  1, Batch  43 -Loss:  9661.6035 Validation Accuracy: 0.339844\n","Epoch  1, Batch  44 -Loss:  7169.4014 Validation Accuracy: 0.355469\n","Epoch  1, Batch  45 -Loss:  8321.1416 Validation Accuracy: 0.347656\n","Epoch  1, Batch  46 -Loss:  9262.8750 Validation Accuracy: 0.339844\n","Epoch  1, Batch  47 -Loss:  9412.1191 Validation Accuracy: 0.363281\n","Epoch  1, Batch  48 -Loss:  7462.7988 Validation Accuracy: 0.371094\n","Epoch  1, Batch  49 -Loss:  7368.1514 Validation Accuracy: 0.394531\n","Epoch  1, Batch  50 -Loss:  8267.9121 Validation Accuracy: 0.375000\n","Epoch  1, Batch  51 -Loss:  7402.3066 Validation Accuracy: 0.390625\n","Epoch  1, Batch  52 -Loss:  8126.4443 Validation Accuracy: 0.367188\n","Epoch  1, Batch  53 -Loss:  9854.0723 Validation Accuracy: 0.359375\n","Epoch  1, Batch  54 -Loss:  6383.8428 Validation Accuracy: 0.394531\n","Epoch  1, Batch  55 -Loss:  6817.2891 Validation Accuracy: 0.410156\n","Epoch  1, Batch  56 -Loss:  9171.9668 Validation Accuracy: 0.406250\n","Epoch  1, Batch  57 -Loss:  7561.8955 Validation Accuracy: 0.406250\n","Epoch  1, Batch  58 -Loss:  7423.4990 Validation Accuracy: 0.414062\n","Epoch  1, Batch  59 -Loss:  6881.3530 Validation Accuracy: 0.410156\n","Epoch  1, Batch  60 -Loss:  6942.8291 Validation Accuracy: 0.410156\n","Epoch  1, Batch  61 -Loss:  6054.0796 Validation Accuracy: 0.406250\n","Epoch  1, Batch  62 -Loss:  6812.6084 Validation Accuracy: 0.421875\n","Epoch  1, Batch  63 -Loss:  6606.4609 Validation Accuracy: 0.417969\n","Epoch  1, Batch  64 -Loss:  6542.7407 Validation Accuracy: 0.417969\n","Epoch  1, Batch  65 -Loss:  9054.8320 Validation Accuracy: 0.417969\n","Epoch  1, Batch  66 -Loss:  5045.7764 Validation Accuracy: 0.410156\n","Epoch  1, Batch  67 -Loss:  6947.4819 Validation Accuracy: 0.429688\n","Epoch  1, Batch  68 -Loss:  5538.0962 Validation Accuracy: 0.429688\n","Epoch  1, Batch  69 -Loss:  6810.8643 Validation Accuracy: 0.441406\n","Epoch  1, Batch  70 -Loss:  5787.6724 Validation Accuracy: 0.429688\n","Epoch  1, Batch  71 -Loss:  5557.0762 Validation Accuracy: 0.441406\n","Epoch  1, Batch  72 -Loss:  5958.3149 Validation Accuracy: 0.441406\n","Epoch  1, Batch  73 -Loss:  4630.4365 Validation Accuracy: 0.449219\n","Epoch  1, Batch  74 -Loss:  5229.7012 Validation Accuracy: 0.449219\n","Epoch  1, Batch  75 -Loss:  5775.7158 Validation Accuracy: 0.433594\n","Epoch  1, Batch  76 -Loss:  6143.1460 Validation Accuracy: 0.429688\n","Epoch  1, Batch  77 -Loss:  5590.0337 Validation Accuracy: 0.433594\n","Epoch  1, Batch  78 -Loss:  4676.6602 Validation Accuracy: 0.441406\n","Epoch  1, Batch  79 -Loss:  5257.4258 Validation Accuracy: 0.464844\n","Epoch  1, Batch  80 -Loss:  5771.5625 Validation Accuracy: 0.476562\n","Epoch  1, Batch  81 -Loss:  5346.9482 Validation Accuracy: 0.453125\n","Epoch  1, Batch  82 -Loss:  6045.8159 Validation Accuracy: 0.453125\n","Epoch  1, Batch  83 -Loss:  5546.7188 Validation Accuracy: 0.480469\n","Epoch  1, Batch  84 -Loss:  4881.0508 Validation Accuracy: 0.480469\n","Epoch  1, Batch  85 -Loss:  5729.9141 Validation Accuracy: 0.464844\n","Epoch  1, Batch  86 -Loss:  5534.8887 Validation Accuracy: 0.468750\n","Epoch  1, Batch  87 -Loss:  4599.0938 Validation Accuracy: 0.476562\n","Epoch  1, Batch  88 -Loss:  5247.0605 Validation Accuracy: 0.476562\n","Epoch  1, Batch  89 -Loss:  4160.8921 Validation Accuracy: 0.496094\n","Epoch  1, Batch  90 -Loss:  4773.4136 Validation Accuracy: 0.484375\n","Epoch  1, Batch  91 -Loss:  6004.5103 Validation Accuracy: 0.480469\n","Epoch  1, Batch  92 -Loss:  4375.7817 Validation Accuracy: 0.480469\n","Epoch  1, Batch  93 -Loss:  6052.8467 Validation Accuracy: 0.484375\n","Epoch  1, Batch  94 -Loss:  4068.9709 Validation Accuracy: 0.488281\n","Epoch  1, Batch  95 -Loss:  6073.6699 Validation Accuracy: 0.500000\n","Epoch  1, Batch  96 -Loss:  3943.1196 Validation Accuracy: 0.496094\n","Epoch  1, Batch  97 -Loss:  4149.0947 Validation Accuracy: 0.507812\n","Epoch  1, Batch  98 -Loss:  4633.0176 Validation Accuracy: 0.503906\n","Epoch  1, Batch  99 -Loss:  5773.2207 Validation Accuracy: 0.507812\n","Epoch  1, Batch 100 -Loss:  4659.9980 Validation Accuracy: 0.511719\n","Epoch  1, Batch 101 -Loss:  5258.7998 Validation Accuracy: 0.507812\n","Epoch  1, Batch 102 -Loss:  5377.9736 Validation Accuracy: 0.507812\n","Epoch  1, Batch 103 -Loss:  4325.5566 Validation Accuracy: 0.515625\n","Epoch  1, Batch 104 -Loss:  4428.4014 Validation Accuracy: 0.511719\n","Epoch  1, Batch 105 -Loss:  4207.3481 Validation Accuracy: 0.507812\n","Epoch  1, Batch 106 -Loss:  4292.5903 Validation Accuracy: 0.515625\n","Epoch  1, Batch 107 -Loss:  4338.0391 Validation Accuracy: 0.511719\n","Epoch  1, Batch 108 -Loss:  4118.0825 Validation Accuracy: 0.527344\n","Epoch  1, Batch 109 -Loss:  3437.3000 Validation Accuracy: 0.531250\n","Epoch  1, Batch 110 -Loss:  3846.5247 Validation Accuracy: 0.515625\n","Epoch  1, Batch 111 -Loss:  3768.4810 Validation Accuracy: 0.519531\n","Epoch  1, Batch 112 -Loss:  4252.4805 Validation Accuracy: 0.523438\n","Epoch  1, Batch 113 -Loss:  4299.7930 Validation Accuracy: 0.535156\n","Epoch  1, Batch 114 -Loss:  4094.8506 Validation Accuracy: 0.535156\n","Epoch  1, Batch 115 -Loss:  4344.8394 Validation Accuracy: 0.527344\n","Epoch  1, Batch 116 -Loss:  3984.2593 Validation Accuracy: 0.539062\n","Epoch  1, Batch 117 -Loss:  4376.8789 Validation Accuracy: 0.539062\n","Epoch  1, Batch 118 -Loss:  4160.1108 Validation Accuracy: 0.542969\n","Epoch  1, Batch 119 -Loss:  4052.3560 Validation Accuracy: 0.539062\n","Epoch  1, Batch 120 -Loss:  4759.3750 Validation Accuracy: 0.542969\n","Epoch  1, Batch 121 -Loss:  4114.3848 Validation Accuracy: 0.546875\n","Epoch  1, Batch 122 -Loss:  3224.3877 Validation Accuracy: 0.550781\n","Epoch  1, Batch 123 -Loss:  3305.1484 Validation Accuracy: 0.550781\n","Epoch  1, Batch 124 -Loss:  3562.3857 Validation Accuracy: 0.550781\n","Epoch  1, Batch 125 -Loss:  3681.0132 Validation Accuracy: 0.542969\n","Epoch  1, Batch 126 -Loss:  3348.3823 Validation Accuracy: 0.554688\n","Epoch  1, Batch 127 -Loss:  3428.6082 Validation Accuracy: 0.550781\n","Epoch  1, Batch 128 -Loss:  3271.3037 Validation Accuracy: 0.562500\n","Epoch  1, Batch 129 -Loss:  3184.5176 Validation Accuracy: 0.574219\n","Epoch  1, Batch 130 -Loss:  3197.0979 Validation Accuracy: 0.566406\n","Epoch  1, Batch 131 -Loss:  4537.8145 Validation Accuracy: 0.558594\n","Epoch  1, Batch 132 -Loss:  4186.9385 Validation Accuracy: 0.574219\n","Epoch  1, Batch 133 -Loss:  2851.6802 Validation Accuracy: 0.570312\n","Epoch  1, Batch 134 -Loss:  4458.9385 Validation Accuracy: 0.558594\n","Epoch  1, Batch 135 -Loss:  3458.8672 Validation Accuracy: 0.574219\n","Epoch  1, Batch 136 -Loss:  3698.0322 Validation Accuracy: 0.566406\n","Epoch  1, Batch 137 -Loss:  3262.0811 Validation Accuracy: 0.578125\n","Epoch  1, Batch 138 -Loss:  2681.4189 Validation Accuracy: 0.597656\n","Epoch  1, Batch 139 -Loss:  3243.1396 Validation Accuracy: 0.578125\n","Epoch  1, Batch 140 -Loss:  3578.2771 Validation Accuracy: 0.578125\n","Epoch  1, Batch 141 -Loss:  3741.4709 Validation Accuracy: 0.566406\n","Epoch  1, Batch 142 -Loss:  3994.3506 Validation Accuracy: 0.578125\n","Epoch  1, Batch 143 -Loss:  4043.2383 Validation Accuracy: 0.570312\n","Epoch  1, Batch 144 -Loss:  3066.4392 Validation Accuracy: 0.582031\n","Epoch  1, Batch 145 -Loss:  3215.8530 Validation Accuracy: 0.585938\n","Epoch  1, Batch 146 -Loss:  3542.9180 Validation Accuracy: 0.574219\n","Epoch  1, Batch 147 -Loss:  3366.3853 Validation Accuracy: 0.578125\n","Epoch  1, Batch 148 -Loss:  3400.9739 Validation Accuracy: 0.574219\n","Epoch  1, Batch 149 -Loss:  1902.5632 Validation Accuracy: 0.578125\n","Epoch  1, Batch 150 -Loss:  2678.1265 Validation Accuracy: 0.597656\n","Epoch  1, Batch 151 -Loss:  3254.7439 Validation Accuracy: 0.605469\n","Epoch  1, Batch 152 -Loss:  3523.7205 Validation Accuracy: 0.613281\n","Epoch  1, Batch 153 -Loss:  2366.1099 Validation Accuracy: 0.613281\n","Epoch  1, Batch 154 -Loss:  3736.2302 Validation Accuracy: 0.609375\n","Epoch  1, Batch 155 -Loss:  2824.6143 Validation Accuracy: 0.613281\n","Epoch  1, Batch 156 -Loss:  3439.0752 Validation Accuracy: 0.605469\n","Epoch  1, Batch 157 -Loss:  2221.0986 Validation Accuracy: 0.613281\n","Epoch  1, Batch 158 -Loss:  3885.0134 Validation Accuracy: 0.625000\n","Epoch  1, Batch 159 -Loss:  2723.4509 Validation Accuracy: 0.617188\n","Epoch  1, Batch 160 -Loss:  3666.9219 Validation Accuracy: 0.609375\n","Epoch  1, Batch 161 -Loss:  3146.8223 Validation Accuracy: 0.601562\n","Epoch  1, Batch 162 -Loss:  2553.7820 Validation Accuracy: 0.613281\n","Epoch  1, Batch 163 -Loss:  3360.4756 Validation Accuracy: 0.628906\n","Epoch  1, Batch 164 -Loss:  3150.2642 Validation Accuracy: 0.621094\n","Epoch  1, Batch 165 -Loss:  4159.6724 Validation Accuracy: 0.628906\n","Epoch  1, Batch 166 -Loss:  2991.4819 Validation Accuracy: 0.632812\n","Epoch  1, Batch 167 -Loss:  3476.4736 Validation Accuracy: 0.621094\n","Epoch  1, Batch 168 -Loss:  3271.1157 Validation Accuracy: 0.625000\n","Epoch  1, Batch 169 -Loss:  3915.2275 Validation Accuracy: 0.617188\n","Epoch  1, Batch 170 -Loss:  3941.9092 Validation Accuracy: 0.621094\n","Epoch  1, Batch 171 -Loss:  2846.5491 Validation Accuracy: 0.625000\n","Epoch  1, Batch 172 -Loss:  2080.0784 Validation Accuracy: 0.621094\n","Epoch  1, Batch 173 -Loss:  2792.1228 Validation Accuracy: 0.621094\n","Epoch  1, Batch 174 -Loss:  3329.0273 Validation Accuracy: 0.625000\n","Epoch  1, Batch 175 -Loss:  3229.3037 Validation Accuracy: 0.621094\n","Epoch  1, Batch 176 -Loss:  2600.7600 Validation Accuracy: 0.613281\n","Epoch  1, Batch 177 -Loss:  2988.9780 Validation Accuracy: 0.621094\n","Epoch  1, Batch 178 -Loss:  2743.0527 Validation Accuracy: 0.621094\n","Epoch  1, Batch 179 -Loss:  2540.5232 Validation Accuracy: 0.617188\n","Epoch  1, Batch 180 -Loss:  2474.7166 Validation Accuracy: 0.617188\n","Epoch  1, Batch 181 -Loss:  2388.3857 Validation Accuracy: 0.625000\n","Epoch  1, Batch 182 -Loss:  2413.0752 Validation Accuracy: 0.617188\n","Epoch  1, Batch 183 -Loss:  1978.0654 Validation Accuracy: 0.609375\n","Epoch  1, Batch 184 -Loss:  2427.1729 Validation Accuracy: 0.617188\n","Epoch  1, Batch 185 -Loss:  2043.0073 Validation Accuracy: 0.621094\n","Epoch  1, Batch 186 -Loss:  2559.6492 Validation Accuracy: 0.617188\n","Epoch  1, Batch 187 -Loss:  3028.2212 Validation Accuracy: 0.621094\n","Epoch  1, Batch 188 -Loss:  2324.4690 Validation Accuracy: 0.617188\n","Epoch  1, Batch 189 -Loss:  2578.0249 Validation Accuracy: 0.617188\n","Epoch  1, Batch 190 -Loss:  2239.1550 Validation Accuracy: 0.609375\n","Epoch  1, Batch 191 -Loss:  2923.1882 Validation Accuracy: 0.613281\n","Epoch  1, Batch 192 -Loss:  3873.7729 Validation Accuracy: 0.613281\n","Epoch  1, Batch 193 -Loss:  2860.0850 Validation Accuracy: 0.613281\n","Epoch  1, Batch 194 -Loss:  3059.3828 Validation Accuracy: 0.621094\n","Epoch  1, Batch 195 -Loss:  2783.2202 Validation Accuracy: 0.621094\n","Epoch  1, Batch 196 -Loss:  3399.6597 Validation Accuracy: 0.613281\n","Epoch  1, Batch 197 -Loss:  3300.4424 Validation Accuracy: 0.625000\n","Epoch  1, Batch 198 -Loss:  3149.4312 Validation Accuracy: 0.625000\n","Epoch  1, Batch 199 -Loss:  2872.4912 Validation Accuracy: 0.625000\n","Epoch  1, Batch 200 -Loss:  2451.0254 Validation Accuracy: 0.617188\n","Epoch  1, Batch 201 -Loss:  2668.8359 Validation Accuracy: 0.621094\n","Epoch  1, Batch 202 -Loss:  3584.1042 Validation Accuracy: 0.621094\n","Epoch  1, Batch 203 -Loss:  2134.7976 Validation Accuracy: 0.621094\n","Epoch  1, Batch 204 -Loss:  1984.3496 Validation Accuracy: 0.628906\n","Epoch  1, Batch 205 -Loss:  2339.5554 Validation Accuracy: 0.628906\n","Epoch  1, Batch 206 -Loss:  2709.0015 Validation Accuracy: 0.640625\n","Epoch  1, Batch 207 -Loss:  2553.5229 Validation Accuracy: 0.628906\n","Epoch  1, Batch 208 -Loss:  1917.5762 Validation Accuracy: 0.632812\n","Epoch  1, Batch 209 -Loss:  3005.0256 Validation Accuracy: 0.644531\n","Epoch  1, Batch 210 -Loss:  2431.8350 Validation Accuracy: 0.640625\n","Epoch  1, Batch 211 -Loss:  2244.7898 Validation Accuracy: 0.636719\n","Epoch  1, Batch 212 -Loss:  2087.6062 Validation Accuracy: 0.640625\n","Epoch  1, Batch 213 -Loss:  2572.7739 Validation Accuracy: 0.632812\n","Epoch  1, Batch 214 -Loss:  2094.8655 Validation Accuracy: 0.636719\n","Epoch  1, Batch 215 -Loss:  2216.7417 Validation Accuracy: 0.640625\n","Epoch  1, Batch 216 -Loss:  2645.5627 Validation Accuracy: 0.640625\n","Epoch  1, Batch 217 -Loss:  1808.3287 Validation Accuracy: 0.640625\n","Epoch  1, Batch 218 -Loss:  2565.5576 Validation Accuracy: 0.644531\n","Epoch  1, Batch 219 -Loss:  2165.0586 Validation Accuracy: 0.636719\n","Epoch  1, Batch 220 -Loss:  2145.8467 Validation Accuracy: 0.628906\n","Epoch  1, Batch 221 -Loss:  2363.2234 Validation Accuracy: 0.632812\n","Epoch  1, Batch 222 -Loss:  2105.8240 Validation Accuracy: 0.632812\n","Epoch  1, Batch 223 -Loss:  1419.5839 Validation Accuracy: 0.628906\n","Epoch  1, Batch 224 -Loss:  2495.1887 Validation Accuracy: 0.632812\n","Epoch  1, Batch 225 -Loss:  2034.1987 Validation Accuracy: 0.628906\n","Epoch  1, Batch 226 -Loss:  2643.6221 Validation Accuracy: 0.628906\n","Epoch  1, Batch 227 -Loss:  2726.2273 Validation Accuracy: 0.644531\n","Epoch  1, Batch 228 -Loss:  2510.2632 Validation Accuracy: 0.664062\n","Epoch  1, Batch 229 -Loss:  2342.3757 Validation Accuracy: 0.664062\n","Epoch  1, Batch 230 -Loss:  1342.8625 Validation Accuracy: 0.656250\n","Epoch  1, Batch 231 -Loss:  1876.4771 Validation Accuracy: 0.648438\n","Epoch  1, Batch 232 -Loss:  1634.0261 Validation Accuracy: 0.652344\n","Epoch  1, Batch 233 -Loss:  2088.8401 Validation Accuracy: 0.652344\n","Epoch  1, Batch 234 -Loss:  2313.9751 Validation Accuracy: 0.656250\n","Epoch  1, Batch 235 -Loss:  2599.3159 Validation Accuracy: 0.652344\n","Epoch  1, Batch 236 -Loss:  1985.3831 Validation Accuracy: 0.648438\n","Epoch  1, Batch 237 -Loss:  2089.4775 Validation Accuracy: 0.644531\n","Epoch  1, Batch 238 -Loss:  2269.2432 Validation Accuracy: 0.648438\n","Epoch  1, Batch 239 -Loss:  1911.0380 Validation Accuracy: 0.648438\n","Epoch  1, Batch 240 -Loss:  1819.0751 Validation Accuracy: 0.652344\n","Epoch  1, Batch 241 -Loss:  1573.3826 Validation Accuracy: 0.664062\n","Epoch  1, Batch 242 -Loss:  1741.1716 Validation Accuracy: 0.652344\n","Epoch  1, Batch 243 -Loss:  2091.7942 Validation Accuracy: 0.656250\n","Epoch  1, Batch 244 -Loss:  2617.4556 Validation Accuracy: 0.660156\n","Epoch  1, Batch 245 -Loss:  2176.0474 Validation Accuracy: 0.648438\n","Epoch  1, Batch 246 -Loss:  1607.5605 Validation Accuracy: 0.648438\n","Epoch  1, Batch 247 -Loss:  2157.6230 Validation Accuracy: 0.648438\n","Epoch  1, Batch 248 -Loss:  1895.1973 Validation Accuracy: 0.656250\n","Epoch  1, Batch 249 -Loss:  2287.0728 Validation Accuracy: 0.656250\n","Epoch  1, Batch 250 -Loss:  1703.4789 Validation Accuracy: 0.664062\n","Epoch  1, Batch 251 -Loss:  2364.5215 Validation Accuracy: 0.660156\n","Epoch  1, Batch 252 -Loss:  3055.2729 Validation Accuracy: 0.667969\n","Epoch  1, Batch 253 -Loss:  2083.9380 Validation Accuracy: 0.671875\n","Epoch  1, Batch 254 -Loss:  2027.3279 Validation Accuracy: 0.667969\n","Epoch  1, Batch 255 -Loss:  1844.0841 Validation Accuracy: 0.664062\n","Epoch  1, Batch 256 -Loss:  2144.7930 Validation Accuracy: 0.667969\n","Epoch  1, Batch 257 -Loss:  1865.1080 Validation Accuracy: 0.664062\n","Epoch  1, Batch 258 -Loss:  1825.9443 Validation Accuracy: 0.675781\n","Epoch  1, Batch 259 -Loss:  2219.5503 Validation Accuracy: 0.660156\n","Epoch  1, Batch 260 -Loss:  2865.0962 Validation Accuracy: 0.667969\n","Epoch  1, Batch 261 -Loss:  1436.9064 Validation Accuracy: 0.671875\n","Epoch  1, Batch 262 -Loss:  2364.0684 Validation Accuracy: 0.667969\n","Epoch  1, Batch 263 -Loss:  2069.8582 Validation Accuracy: 0.675781\n","Epoch  1, Batch 264 -Loss:  1797.8218 Validation Accuracy: 0.671875\n","Epoch  1, Batch 265 -Loss:  2059.5708 Validation Accuracy: 0.675781\n","Epoch  1, Batch 266 -Loss:  2501.6160 Validation Accuracy: 0.691406\n","Epoch  1, Batch 267 -Loss:  1710.1807 Validation Accuracy: 0.667969\n","Epoch  1, Batch 268 -Loss:  1842.8198 Validation Accuracy: 0.675781\n","Epoch  1, Batch 269 -Loss:  2127.2522 Validation Accuracy: 0.671875\n","Epoch  1, Batch 270 -Loss:  2279.5986 Validation Accuracy: 0.667969\n","Epoch  1, Batch 271 -Loss:  2154.7981 Validation Accuracy: 0.671875\n","Epoch  1, Batch 272 -Loss:  2547.1880 Validation Accuracy: 0.683594\n","Epoch  1, Batch 273 -Loss:  1713.4933 Validation Accuracy: 0.679688\n","Epoch  1, Batch 274 -Loss:  1968.0234 Validation Accuracy: 0.679688\n","Epoch  1, Batch 275 -Loss:  1841.1873 Validation Accuracy: 0.675781\n","Epoch  1, Batch 276 -Loss:  1687.3417 Validation Accuracy: 0.675781\n","Epoch  1, Batch 277 -Loss:  2258.6875 Validation Accuracy: 0.687500\n","Epoch  1, Batch 278 -Loss:  1846.0892 Validation Accuracy: 0.671875\n","Epoch  1, Batch 279 -Loss:  1586.9723 Validation Accuracy: 0.671875\n","Epoch  1, Batch 280 -Loss:  1829.3000 Validation Accuracy: 0.675781\n","Epoch  1, Batch 281 -Loss:  1683.5122 Validation Accuracy: 0.683594\n","Epoch  1, Batch 282 -Loss:  2210.4414 Validation Accuracy: 0.683594\n","Epoch  1, Batch 283 -Loss:  2046.3545 Validation Accuracy: 0.679688\n","Epoch  1, Batch 284 -Loss:  2079.7485 Validation Accuracy: 0.671875\n","Epoch  1, Batch 285 -Loss:  1560.3228 Validation Accuracy: 0.671875\n","Epoch  1, Batch 286 -Loss:  1934.5870 Validation Accuracy: 0.683594\n","Epoch  1, Batch 287 -Loss:  1546.4717 Validation Accuracy: 0.687500\n","Epoch  1, Batch 288 -Loss:  1436.7864 Validation Accuracy: 0.691406\n","Epoch  1, Batch 289 -Loss:  1759.8518 Validation Accuracy: 0.695312\n","Epoch  1, Batch 290 -Loss:  1932.2766 Validation Accuracy: 0.675781\n","Epoch  1, Batch 291 -Loss:  2290.1191 Validation Accuracy: 0.675781\n","Epoch  1, Batch 292 -Loss:  2184.8979 Validation Accuracy: 0.679688\n","Epoch  1, Batch 293 -Loss:  1550.1079 Validation Accuracy: 0.691406\n","Epoch  1, Batch 294 -Loss:  1763.7366 Validation Accuracy: 0.691406\n","Epoch  1, Batch 295 -Loss:  1454.2135 Validation Accuracy: 0.687500\n","Epoch  1, Batch 296 -Loss:  1612.5085 Validation Accuracy: 0.691406\n","Epoch  1, Batch 297 -Loss:  1213.8665 Validation Accuracy: 0.695312\n","Epoch  1, Batch 298 -Loss:  1702.7474 Validation Accuracy: 0.695312\n","Epoch  1, Batch 299 -Loss:  1587.1162 Validation Accuracy: 0.691406\n","Epoch  1, Batch 300 -Loss:  1828.3184 Validation Accuracy: 0.695312\n","Epoch  1, Batch 301 -Loss:  1284.7444 Validation Accuracy: 0.691406\n","Epoch  1, Batch 302 -Loss:  1431.5474 Validation Accuracy: 0.695312\n","Epoch  1, Batch 303 -Loss:  1595.6250 Validation Accuracy: 0.691406\n","Epoch  1, Batch 304 -Loss:  2240.0903 Validation Accuracy: 0.687500\n","Epoch  1, Batch 305 -Loss:  1699.5841 Validation Accuracy: 0.679688\n","Epoch  1, Batch 306 -Loss:  1718.4246 Validation Accuracy: 0.687500\n","Epoch  1, Batch 307 -Loss:  1185.2428 Validation Accuracy: 0.687500\n","Epoch  1, Batch 308 -Loss:  1639.5809 Validation Accuracy: 0.687500\n","Epoch  1, Batch 309 -Loss:  1679.1667 Validation Accuracy: 0.687500\n","Epoch  1, Batch 310 -Loss:  1732.5337 Validation Accuracy: 0.687500\n","Epoch  1, Batch 311 -Loss:  1327.2637 Validation Accuracy: 0.687500\n","Epoch  1, Batch 312 -Loss:  1636.6486 Validation Accuracy: 0.683594\n","Epoch  1, Batch 313 -Loss:  1860.8748 Validation Accuracy: 0.679688\n","Epoch  1, Batch 314 -Loss:  1593.1423 Validation Accuracy: 0.679688\n","Epoch  1, Batch 315 -Loss:  1862.5271 Validation Accuracy: 0.691406\n","Epoch  1, Batch 316 -Loss:  1704.3430 Validation Accuracy: 0.683594\n","Epoch  1, Batch 317 -Loss:  2071.9497 Validation Accuracy: 0.679688\n","Epoch  1, Batch 318 -Loss:  1842.2092 Validation Accuracy: 0.683594\n","Epoch  1, Batch 319 -Loss:  1930.4327 Validation Accuracy: 0.683594\n","Epoch  1, Batch 320 -Loss:  1765.5645 Validation Accuracy: 0.683594\n","Epoch  1, Batch 321 -Loss:  1343.5917 Validation Accuracy: 0.683594\n","Epoch  1, Batch 322 -Loss:  1489.5698 Validation Accuracy: 0.687500\n","Epoch  1, Batch 323 -Loss:  1771.7039 Validation Accuracy: 0.679688\n","Epoch  1, Batch 324 -Loss:  2130.5195 Validation Accuracy: 0.679688\n","Epoch  1, Batch 325 -Loss:  1477.8640 Validation Accuracy: 0.679688\n","Epoch  1, Batch 326 -Loss:  1763.7001 Validation Accuracy: 0.683594\n","Epoch  1, Batch 327 -Loss:  1779.3301 Validation Accuracy: 0.687500\n","Epoch  1, Batch 328 -Loss:  1579.3110 Validation Accuracy: 0.679688\n","Epoch  1, Batch 329 -Loss:  1365.9734 Validation Accuracy: 0.699219\n","Epoch  1, Batch 330 -Loss:  1565.9231 Validation Accuracy: 0.687500\n","Epoch  1, Batch 331 -Loss:  1616.6257 Validation Accuracy: 0.683594\n","Epoch  1, Batch 332 -Loss:  1356.0596 Validation Accuracy: 0.687500\n","Epoch  1, Batch 333 -Loss:  1402.2229 Validation Accuracy: 0.683594\n","Epoch  1, Batch 334 -Loss:  1798.5190 Validation Accuracy: 0.687500\n","Epoch  1, Batch 335 -Loss:  1197.9204 Validation Accuracy: 0.691406\n","Epoch  1, Batch 336 -Loss:  1888.1775 Validation Accuracy: 0.691406\n","Epoch  1, Batch 337 -Loss:  1030.6920 Validation Accuracy: 0.679688\n","Epoch  1, Batch 338 -Loss:  2041.2937 Validation Accuracy: 0.687500\n","Epoch  1, Batch 339 -Loss:  1606.1019 Validation Accuracy: 0.683594\n","Epoch  1, Batch 340 -Loss:  1262.9529 Validation Accuracy: 0.683594\n","Epoch  1, Batch 341 -Loss:  1887.5684 Validation Accuracy: 0.687500\n","Epoch  1, Batch 342 -Loss:  1520.2628 Validation Accuracy: 0.691406\n","Epoch  1, Batch 343 -Loss:  1448.9259 Validation Accuracy: 0.699219\n","Epoch  1, Batch 344 -Loss:  1068.7117 Validation Accuracy: 0.691406\n","Epoch  1, Batch 345 -Loss:  1363.6470 Validation Accuracy: 0.683594\n","Epoch  1, Batch 346 -Loss:  1778.2577 Validation Accuracy: 0.687500\n","Epoch  1, Batch 347 -Loss:  1868.0697 Validation Accuracy: 0.695312\n","Epoch  1, Batch 348 -Loss:   932.9600 Validation Accuracy: 0.691406\n","Epoch  1, Batch 349 -Loss:  1563.2036 Validation Accuracy: 0.695312\n","Epoch  1, Batch 350 -Loss:  1707.5891 Validation Accuracy: 0.695312\n","Epoch  1, Batch 351 -Loss:  2080.7114 Validation Accuracy: 0.703125\n","Epoch  1, Batch 352 -Loss:  1409.6643 Validation Accuracy: 0.710938\n","Epoch  1, Batch 353 -Loss:   948.2988 Validation Accuracy: 0.707031\n","Epoch  1, Batch 354 -Loss:  1782.3967 Validation Accuracy: 0.714844\n","Epoch  1, Batch 355 -Loss:  1167.4788 Validation Accuracy: 0.714844\n","Epoch  1, Batch 356 -Loss:  1502.8892 Validation Accuracy: 0.703125\n","Epoch  1, Batch 357 -Loss:  1717.2135 Validation Accuracy: 0.699219\n","Epoch  1, Batch 358 -Loss:  1544.5872 Validation Accuracy: 0.699219\n","Epoch  1, Batch 359 -Loss:  1704.0276 Validation Accuracy: 0.707031\n","Epoch  1, Batch 360 -Loss:  1407.8711 Validation Accuracy: 0.710938\n","Epoch  1, Batch 361 -Loss:  1384.8762 Validation Accuracy: 0.703125\n","Epoch  1, Batch 362 -Loss:  1729.3655 Validation Accuracy: 0.703125\n","Epoch  1, Batch 363 -Loss:  1759.9167 Validation Accuracy: 0.695312\n","Epoch  1, Batch 364 -Loss:  1070.8654 Validation Accuracy: 0.699219\n","Epoch  1, Batch 365 -Loss:  1458.0637 Validation Accuracy: 0.695312\n","Epoch  1, Batch 366 -Loss:  1715.7368 Validation Accuracy: 0.695312\n","Epoch  1, Batch 367 -Loss:  1383.9133 Validation Accuracy: 0.695312\n","Epoch  1, Batch 368 -Loss:  1544.0469 Validation Accuracy: 0.699219\n","Epoch  1, Batch 369 -Loss:  1614.3391 Validation Accuracy: 0.699219\n","Epoch  1, Batch 370 -Loss:   883.6216 Validation Accuracy: 0.714844\n","Epoch  1, Batch 371 -Loss:  1775.9045 Validation Accuracy: 0.710938\n","Epoch  1, Batch 372 -Loss:  1541.7039 Validation Accuracy: 0.687500\n","Epoch  1, Batch 373 -Loss:  1300.3372 Validation Accuracy: 0.707031\n","Epoch  1, Batch 374 -Loss:  1359.7863 Validation Accuracy: 0.710938\n","Epoch  1, Batch 375 -Loss:  1619.4153 Validation Accuracy: 0.710938\n","Epoch  1, Batch 376 -Loss:  1012.8278 Validation Accuracy: 0.707031\n","Epoch  1, Batch 377 -Loss:  1617.8455 Validation Accuracy: 0.714844\n","Epoch  1, Batch 378 -Loss:  1152.9895 Validation Accuracy: 0.710938\n","Epoch  1, Batch 379 -Loss:  1385.2029 Validation Accuracy: 0.707031\n","Epoch  1, Batch 380 -Loss:  1695.0562 Validation Accuracy: 0.718750\n","Epoch  1, Batch 381 -Loss:  1682.7452 Validation Accuracy: 0.714844\n","Epoch  1, Batch 382 -Loss:   963.3195 Validation Accuracy: 0.722656\n","Epoch  1, Batch 383 -Loss:  1689.7441 Validation Accuracy: 0.714844\n","Epoch  1, Batch 384 -Loss:  1335.4590 Validation Accuracy: 0.714844\n","Epoch  1, Batch 385 -Loss:  1440.0402 Validation Accuracy: 0.714844\n","Epoch  1, Batch 386 -Loss:   657.8396 Validation Accuracy: 0.710938\n","Epoch  1, Batch 387 -Loss:  1528.1823 Validation Accuracy: 0.707031\n","Epoch  1, Batch 388 -Loss:  1542.7185 Validation Accuracy: 0.707031\n","Epoch  1, Batch 389 -Loss:  1663.1974 Validation Accuracy: 0.710938\n","Epoch  1, Batch 390 -Loss:   919.8491 Validation Accuracy: 0.707031\n","Epoch  1, Batch 391 -Loss:  1473.1089 Validation Accuracy: 0.710938\n","Epoch  1, Batch 392 -Loss:   914.8317 Validation Accuracy: 0.714844\n","Epoch  1, Batch 393 -Loss:   959.4366 Validation Accuracy: 0.714844\n","Epoch  1, Batch 394 -Loss:   970.6317 Validation Accuracy: 0.714844\n","Epoch  1, Batch 395 -Loss:  1420.7689 Validation Accuracy: 0.714844\n","Epoch  1, Batch 396 -Loss:  1247.2014 Validation Accuracy: 0.710938\n","Epoch  1, Batch 397 -Loss:  1060.0419 Validation Accuracy: 0.718750\n","Epoch  1, Batch 398 -Loss:  1410.1499 Validation Accuracy: 0.714844\n","Epoch  1, Batch 399 -Loss:  1367.4523 Validation Accuracy: 0.722656\n","Epoch  1, Batch 400 -Loss:  1429.3893 Validation Accuracy: 0.726562\n","Epoch  1, Batch 401 -Loss:  1510.5035 Validation Accuracy: 0.730469\n","Epoch  1, Batch 402 -Loss:  1069.6840 Validation Accuracy: 0.730469\n","Epoch  1, Batch 403 -Loss:  1126.8984 Validation Accuracy: 0.738281\n","Epoch  1, Batch 404 -Loss:  1529.2769 Validation Accuracy: 0.730469\n","Epoch  1, Batch 405 -Loss:  1307.9580 Validation Accuracy: 0.730469\n","Epoch  1, Batch 406 -Loss:  1477.9843 Validation Accuracy: 0.730469\n","Epoch  1, Batch 407 -Loss:  1262.4636 Validation Accuracy: 0.714844\n","Epoch  1, Batch 408 -Loss:  1614.0842 Validation Accuracy: 0.710938\n","Epoch  1, Batch 409 -Loss:  1675.1259 Validation Accuracy: 0.699219\n","Epoch  1, Batch 410 -Loss:  1479.8472 Validation Accuracy: 0.695312\n","Epoch  1, Batch 411 -Loss:  1036.3496 Validation Accuracy: 0.695312\n","Epoch  1, Batch 412 -Loss:  1736.3549 Validation Accuracy: 0.703125\n","Epoch  1, Batch 413 -Loss:  1314.0645 Validation Accuracy: 0.707031\n","Epoch  1, Batch 414 -Loss:  1232.3044 Validation Accuracy: 0.722656\n","Epoch  1, Batch 415 -Loss:   901.0984 Validation Accuracy: 0.714844\n","Epoch  1, Batch 416 -Loss:  1777.1793 Validation Accuracy: 0.707031\n","Epoch  1, Batch 417 -Loss:  1233.0428 Validation Accuracy: 0.710938\n","Epoch  1, Batch 418 -Loss:  1334.7512 Validation Accuracy: 0.718750\n","Epoch  1, Batch 419 -Loss:  1398.1313 Validation Accuracy: 0.718750\n","Epoch  1, Batch 420 -Loss:  1743.9312 Validation Accuracy: 0.730469\n","Epoch  1, Batch 421 -Loss:  1536.7913 Validation Accuracy: 0.730469\n","Epoch  1, Batch 422 -Loss:  1303.1564 Validation Accuracy: 0.714844\n","Epoch  1, Batch 423 -Loss:  1475.0972 Validation Accuracy: 0.722656\n","Epoch  1, Batch 424 -Loss:  1015.2343 Validation Accuracy: 0.722656\n","Epoch  1, Batch 425 -Loss:  1250.7896 Validation Accuracy: 0.730469\n","Epoch  1, Batch 426 -Loss:   985.4417 Validation Accuracy: 0.734375\n","Epoch  1, Batch 427 -Loss:  1147.5693 Validation Accuracy: 0.726562\n","Epoch  1, Batch 428 -Loss:  1380.3816 Validation Accuracy: 0.730469\n","Epoch  1, Batch 429 -Loss:  1452.7833 Validation Accuracy: 0.730469\n","Epoch  2, Batch   1 -Loss:  1191.7024 Validation Accuracy: 0.718750\n","Epoch  2, Batch   2 -Loss:  1286.8467 Validation Accuracy: 0.726562\n","Epoch  2, Batch   3 -Loss:   978.7511 Validation Accuracy: 0.730469\n","Epoch  2, Batch   4 -Loss:   880.0738 Validation Accuracy: 0.730469\n","Epoch  2, Batch   5 -Loss:  1074.5786 Validation Accuracy: 0.726562\n","Epoch  2, Batch   6 -Loss:  1607.7004 Validation Accuracy: 0.734375\n","Epoch  2, Batch   7 -Loss:  1326.8575 Validation Accuracy: 0.734375\n","Epoch  2, Batch   8 -Loss:  1930.7657 Validation Accuracy: 0.734375\n","Epoch  2, Batch   9 -Loss:  1119.7069 Validation Accuracy: 0.738281\n","Epoch  2, Batch  10 -Loss:   785.1014 Validation Accuracy: 0.738281\n","Epoch  2, Batch  11 -Loss:  1369.7063 Validation Accuracy: 0.738281\n","Epoch  2, Batch  12 -Loss:  1029.1785 Validation Accuracy: 0.738281\n","Epoch  2, Batch  13 -Loss:  1020.9160 Validation Accuracy: 0.738281\n","Epoch  2, Batch  14 -Loss:   882.4622 Validation Accuracy: 0.738281\n","Epoch  2, Batch  15 -Loss:  1262.1674 Validation Accuracy: 0.738281\n","Epoch  2, Batch  16 -Loss:  1281.2994 Validation Accuracy: 0.734375\n","Epoch  2, Batch  17 -Loss:  1327.6373 Validation Accuracy: 0.718750\n","Epoch  2, Batch  18 -Loss:  1540.1595 Validation Accuracy: 0.726562\n","Epoch  2, Batch  19 -Loss:  1256.3414 Validation Accuracy: 0.726562\n","Epoch  2, Batch  20 -Loss:  1765.6259 Validation Accuracy: 0.714844\n","Epoch  2, Batch  21 -Loss:  1749.0176 Validation Accuracy: 0.722656\n","Epoch  2, Batch  22 -Loss:  1568.3798 Validation Accuracy: 0.726562\n","Epoch  2, Batch  23 -Loss:  1428.9995 Validation Accuracy: 0.726562\n","Epoch  2, Batch  24 -Loss:   914.4475 Validation Accuracy: 0.734375\n","Epoch  2, Batch  25 -Loss:  1087.1809 Validation Accuracy: 0.734375\n","Epoch  2, Batch  26 -Loss:  1574.2540 Validation Accuracy: 0.734375\n","Epoch  2, Batch  27 -Loss:   848.2794 Validation Accuracy: 0.730469\n","Epoch  2, Batch  28 -Loss:  1255.1907 Validation Accuracy: 0.738281\n","Epoch  2, Batch  29 -Loss:  1568.0522 Validation Accuracy: 0.734375\n","Epoch  2, Batch  30 -Loss:  1542.2407 Validation Accuracy: 0.738281\n","Epoch  2, Batch  31 -Loss:  1682.2151 Validation Accuracy: 0.726562\n","Epoch  2, Batch  32 -Loss:  1283.6378 Validation Accuracy: 0.722656\n","Epoch  2, Batch  33 -Loss:  1623.5989 Validation Accuracy: 0.726562\n","Epoch  2, Batch  34 -Loss:  1413.3425 Validation Accuracy: 0.726562\n","Epoch  2, Batch  35 -Loss:  1393.8339 Validation Accuracy: 0.730469\n","Epoch  2, Batch  36 -Loss:  1262.3628 Validation Accuracy: 0.730469\n","Epoch  2, Batch  37 -Loss:   966.0645 Validation Accuracy: 0.742188\n","Epoch  2, Batch  38 -Loss:  1335.4775 Validation Accuracy: 0.734375\n","Epoch  2, Batch  39 -Loss:  1067.1853 Validation Accuracy: 0.738281\n","Epoch  2, Batch  40 -Loss:  1068.5948 Validation Accuracy: 0.746094\n","Epoch  2, Batch  41 -Loss:  1046.1356 Validation Accuracy: 0.738281\n","Epoch  2, Batch  42 -Loss:  1121.7125 Validation Accuracy: 0.734375\n","Epoch  2, Batch  43 -Loss:  1042.5260 Validation Accuracy: 0.734375\n","Epoch  2, Batch  44 -Loss:  1229.6589 Validation Accuracy: 0.734375\n","Epoch  2, Batch  45 -Loss:  1012.0356 Validation Accuracy: 0.734375\n","Epoch  2, Batch  46 -Loss:  1610.7206 Validation Accuracy: 0.730469\n","Epoch  2, Batch  47 -Loss:  1333.4421 Validation Accuracy: 0.742188\n","Epoch  2, Batch  48 -Loss:   918.3493 Validation Accuracy: 0.742188\n","Epoch  2, Batch  49 -Loss:  1583.8546 Validation Accuracy: 0.742188\n","Epoch  2, Batch  50 -Loss:  1422.4891 Validation Accuracy: 0.746094\n","Epoch  2, Batch  51 -Loss:   760.0671 Validation Accuracy: 0.742188\n","Epoch  2, Batch  52 -Loss:  1583.9330 Validation Accuracy: 0.746094\n","Epoch  2, Batch  53 -Loss:  1060.3350 Validation Accuracy: 0.750000\n","Epoch  2, Batch  54 -Loss:  1051.3600 Validation Accuracy: 0.746094\n","Epoch  2, Batch  55 -Loss:  1326.1914 Validation Accuracy: 0.750000\n","Epoch  2, Batch  56 -Loss:  1241.8186 Validation Accuracy: 0.742188\n","Epoch  2, Batch  57 -Loss:  1462.8380 Validation Accuracy: 0.753906\n","Epoch  2, Batch  58 -Loss:  1180.1859 Validation Accuracy: 0.746094\n","Epoch  2, Batch  59 -Loss:  1172.2255 Validation Accuracy: 0.742188\n","Epoch  2, Batch  60 -Loss:   918.8057 Validation Accuracy: 0.742188\n","Epoch  2, Batch  61 -Loss:  1247.8967 Validation Accuracy: 0.742188\n","Epoch  2, Batch  62 -Loss:  1413.0151 Validation Accuracy: 0.742188\n","Epoch  2, Batch  63 -Loss:  1503.0828 Validation Accuracy: 0.746094\n","Epoch  2, Batch  64 -Loss:  1374.3447 Validation Accuracy: 0.742188\n","Epoch  2, Batch  65 -Loss:  1334.4872 Validation Accuracy: 0.746094\n","Epoch  2, Batch  66 -Loss:   928.0068 Validation Accuracy: 0.746094\n","Epoch  2, Batch  67 -Loss:   984.5452 Validation Accuracy: 0.742188\n","Epoch  2, Batch  68 -Loss:  1437.5964 Validation Accuracy: 0.746094\n","Epoch  2, Batch  69 -Loss:  1267.9318 Validation Accuracy: 0.746094\n","Epoch  2, Batch  70 -Loss:  1184.1580 Validation Accuracy: 0.746094\n","Epoch  2, Batch  71 -Loss:  1486.9204 Validation Accuracy: 0.750000\n","Epoch  2, Batch  72 -Loss:  1019.0525 Validation Accuracy: 0.746094\n","Epoch  2, Batch  73 -Loss:   886.7067 Validation Accuracy: 0.753906\n","Epoch  2, Batch  74 -Loss:  1235.0056 Validation Accuracy: 0.750000\n","Epoch  2, Batch  75 -Loss:  1012.2678 Validation Accuracy: 0.746094\n","Epoch  2, Batch  76 -Loss:  1326.8436 Validation Accuracy: 0.753906\n","Epoch  2, Batch  77 -Loss:   559.6336 Validation Accuracy: 0.753906\n","Epoch  2, Batch  78 -Loss:  1175.7920 Validation Accuracy: 0.753906\n","Epoch  2, Batch  79 -Loss:  1153.7650 Validation Accuracy: 0.750000\n","Epoch  2, Batch  80 -Loss:  1197.1760 Validation Accuracy: 0.753906\n","Epoch  2, Batch  81 -Loss:  1063.2675 Validation Accuracy: 0.757812\n","Epoch  2, Batch  82 -Loss:  1040.6212 Validation Accuracy: 0.757812\n","Epoch  2, Batch  83 -Loss:  1203.6653 Validation Accuracy: 0.757812\n","Epoch  2, Batch  84 -Loss:  1392.2432 Validation Accuracy: 0.761719\n","Epoch  2, Batch  85 -Loss:  1320.7916 Validation Accuracy: 0.757812\n","Epoch  2, Batch  86 -Loss:  1173.4866 Validation Accuracy: 0.757812\n","Epoch  2, Batch  87 -Loss:  1270.6544 Validation Accuracy: 0.757812\n","Epoch  2, Batch  88 -Loss:  1014.4608 Validation Accuracy: 0.753906\n","Epoch  2, Batch  89 -Loss:  1067.6847 Validation Accuracy: 0.761719\n","Epoch  2, Batch  90 -Loss:   615.0026 Validation Accuracy: 0.761719\n","Epoch  2, Batch  91 -Loss:  1526.3389 Validation Accuracy: 0.746094\n","Epoch  2, Batch  92 -Loss:  1357.0494 Validation Accuracy: 0.742188\n","Epoch  2, Batch  93 -Loss:   884.1506 Validation Accuracy: 0.750000\n","Epoch  2, Batch  94 -Loss:   927.4446 Validation Accuracy: 0.746094\n","Epoch  2, Batch  95 -Loss:  1232.2510 Validation Accuracy: 0.750000\n","Epoch  2, Batch  96 -Loss:  1384.8236 Validation Accuracy: 0.753906\n","Epoch  2, Batch  97 -Loss:   745.8271 Validation Accuracy: 0.753906\n","Epoch  2, Batch  98 -Loss:   809.4257 Validation Accuracy: 0.750000\n","Epoch  2, Batch  99 -Loss:   977.2287 Validation Accuracy: 0.753906\n","Epoch  2, Batch 100 -Loss:   974.2031 Validation Accuracy: 0.753906\n","Epoch  2, Batch 101 -Loss:  1195.9003 Validation Accuracy: 0.761719\n","Epoch  2, Batch 102 -Loss:  1360.5078 Validation Accuracy: 0.765625\n","Epoch  2, Batch 103 -Loss:  1173.7098 Validation Accuracy: 0.761719\n","Epoch  2, Batch 104 -Loss:  1408.3535 Validation Accuracy: 0.765625\n","Epoch  2, Batch 105 -Loss:  1079.7759 Validation Accuracy: 0.765625\n","Epoch  2, Batch 106 -Loss:   846.4344 Validation Accuracy: 0.765625\n","Epoch  2, Batch 107 -Loss:  1339.9983 Validation Accuracy: 0.761719\n","Epoch  2, Batch 108 -Loss:   981.1050 Validation Accuracy: 0.761719\n","Epoch  2, Batch 109 -Loss:   884.6007 Validation Accuracy: 0.761719\n","Epoch  2, Batch 110 -Loss:   955.7291 Validation Accuracy: 0.761719\n","Epoch  2, Batch 111 -Loss:   854.5158 Validation Accuracy: 0.765625\n","Epoch  2, Batch 112 -Loss:   825.2600 Validation Accuracy: 0.765625\n","Epoch  2, Batch 113 -Loss:  1361.4773 Validation Accuracy: 0.761719\n","Epoch  2, Batch 114 -Loss:  1342.1366 Validation Accuracy: 0.769531\n","Epoch  2, Batch 115 -Loss:  1057.2524 Validation Accuracy: 0.765625\n","Epoch  2, Batch 116 -Loss:  1094.3748 Validation Accuracy: 0.761719\n","Epoch  2, Batch 117 -Loss:  1216.7535 Validation Accuracy: 0.757812\n","Epoch  2, Batch 118 -Loss:  1145.4558 Validation Accuracy: 0.761719\n","Epoch  2, Batch 119 -Loss:  1042.6517 Validation Accuracy: 0.765625\n","Epoch  2, Batch 120 -Loss:  1401.9585 Validation Accuracy: 0.765625\n","Epoch  2, Batch 121 -Loss:  1094.3667 Validation Accuracy: 0.761719\n","Epoch  2, Batch 122 -Loss:  1034.5626 Validation Accuracy: 0.761719\n","Epoch  2, Batch 123 -Loss:  1276.0604 Validation Accuracy: 0.769531\n","Epoch  2, Batch 124 -Loss:  1099.4731 Validation Accuracy: 0.765625\n","Epoch  2, Batch 125 -Loss:  1167.6084 Validation Accuracy: 0.773438\n","Epoch  2, Batch 126 -Loss:   987.1710 Validation Accuracy: 0.769531\n","Epoch  2, Batch 127 -Loss:  1452.6010 Validation Accuracy: 0.769531\n","Epoch  2, Batch 128 -Loss:   802.5592 Validation Accuracy: 0.773438\n","Epoch  2, Batch 129 -Loss:   997.8958 Validation Accuracy: 0.773438\n","Epoch  2, Batch 130 -Loss:  1244.2117 Validation Accuracy: 0.769531\n","Epoch  2, Batch 131 -Loss:   979.7950 Validation Accuracy: 0.773438\n","Epoch  2, Batch 132 -Loss:  1184.7994 Validation Accuracy: 0.769531\n","Epoch  2, Batch 133 -Loss:  1174.9204 Validation Accuracy: 0.757812\n","Epoch  2, Batch 134 -Loss:   876.1222 Validation Accuracy: 0.765625\n","Epoch  2, Batch 135 -Loss:   626.3301 Validation Accuracy: 0.757812\n","Epoch  2, Batch 136 -Loss:   662.3398 Validation Accuracy: 0.773438\n","Epoch  2, Batch 137 -Loss:   974.5869 Validation Accuracy: 0.773438\n","Epoch  2, Batch 138 -Loss:   538.8649 Validation Accuracy: 0.777344\n","Epoch  2, Batch 139 -Loss:  1016.0328 Validation Accuracy: 0.773438\n","Epoch  2, Batch 140 -Loss:  1179.0659 Validation Accuracy: 0.773438\n","Epoch  2, Batch 141 -Loss:   883.8734 Validation Accuracy: 0.777344\n","Epoch  2, Batch 142 -Loss:   889.8591 Validation Accuracy: 0.777344\n","Epoch  2, Batch 143 -Loss:  1226.7975 Validation Accuracy: 0.777344\n","Epoch  2, Batch 144 -Loss:  1103.5796 Validation Accuracy: 0.777344\n","Epoch  2, Batch 145 -Loss:  1025.0560 Validation Accuracy: 0.769531\n","Epoch  2, Batch 146 -Loss:  1295.1982 Validation Accuracy: 0.769531\n","Epoch  2, Batch 147 -Loss:  1271.3547 Validation Accuracy: 0.765625\n","Epoch  2, Batch 148 -Loss:   932.2257 Validation Accuracy: 0.765625\n","Epoch  2, Batch 149 -Loss:   767.2321 Validation Accuracy: 0.773438\n","Epoch  2, Batch 150 -Loss:   983.3250 Validation Accuracy: 0.773438\n","Epoch  2, Batch 151 -Loss:  1572.1660 Validation Accuracy: 0.773438\n","Epoch  2, Batch 152 -Loss:  1089.2446 Validation Accuracy: 0.773438\n","Epoch  2, Batch 153 -Loss:   661.8663 Validation Accuracy: 0.773438\n","Epoch  2, Batch 154 -Loss:   950.1594 Validation Accuracy: 0.773438\n","Epoch  2, Batch 155 -Loss:  1153.0986 Validation Accuracy: 0.777344\n","Epoch  2, Batch 156 -Loss:  1094.4380 Validation Accuracy: 0.777344\n","Epoch  2, Batch 157 -Loss:   753.8139 Validation Accuracy: 0.773438\n","Epoch  2, Batch 158 -Loss:   725.5292 Validation Accuracy: 0.773438\n","Epoch  2, Batch 159 -Loss:   599.8508 Validation Accuracy: 0.777344\n","Epoch  2, Batch 160 -Loss:  1026.2468 Validation Accuracy: 0.781250\n","Epoch  2, Batch 161 -Loss:  1278.8118 Validation Accuracy: 0.781250\n","Epoch  2, Batch 162 -Loss:  1021.1596 Validation Accuracy: 0.792969\n","Epoch  2, Batch 163 -Loss:   901.2379 Validation Accuracy: 0.789062\n","Epoch  2, Batch 164 -Loss:  1276.3723 Validation Accuracy: 0.781250\n","Epoch  2, Batch 165 -Loss:  1043.4465 Validation Accuracy: 0.781250\n","Epoch  2, Batch 166 -Loss:  1100.1570 Validation Accuracy: 0.781250\n","Epoch  2, Batch 167 -Loss:  1117.7638 Validation Accuracy: 0.781250\n","Epoch  2, Batch 168 -Loss:  1137.8264 Validation Accuracy: 0.785156\n","Epoch  2, Batch 169 -Loss:   905.8998 Validation Accuracy: 0.781250\n","Epoch  2, Batch 170 -Loss:  1281.0481 Validation Accuracy: 0.781250\n","Epoch  2, Batch 171 -Loss:  1052.1394 Validation Accuracy: 0.773438\n","Epoch  2, Batch 172 -Loss:  1039.7271 Validation Accuracy: 0.777344\n","Epoch  2, Batch 173 -Loss:   852.0886 Validation Accuracy: 0.785156\n","Epoch  2, Batch 174 -Loss:   760.4404 Validation Accuracy: 0.781250\n","Epoch  2, Batch 175 -Loss:  1002.7128 Validation Accuracy: 0.781250\n","Epoch  2, Batch 176 -Loss:   728.9892 Validation Accuracy: 0.789062\n","Epoch  2, Batch 177 -Loss:   942.6577 Validation Accuracy: 0.789062\n","Epoch  2, Batch 178 -Loss:   933.8642 Validation Accuracy: 0.785156\n","Epoch  2, Batch 179 -Loss:  1079.3027 Validation Accuracy: 0.781250\n","Epoch  2, Batch 180 -Loss:  1267.5643 Validation Accuracy: 0.789062\n","Epoch  2, Batch 181 -Loss:  1029.5686 Validation Accuracy: 0.789062\n","Epoch  2, Batch 182 -Loss:   749.5597 Validation Accuracy: 0.789062\n","Epoch  2, Batch 183 -Loss:   959.9265 Validation Accuracy: 0.789062\n","Epoch  2, Batch 184 -Loss:   983.7328 Validation Accuracy: 0.792969\n","Epoch  2, Batch 185 -Loss:   933.8795 Validation Accuracy: 0.792969\n","Epoch  2, Batch 186 -Loss:   908.2300 Validation Accuracy: 0.785156\n","Epoch  2, Batch 187 -Loss:  1003.9381 Validation Accuracy: 0.785156\n","Epoch  2, Batch 188 -Loss:  1110.6362 Validation Accuracy: 0.781250\n","Epoch  2, Batch 189 -Loss:  1063.2440 Validation Accuracy: 0.789062\n","Epoch  2, Batch 190 -Loss:   994.3644 Validation Accuracy: 0.785156\n","Epoch  2, Batch 191 -Loss:   775.5176 Validation Accuracy: 0.792969\n","Epoch  2, Batch 192 -Loss:   682.1265 Validation Accuracy: 0.769531\n","Epoch  2, Batch 193 -Loss:   837.6703 Validation Accuracy: 0.769531\n","Epoch  2, Batch 194 -Loss:   821.6714 Validation Accuracy: 0.777344\n","Epoch  2, Batch 195 -Loss:   996.1321 Validation Accuracy: 0.781250\n","Epoch  2, Batch 196 -Loss:   780.7863 Validation Accuracy: 0.769531\n","Epoch  2, Batch 197 -Loss:   791.2204 Validation Accuracy: 0.765625\n","Epoch  2, Batch 198 -Loss:  1148.0989 Validation Accuracy: 0.765625\n","Epoch  2, Batch 199 -Loss:   897.0290 Validation Accuracy: 0.765625\n","Epoch  2, Batch 200 -Loss:   946.8899 Validation Accuracy: 0.769531\n","Epoch  2, Batch 201 -Loss:  1041.6661 Validation Accuracy: 0.769531\n","Epoch  2, Batch 202 -Loss:  1225.2415 Validation Accuracy: 0.765625\n","Epoch  2, Batch 203 -Loss:   761.0713 Validation Accuracy: 0.765625\n","Epoch  2, Batch 204 -Loss:   994.0801 Validation Accuracy: 0.781250\n","Epoch  2, Batch 205 -Loss:  1198.2762 Validation Accuracy: 0.773438\n","Epoch  2, Batch 206 -Loss:   602.8663 Validation Accuracy: 0.773438\n","Epoch  2, Batch 207 -Loss:  1528.7233 Validation Accuracy: 0.781250\n","Epoch  2, Batch 208 -Loss:  1086.2094 Validation Accuracy: 0.785156\n","Epoch  2, Batch 209 -Loss:   703.8115 Validation Accuracy: 0.785156\n","Epoch  2, Batch 210 -Loss:   999.5663 Validation Accuracy: 0.781250\n","Epoch  2, Batch 211 -Loss:  1222.1617 Validation Accuracy: 0.785156\n","Epoch  2, Batch 212 -Loss:   985.0750 Validation Accuracy: 0.792969\n","Epoch  2, Batch 213 -Loss:   959.6062 Validation Accuracy: 0.789062\n","Epoch  2, Batch 214 -Loss:  1117.2234 Validation Accuracy: 0.792969\n","Epoch  2, Batch 215 -Loss:   907.4072 Validation Accuracy: 0.789062\n","Epoch  2, Batch 216 -Loss:   802.1733 Validation Accuracy: 0.777344\n","Epoch  2, Batch 217 -Loss:  1373.3230 Validation Accuracy: 0.777344\n","Epoch  2, Batch 218 -Loss:  1427.1592 Validation Accuracy: 0.785156\n","Epoch  2, Batch 219 -Loss:  1011.1949 Validation Accuracy: 0.785156\n","Epoch  2, Batch 220 -Loss:   712.4666 Validation Accuracy: 0.777344\n","Epoch  2, Batch 221 -Loss:  1256.8340 Validation Accuracy: 0.789062\n","Epoch  2, Batch 222 -Loss:   960.3698 Validation Accuracy: 0.785156\n","Epoch  2, Batch 223 -Loss:  1184.4004 Validation Accuracy: 0.789062\n","Epoch  2, Batch 224 -Loss:   829.1899 Validation Accuracy: 0.789062\n","Epoch  2, Batch 225 -Loss:  1163.6902 Validation Accuracy: 0.785156\n","Epoch  2, Batch 226 -Loss:   758.8616 Validation Accuracy: 0.785156\n","Epoch  2, Batch 227 -Loss:   703.7272 Validation Accuracy: 0.789062\n","Epoch  2, Batch 228 -Loss:  1083.7312 Validation Accuracy: 0.792969\n","Epoch  2, Batch 229 -Loss:   491.4297 Validation Accuracy: 0.792969\n","Epoch  2, Batch 230 -Loss:   856.9690 Validation Accuracy: 0.796875\n","Epoch  2, Batch 231 -Loss:   684.8005 Validation Accuracy: 0.792969\n","Epoch  2, Batch 232 -Loss:   972.7412 Validation Accuracy: 0.789062\n","Epoch  2, Batch 233 -Loss:  1068.5060 Validation Accuracy: 0.789062\n","Epoch  2, Batch 234 -Loss:   886.7758 Validation Accuracy: 0.781250\n","Epoch  2, Batch 235 -Loss:   963.2144 Validation Accuracy: 0.789062\n","Epoch  2, Batch 236 -Loss:   863.1743 Validation Accuracy: 0.785156\n","Epoch  2, Batch 237 -Loss:   821.8211 Validation Accuracy: 0.789062\n","Epoch  2, Batch 238 -Loss:   890.4655 Validation Accuracy: 0.789062\n","Epoch  2, Batch 239 -Loss:   714.6984 Validation Accuracy: 0.792969\n","Epoch  2, Batch 240 -Loss:  1337.9319 Validation Accuracy: 0.789062\n","Epoch  2, Batch 241 -Loss:  1054.4054 Validation Accuracy: 0.792969\n","Epoch  2, Batch 242 -Loss:   828.7250 Validation Accuracy: 0.792969\n","Epoch  2, Batch 243 -Loss:   970.3160 Validation Accuracy: 0.796875\n","Epoch  2, Batch 244 -Loss:   710.6042 Validation Accuracy: 0.796875\n","Epoch  2, Batch 245 -Loss:   846.1732 Validation Accuracy: 0.789062\n","Epoch  2, Batch 246 -Loss:   883.2015 Validation Accuracy: 0.792969\n","Epoch  2, Batch 247 -Loss:   820.9895 Validation Accuracy: 0.789062\n","Epoch  2, Batch 248 -Loss:   934.8522 Validation Accuracy: 0.792969\n","Epoch  2, Batch 249 -Loss:  1035.7776 Validation Accuracy: 0.792969\n","Epoch  2, Batch 250 -Loss:   988.4092 Validation Accuracy: 0.796875\n","Epoch  2, Batch 251 -Loss:   703.4691 Validation Accuracy: 0.792969\n","Epoch  2, Batch 252 -Loss:   961.4749 Validation Accuracy: 0.792969\n","Epoch  2, Batch 253 -Loss:  1199.4888 Validation Accuracy: 0.792969\n","Epoch  2, Batch 254 -Loss:   854.4232 Validation Accuracy: 0.796875\n","Epoch  2, Batch 255 -Loss:   880.0089 Validation Accuracy: 0.796875\n","Epoch  2, Batch 256 -Loss:  1085.2355 Validation Accuracy: 0.796875\n","Epoch  2, Batch 257 -Loss:   962.5865 Validation Accuracy: 0.796875\n","Epoch  2, Batch 258 -Loss:   988.3577 Validation Accuracy: 0.789062\n","Epoch  2, Batch 259 -Loss:   873.3000 Validation Accuracy: 0.789062\n","Epoch  2, Batch 260 -Loss:   819.7176 Validation Accuracy: 0.789062\n","Epoch  2, Batch 261 -Loss:   846.8413 Validation Accuracy: 0.785156\n","Epoch  2, Batch 262 -Loss:   961.4629 Validation Accuracy: 0.785156\n","Epoch  2, Batch 263 -Loss:  1131.9187 Validation Accuracy: 0.785156\n","Epoch  2, Batch 264 -Loss:   733.1903 Validation Accuracy: 0.781250\n","Epoch  2, Batch 265 -Loss:   903.8374 Validation Accuracy: 0.781250\n","Epoch  2, Batch 266 -Loss:  1251.0199 Validation Accuracy: 0.785156\n","Epoch  2, Batch 267 -Loss:  1109.1152 Validation Accuracy: 0.785156\n","Epoch  2, Batch 268 -Loss:  1079.6805 Validation Accuracy: 0.792969\n","Epoch  2, Batch 269 -Loss:   889.8943 Validation Accuracy: 0.789062\n","Epoch  2, Batch 270 -Loss:   796.2009 Validation Accuracy: 0.785156\n","Epoch  2, Batch 271 -Loss:   653.4424 Validation Accuracy: 0.785156\n","Epoch  2, Batch 272 -Loss:   930.3932 Validation Accuracy: 0.789062\n","Epoch  2, Batch 273 -Loss:  1216.7556 Validation Accuracy: 0.792969\n","Epoch  2, Batch 274 -Loss:   962.3895 Validation Accuracy: 0.781250\n","Epoch  2, Batch 275 -Loss:  1220.1779 Validation Accuracy: 0.781250\n","Epoch  2, Batch 276 -Loss:   709.5153 Validation Accuracy: 0.781250\n","Epoch  2, Batch 277 -Loss:   947.5717 Validation Accuracy: 0.781250\n","Epoch  2, Batch 278 -Loss:   712.8275 Validation Accuracy: 0.777344\n","Epoch  2, Batch 279 -Loss:  1023.3654 Validation Accuracy: 0.781250\n","Epoch  2, Batch 280 -Loss:   798.0372 Validation Accuracy: 0.785156\n","Epoch  2, Batch 281 -Loss:   588.4814 Validation Accuracy: 0.781250\n","Epoch  2, Batch 282 -Loss:  1096.3246 Validation Accuracy: 0.785156\n","Epoch  2, Batch 283 -Loss:  1218.0767 Validation Accuracy: 0.785156\n","Epoch  2, Batch 284 -Loss:   871.1462 Validation Accuracy: 0.789062\n","Epoch  2, Batch 285 -Loss:   914.8873 Validation Accuracy: 0.785156\n","Epoch  2, Batch 286 -Loss:   422.6815 Validation Accuracy: 0.785156\n","Epoch  2, Batch 287 -Loss:   996.7124 Validation Accuracy: 0.785156\n","Epoch  2, Batch 288 -Loss:   919.5195 Validation Accuracy: 0.785156\n","Epoch  2, Batch 289 -Loss:   825.5437 Validation Accuracy: 0.785156\n","Epoch  2, Batch 290 -Loss:   674.9396 Validation Accuracy: 0.785156\n","Epoch  2, Batch 291 -Loss:  1229.1907 Validation Accuracy: 0.789062\n","Epoch  2, Batch 292 -Loss:   583.2817 Validation Accuracy: 0.785156\n","Epoch  2, Batch 293 -Loss:   630.3639 Validation Accuracy: 0.792969\n","Epoch  2, Batch 294 -Loss:  1023.0737 Validation Accuracy: 0.781250\n","Epoch  2, Batch 295 -Loss:  1241.1091 Validation Accuracy: 0.785156\n","Epoch  2, Batch 296 -Loss:   727.5662 Validation Accuracy: 0.789062\n","Epoch  2, Batch 297 -Loss:   907.7234 Validation Accuracy: 0.785156\n","Epoch  2, Batch 298 -Loss:  1117.9102 Validation Accuracy: 0.789062\n","Epoch  2, Batch 299 -Loss:   962.8032 Validation Accuracy: 0.789062\n","Epoch  2, Batch 300 -Loss:   734.2532 Validation Accuracy: 0.789062\n","Epoch  2, Batch 301 -Loss:   809.9564 Validation Accuracy: 0.789062\n","Epoch  2, Batch 302 -Loss:   782.7505 Validation Accuracy: 0.785156\n","Epoch  2, Batch 303 -Loss:   640.2247 Validation Accuracy: 0.789062\n","Epoch  2, Batch 304 -Loss:   627.5985 Validation Accuracy: 0.781250\n","Epoch  2, Batch 305 -Loss:   684.9159 Validation Accuracy: 0.789062\n","Epoch  2, Batch 306 -Loss:   846.3590 Validation Accuracy: 0.789062\n","Epoch  2, Batch 307 -Loss:  1177.8154 Validation Accuracy: 0.785156\n","Epoch  2, Batch 308 -Loss:   662.2042 Validation Accuracy: 0.789062\n","Epoch  2, Batch 309 -Loss:   774.0977 Validation Accuracy: 0.789062\n","Epoch  2, Batch 310 -Loss:   827.9858 Validation Accuracy: 0.789062\n","Epoch  2, Batch 311 -Loss:   672.6260 Validation Accuracy: 0.789062\n","Epoch  2, Batch 312 -Loss:   845.3292 Validation Accuracy: 0.789062\n","Epoch  2, Batch 313 -Loss:   441.7434 Validation Accuracy: 0.792969\n","Epoch  2, Batch 314 -Loss:   921.8479 Validation Accuracy: 0.792969\n","Epoch  2, Batch 315 -Loss:   918.0598 Validation Accuracy: 0.792969\n","Epoch  2, Batch 316 -Loss:   845.7621 Validation Accuracy: 0.792969\n","Epoch  2, Batch 317 -Loss:   895.2964 Validation Accuracy: 0.796875\n","Epoch  2, Batch 318 -Loss:   982.3044 Validation Accuracy: 0.796875\n","Epoch  2, Batch 319 -Loss:  1037.3925 Validation Accuracy: 0.789062\n","Epoch  2, Batch 320 -Loss:   836.3856 Validation Accuracy: 0.789062\n","Epoch  2, Batch 321 -Loss:   780.1808 Validation Accuracy: 0.789062\n","Epoch  2, Batch 322 -Loss:   742.0248 Validation Accuracy: 0.792969\n","Epoch  2, Batch 323 -Loss:  1031.8359 Validation Accuracy: 0.789062\n","Epoch  2, Batch 324 -Loss:   718.2809 Validation Accuracy: 0.796875\n","Epoch  2, Batch 325 -Loss:   581.9927 Validation Accuracy: 0.789062\n","Epoch  2, Batch 326 -Loss:   643.7701 Validation Accuracy: 0.792969\n","Epoch  2, Batch 327 -Loss:   738.8235 Validation Accuracy: 0.792969\n","Epoch  2, Batch 328 -Loss:   879.0633 Validation Accuracy: 0.789062\n","Epoch  2, Batch 329 -Loss:   760.1661 Validation Accuracy: 0.781250\n","Epoch  2, Batch 330 -Loss:   592.8877 Validation Accuracy: 0.785156\n","Epoch  2, Batch 331 -Loss:   682.8705 Validation Accuracy: 0.781250\n","Epoch  2, Batch 332 -Loss:   629.6127 Validation Accuracy: 0.781250\n","Epoch  2, Batch 333 -Loss:  1000.4655 Validation Accuracy: 0.785156\n","Epoch  2, Batch 334 -Loss:   862.7568 Validation Accuracy: 0.789062\n","Epoch  2, Batch 335 -Loss:   779.2897 Validation Accuracy: 0.789062\n","Epoch  2, Batch 336 -Loss:   667.9435 Validation Accuracy: 0.789062\n","Epoch  2, Batch 337 -Loss:   671.6637 Validation Accuracy: 0.785156\n","Epoch  2, Batch 338 -Loss:   862.3413 Validation Accuracy: 0.789062\n","Epoch  2, Batch 339 -Loss:   819.1285 Validation Accuracy: 0.789062\n","Epoch  2, Batch 340 -Loss:   780.1530 Validation Accuracy: 0.792969\n","Epoch  2, Batch 341 -Loss:   722.3155 Validation Accuracy: 0.789062\n","Epoch  2, Batch 342 -Loss:  1085.3901 Validation Accuracy: 0.785156\n","Epoch  2, Batch 343 -Loss:  1001.0721 Validation Accuracy: 0.789062\n","Epoch  2, Batch 344 -Loss:   714.3328 Validation Accuracy: 0.785156\n","Epoch  2, Batch 345 -Loss:   786.5141 Validation Accuracy: 0.789062\n","Epoch  2, Batch 346 -Loss:   834.3538 Validation Accuracy: 0.789062\n","Epoch  2, Batch 347 -Loss:   610.9902 Validation Accuracy: 0.785156\n","Epoch  2, Batch 348 -Loss:   572.9791 Validation Accuracy: 0.792969\n","Epoch  2, Batch 349 -Loss:   682.9532 Validation Accuracy: 0.792969\n","Epoch  2, Batch 350 -Loss:   790.3247 Validation Accuracy: 0.789062\n","Epoch  2, Batch 351 -Loss:   865.5771 Validation Accuracy: 0.789062\n","Epoch  2, Batch 352 -Loss:   970.3810 Validation Accuracy: 0.792969\n","Epoch  2, Batch 353 -Loss:   717.2322 Validation Accuracy: 0.789062\n","Epoch  2, Batch 354 -Loss:  1001.5538 Validation Accuracy: 0.792969\n","Epoch  2, Batch 355 -Loss:   287.7114 Validation Accuracy: 0.796875\n","Epoch  2, Batch 356 -Loss:   757.8868 Validation Accuracy: 0.796875\n","Epoch  2, Batch 357 -Loss:   917.6702 Validation Accuracy: 0.785156\n","Epoch  2, Batch 358 -Loss:   523.8112 Validation Accuracy: 0.781250\n","Epoch  2, Batch 359 -Loss:   739.7010 Validation Accuracy: 0.777344\n","Epoch  2, Batch 360 -Loss:   593.6379 Validation Accuracy: 0.777344\n","Epoch  2, Batch 361 -Loss:   750.3196 Validation Accuracy: 0.781250\n","Epoch  2, Batch 362 -Loss:  1024.5905 Validation Accuracy: 0.781250\n","Epoch  2, Batch 363 -Loss:   816.2263 Validation Accuracy: 0.777344\n","Epoch  2, Batch 364 -Loss:   707.1601 Validation Accuracy: 0.785156\n","Epoch  2, Batch 365 -Loss:  1006.9766 Validation Accuracy: 0.777344\n","Epoch  2, Batch 366 -Loss:   966.4064 Validation Accuracy: 0.781250\n","Epoch  2, Batch 367 -Loss:   865.3987 Validation Accuracy: 0.773438\n","Epoch  2, Batch 368 -Loss:   726.3185 Validation Accuracy: 0.777344\n","Epoch  2, Batch 369 -Loss:   633.5950 Validation Accuracy: 0.785156\n","Epoch  2, Batch 370 -Loss:  1068.5138 Validation Accuracy: 0.773438\n","Epoch  2, Batch 371 -Loss:   664.9729 Validation Accuracy: 0.781250\n","Epoch  2, Batch 372 -Loss:  1028.3114 Validation Accuracy: 0.789062\n","Epoch  2, Batch 373 -Loss:   822.8079 Validation Accuracy: 0.785156\n","Epoch  2, Batch 374 -Loss:   919.4102 Validation Accuracy: 0.781250\n","Epoch  2, Batch 375 -Loss:   703.3892 Validation Accuracy: 0.785156\n","Epoch  2, Batch 376 -Loss:   876.3960 Validation Accuracy: 0.785156\n","Epoch  2, Batch 377 -Loss:   748.0387 Validation Accuracy: 0.781250\n","Epoch  2, Batch 378 -Loss:   976.5226 Validation Accuracy: 0.781250\n","Epoch  2, Batch 379 -Loss:   722.6760 Validation Accuracy: 0.777344\n","Epoch  2, Batch 380 -Loss:  1008.9214 Validation Accuracy: 0.777344\n","Epoch  2, Batch 381 -Loss:   451.9724 Validation Accuracy: 0.781250\n","Epoch  2, Batch 382 -Loss:   915.3456 Validation Accuracy: 0.785156\n","Epoch  2, Batch 383 -Loss:   881.8311 Validation Accuracy: 0.785156\n","Epoch  2, Batch 384 -Loss:  1063.2030 Validation Accuracy: 0.789062\n","Epoch  2, Batch 385 -Loss:   643.4504 Validation Accuracy: 0.789062\n","Epoch  2, Batch 386 -Loss:   713.4999 Validation Accuracy: 0.792969\n","Epoch  2, Batch 387 -Loss:   650.1005 Validation Accuracy: 0.792969\n","Epoch  2, Batch 388 -Loss:   807.0062 Validation Accuracy: 0.792969\n","Epoch  2, Batch 389 -Loss:   493.7823 Validation Accuracy: 0.785156\n","Epoch  2, Batch 390 -Loss:   937.6161 Validation Accuracy: 0.781250\n","Epoch  2, Batch 391 -Loss:   887.3191 Validation Accuracy: 0.785156\n","Epoch  2, Batch 392 -Loss:   877.1020 Validation Accuracy: 0.781250\n","Epoch  2, Batch 393 -Loss:   639.8675 Validation Accuracy: 0.781250\n","Epoch  2, Batch 394 -Loss:   871.4756 Validation Accuracy: 0.781250\n","Epoch  2, Batch 395 -Loss:   707.0537 Validation Accuracy: 0.781250\n","Epoch  2, Batch 396 -Loss:   913.6715 Validation Accuracy: 0.777344\n","Epoch  2, Batch 397 -Loss:  1181.7900 Validation Accuracy: 0.777344\n","Epoch  2, Batch 398 -Loss:  1188.0343 Validation Accuracy: 0.781250\n","Epoch  2, Batch 399 -Loss:   936.8458 Validation Accuracy: 0.777344\n","Epoch  2, Batch 400 -Loss:   822.4027 Validation Accuracy: 0.777344\n","Epoch  2, Batch 401 -Loss:   588.3567 Validation Accuracy: 0.781250\n","Epoch  2, Batch 402 -Loss:   724.3429 Validation Accuracy: 0.781250\n","Epoch  2, Batch 403 -Loss:   937.6884 Validation Accuracy: 0.781250\n","Epoch  2, Batch 404 -Loss:   551.6779 Validation Accuracy: 0.785156\n","Epoch  2, Batch 405 -Loss:   647.3870 Validation Accuracy: 0.785156\n","Epoch  2, Batch 406 -Loss:   856.6122 Validation Accuracy: 0.792969\n","Epoch  2, Batch 407 -Loss:   838.5273 Validation Accuracy: 0.792969\n","Epoch  2, Batch 408 -Loss:  1022.8234 Validation Accuracy: 0.792969\n","Epoch  2, Batch 409 -Loss:   554.9570 Validation Accuracy: 0.792969\n","Epoch  2, Batch 410 -Loss:   748.1867 Validation Accuracy: 0.796875\n","Epoch  2, Batch 411 -Loss:   720.6637 Validation Accuracy: 0.796875\n","Epoch  2, Batch 412 -Loss:   663.9773 Validation Accuracy: 0.796875\n","Epoch  2, Batch 413 -Loss:   782.5159 Validation Accuracy: 0.796875\n","Epoch  2, Batch 414 -Loss:  1038.5953 Validation Accuracy: 0.796875\n","Epoch  2, Batch 415 -Loss:   720.5842 Validation Accuracy: 0.796875\n","Epoch  2, Batch 416 -Loss:   908.1486 Validation Accuracy: 0.796875\n","Epoch  2, Batch 417 -Loss:   504.7105 Validation Accuracy: 0.796875\n","Epoch  2, Batch 418 -Loss:   738.8760 Validation Accuracy: 0.792969\n","Epoch  2, Batch 419 -Loss:   832.5101 Validation Accuracy: 0.796875\n","Epoch  2, Batch 420 -Loss:   661.5869 Validation Accuracy: 0.796875\n","Epoch  2, Batch 421 -Loss:  1075.8735 Validation Accuracy: 0.796875\n","Epoch  2, Batch 422 -Loss:   976.9539 Validation Accuracy: 0.796875\n","Epoch  2, Batch 423 -Loss:   413.8080 Validation Accuracy: 0.796875\n","Epoch  2, Batch 424 -Loss:   891.0600 Validation Accuracy: 0.796875\n","Epoch  2, Batch 425 -Loss:   881.9406 Validation Accuracy: 0.792969\n","Epoch  2, Batch 426 -Loss:   644.8904 Validation Accuracy: 0.792969\n","Epoch  2, Batch 427 -Loss:   849.9960 Validation Accuracy: 0.792969\n","Epoch  2, Batch 428 -Loss:   682.9692 Validation Accuracy: 0.792969\n","Epoch  2, Batch 429 -Loss:   555.6933 Validation Accuracy: 0.792969\n","Epoch  3, Batch   1 -Loss:   559.0479 Validation Accuracy: 0.792969\n","Epoch  3, Batch   2 -Loss:   509.8204 Validation Accuracy: 0.785156\n","Epoch  3, Batch   3 -Loss:   558.7957 Validation Accuracy: 0.789062\n","Epoch  3, Batch   4 -Loss:   729.5681 Validation Accuracy: 0.789062\n","Epoch  3, Batch   5 -Loss:   779.8477 Validation Accuracy: 0.796875\n","Epoch  3, Batch   6 -Loss:  1006.6095 Validation Accuracy: 0.789062\n","Epoch  3, Batch   7 -Loss:   480.8667 Validation Accuracy: 0.781250\n","Epoch  3, Batch   8 -Loss:  1179.7969 Validation Accuracy: 0.789062\n","Epoch  3, Batch   9 -Loss:   753.9999 Validation Accuracy: 0.785156\n","Epoch  3, Batch  10 -Loss:   670.1011 Validation Accuracy: 0.792969\n","Epoch  3, Batch  11 -Loss:   808.9141 Validation Accuracy: 0.777344\n","Epoch  3, Batch  12 -Loss:   555.0284 Validation Accuracy: 0.785156\n","Epoch  3, Batch  13 -Loss:   674.9307 Validation Accuracy: 0.789062\n","Epoch  3, Batch  14 -Loss:   760.6371 Validation Accuracy: 0.789062\n","Epoch  3, Batch  15 -Loss:   944.2738 Validation Accuracy: 0.789062\n","Epoch  3, Batch  16 -Loss:   550.7394 Validation Accuracy: 0.789062\n","Epoch  3, Batch  17 -Loss:   478.1074 Validation Accuracy: 0.789062\n","Epoch  3, Batch  18 -Loss:   732.8440 Validation Accuracy: 0.789062\n","Epoch  3, Batch  19 -Loss:   658.8592 Validation Accuracy: 0.789062\n","Epoch  3, Batch  20 -Loss:   692.1575 Validation Accuracy: 0.789062\n","Epoch  3, Batch  21 -Loss:   565.1166 Validation Accuracy: 0.789062\n","Epoch  3, Batch  22 -Loss:   738.8442 Validation Accuracy: 0.785156\n","Epoch  3, Batch  23 -Loss:   718.3655 Validation Accuracy: 0.785156\n","Epoch  3, Batch  24 -Loss:   721.0391 Validation Accuracy: 0.785156\n","Epoch  3, Batch  25 -Loss:   765.1403 Validation Accuracy: 0.789062\n","Epoch  3, Batch  26 -Loss:   717.4096 Validation Accuracy: 0.785156\n","Epoch  3, Batch  27 -Loss:   760.6119 Validation Accuracy: 0.781250\n","Epoch  3, Batch  28 -Loss:   533.0320 Validation Accuracy: 0.781250\n","Epoch  3, Batch  29 -Loss:   655.0453 Validation Accuracy: 0.777344\n","Epoch  3, Batch  30 -Loss:   592.2398 Validation Accuracy: 0.777344\n","Epoch  3, Batch  31 -Loss:   925.8383 Validation Accuracy: 0.781250\n","Epoch  3, Batch  32 -Loss:   651.8002 Validation Accuracy: 0.781250\n","Epoch  3, Batch  33 -Loss:   514.7075 Validation Accuracy: 0.781250\n","Epoch  3, Batch  34 -Loss:   798.3796 Validation Accuracy: 0.785156\n","Epoch  3, Batch  35 -Loss:   522.9497 Validation Accuracy: 0.781250\n","Epoch  3, Batch  36 -Loss:   539.3776 Validation Accuracy: 0.785156\n","Epoch  3, Batch  37 -Loss:   866.4225 Validation Accuracy: 0.785156\n","Epoch  3, Batch  38 -Loss:   717.9022 Validation Accuracy: 0.785156\n","Epoch  3, Batch  39 -Loss:   683.5116 Validation Accuracy: 0.781250\n","Epoch  3, Batch  40 -Loss:   621.6346 Validation Accuracy: 0.777344\n","Epoch  3, Batch  41 -Loss:   646.2679 Validation Accuracy: 0.781250\n","Epoch  3, Batch  42 -Loss:   860.2349 Validation Accuracy: 0.781250\n","Epoch  3, Batch  43 -Loss:  1131.9241 Validation Accuracy: 0.781250\n","Epoch  3, Batch  44 -Loss:   840.4172 Validation Accuracy: 0.781250\n","Epoch  3, Batch  45 -Loss:   585.6645 Validation Accuracy: 0.781250\n","Epoch  3, Batch  46 -Loss:   382.8105 Validation Accuracy: 0.785156\n","Epoch  3, Batch  47 -Loss:   819.9084 Validation Accuracy: 0.781250\n","Epoch  3, Batch  48 -Loss:   620.2010 Validation Accuracy: 0.781250\n","Epoch  3, Batch  49 -Loss:   836.5929 Validation Accuracy: 0.777344\n","Epoch  3, Batch  50 -Loss:   477.7016 Validation Accuracy: 0.773438\n","Epoch  3, Batch  51 -Loss:   508.9799 Validation Accuracy: 0.777344\n","Epoch  3, Batch  52 -Loss:   726.7097 Validation Accuracy: 0.773438\n","Epoch  3, Batch  53 -Loss:   847.1049 Validation Accuracy: 0.777344\n","Epoch  3, Batch  54 -Loss:   620.7944 Validation Accuracy: 0.773438\n","Epoch  3, Batch  55 -Loss:   520.1453 Validation Accuracy: 0.777344\n","Epoch  3, Batch  56 -Loss:   817.2698 Validation Accuracy: 0.773438\n","Epoch  3, Batch  57 -Loss:   644.6866 Validation Accuracy: 0.785156\n","Epoch  3, Batch  58 -Loss:   734.5406 Validation Accuracy: 0.781250\n","Epoch  3, Batch  59 -Loss:   954.9094 Validation Accuracy: 0.781250\n","Epoch  3, Batch  60 -Loss:   553.4938 Validation Accuracy: 0.789062\n","Epoch  3, Batch  61 -Loss:   627.6218 Validation Accuracy: 0.789062\n","Epoch  3, Batch  62 -Loss:   591.5780 Validation Accuracy: 0.785156\n","Epoch  3, Batch  63 -Loss:   569.6623 Validation Accuracy: 0.777344\n","Epoch  3, Batch  64 -Loss:   680.5583 Validation Accuracy: 0.777344\n","Epoch  3, Batch  65 -Loss:   659.0253 Validation Accuracy: 0.777344\n","Epoch  3, Batch  66 -Loss:   452.7492 Validation Accuracy: 0.773438\n","Epoch  3, Batch  67 -Loss:   613.8767 Validation Accuracy: 0.773438\n","Epoch  3, Batch  68 -Loss:   766.3571 Validation Accuracy: 0.769531\n","Epoch  3, Batch  69 -Loss:   476.1229 Validation Accuracy: 0.769531\n","Epoch  3, Batch  70 -Loss:   753.4325 Validation Accuracy: 0.777344\n","Epoch  3, Batch  71 -Loss:   799.9991 Validation Accuracy: 0.777344\n","Epoch  3, Batch  72 -Loss:   619.2285 Validation Accuracy: 0.773438\n","Epoch  3, Batch  73 -Loss:   569.8869 Validation Accuracy: 0.769531\n","Epoch  3, Batch  74 -Loss:   703.2108 Validation Accuracy: 0.769531\n","Epoch  3, Batch  75 -Loss:   679.9644 Validation Accuracy: 0.777344\n","Epoch  3, Batch  76 -Loss:   935.3281 Validation Accuracy: 0.769531\n","Epoch  3, Batch  77 -Loss:   771.1243 Validation Accuracy: 0.769531\n","Epoch  3, Batch  78 -Loss:   955.4745 Validation Accuracy: 0.765625\n","Epoch  3, Batch  79 -Loss:   914.7708 Validation Accuracy: 0.761719\n","Epoch  3, Batch  80 -Loss:   872.8184 Validation Accuracy: 0.765625\n","Epoch  3, Batch  81 -Loss:  1242.8326 Validation Accuracy: 0.769531\n","Epoch  3, Batch  82 -Loss:   686.9014 Validation Accuracy: 0.769531\n","Epoch  3, Batch  83 -Loss:   642.0376 Validation Accuracy: 0.769531\n","Epoch  3, Batch  84 -Loss:   795.4809 Validation Accuracy: 0.769531\n","Epoch  3, Batch  85 -Loss:   982.5385 Validation Accuracy: 0.769531\n","Epoch  3, Batch  86 -Loss:   620.6158 Validation Accuracy: 0.773438\n","Epoch  3, Batch  87 -Loss:   625.8418 Validation Accuracy: 0.777344\n","Epoch  3, Batch  88 -Loss:  1060.4946 Validation Accuracy: 0.773438\n","Epoch  3, Batch  89 -Loss:   496.4567 Validation Accuracy: 0.777344\n","Epoch  3, Batch  90 -Loss:   886.8096 Validation Accuracy: 0.777344\n","Epoch  3, Batch  91 -Loss:   605.9583 Validation Accuracy: 0.781250\n","Epoch  3, Batch  92 -Loss:   627.1573 Validation Accuracy: 0.773438\n","Epoch  3, Batch  93 -Loss:   873.8273 Validation Accuracy: 0.773438\n","Epoch  3, Batch  94 -Loss:   501.5924 Validation Accuracy: 0.765625\n","Epoch  3, Batch  95 -Loss:   838.0225 Validation Accuracy: 0.765625\n","Epoch  3, Batch  96 -Loss:   810.7301 Validation Accuracy: 0.769531\n","Epoch  3, Batch  97 -Loss:   645.4808 Validation Accuracy: 0.769531\n","Epoch  3, Batch  98 -Loss:   686.4609 Validation Accuracy: 0.769531\n","Epoch  3, Batch  99 -Loss:   562.2566 Validation Accuracy: 0.773438\n","Epoch  3, Batch 100 -Loss:   468.7312 Validation Accuracy: 0.773438\n","Epoch  3, Batch 101 -Loss:   613.9777 Validation Accuracy: 0.773438\n","Epoch  3, Batch 102 -Loss:  1081.8472 Validation Accuracy: 0.773438\n","Epoch  3, Batch 103 -Loss:   772.6565 Validation Accuracy: 0.773438\n","Epoch  3, Batch 104 -Loss:   749.9139 Validation Accuracy: 0.773438\n","Epoch  3, Batch 105 -Loss:   553.5051 Validation Accuracy: 0.773438\n","Epoch  3, Batch 106 -Loss:   801.5146 Validation Accuracy: 0.773438\n","Epoch  3, Batch 107 -Loss:   679.8610 Validation Accuracy: 0.773438\n","Epoch  3, Batch 108 -Loss:   759.6511 Validation Accuracy: 0.773438\n","Epoch  3, Batch 109 -Loss:   596.3032 Validation Accuracy: 0.769531\n","Epoch  3, Batch 110 -Loss:   956.5912 Validation Accuracy: 0.765625\n","Epoch  3, Batch 111 -Loss:   740.1967 Validation Accuracy: 0.773438\n","Epoch  3, Batch 112 -Loss:   459.3505 Validation Accuracy: 0.773438\n","Epoch  3, Batch 113 -Loss:   899.9522 Validation Accuracy: 0.777344\n","Epoch  3, Batch 114 -Loss:   615.8691 Validation Accuracy: 0.769531\n","Epoch  3, Batch 115 -Loss:   627.5466 Validation Accuracy: 0.773438\n","Epoch  3, Batch 116 -Loss:   464.0351 Validation Accuracy: 0.769531\n","Epoch  3, Batch 117 -Loss:   622.9523 Validation Accuracy: 0.773438\n","Epoch  3, Batch 118 -Loss:  1008.4080 Validation Accuracy: 0.773438\n","Epoch  3, Batch 119 -Loss:   604.8127 Validation Accuracy: 0.777344\n","Epoch  3, Batch 120 -Loss:   637.6276 Validation Accuracy: 0.773438\n","Epoch  3, Batch 121 -Loss:   352.2703 Validation Accuracy: 0.777344\n","Epoch  3, Batch 122 -Loss:   810.9360 Validation Accuracy: 0.777344\n","Epoch  3, Batch 123 -Loss:   549.8135 Validation Accuracy: 0.781250\n","Epoch  3, Batch 124 -Loss:   594.7761 Validation Accuracy: 0.777344\n","Epoch  3, Batch 125 -Loss:   698.2888 Validation Accuracy: 0.773438\n","Epoch  3, Batch 126 -Loss:   785.3450 Validation Accuracy: 0.773438\n","Epoch  3, Batch 127 -Loss:   692.8444 Validation Accuracy: 0.777344\n","Epoch  3, Batch 128 -Loss:   628.0839 Validation Accuracy: 0.773438\n","Epoch  3, Batch 129 -Loss:   508.8734 Validation Accuracy: 0.777344\n","Epoch  3, Batch 130 -Loss:   870.0826 Validation Accuracy: 0.773438\n","Epoch  3, Batch 131 -Loss:   634.5108 Validation Accuracy: 0.769531\n","Epoch  3, Batch 132 -Loss:   435.6701 Validation Accuracy: 0.773438\n","Epoch  3, Batch 133 -Loss:   415.4016 Validation Accuracy: 0.773438\n","Epoch  3, Batch 134 -Loss:   689.8071 Validation Accuracy: 0.773438\n","Epoch  3, Batch 135 -Loss:   607.3547 Validation Accuracy: 0.769531\n","Epoch  3, Batch 136 -Loss:   806.0648 Validation Accuracy: 0.765625\n","Epoch  3, Batch 137 -Loss:   315.0185 Validation Accuracy: 0.769531\n","Epoch  3, Batch 138 -Loss:   605.4088 Validation Accuracy: 0.769531\n","Epoch  3, Batch 139 -Loss:   784.7046 Validation Accuracy: 0.769531\n","Epoch  3, Batch 140 -Loss:   584.3766 Validation Accuracy: 0.769531\n","Epoch  3, Batch 141 -Loss:   840.8574 Validation Accuracy: 0.769531\n","Epoch  3, Batch 142 -Loss:   674.0710 Validation Accuracy: 0.773438\n","Epoch  3, Batch 143 -Loss:   899.7640 Validation Accuracy: 0.769531\n","Epoch  3, Batch 144 -Loss:   626.4790 Validation Accuracy: 0.769531\n","Epoch  3, Batch 145 -Loss:   667.6991 Validation Accuracy: 0.769531\n","Epoch  3, Batch 146 -Loss:   879.7433 Validation Accuracy: 0.765625\n","Epoch  3, Batch 147 -Loss:   469.1981 Validation Accuracy: 0.769531\n","Epoch  3, Batch 148 -Loss:   703.4351 Validation Accuracy: 0.769531\n","Epoch  3, Batch 149 -Loss:   652.5906 Validation Accuracy: 0.765625\n","Epoch  3, Batch 150 -Loss:   743.4254 Validation Accuracy: 0.757812\n","Epoch  3, Batch 151 -Loss:   746.2698 Validation Accuracy: 0.769531\n","Epoch  3, Batch 152 -Loss:   543.6025 Validation Accuracy: 0.765625\n","Epoch  3, Batch 153 -Loss:   524.0948 Validation Accuracy: 0.773438\n","Epoch  3, Batch 154 -Loss:   622.5028 Validation Accuracy: 0.769531\n","Epoch  3, Batch 155 -Loss:   748.5070 Validation Accuracy: 0.781250\n","Epoch  3, Batch 156 -Loss:   689.5349 Validation Accuracy: 0.781250\n","Epoch  3, Batch 157 -Loss:   696.8580 Validation Accuracy: 0.781250\n","Epoch  3, Batch 158 -Loss:   637.7411 Validation Accuracy: 0.781250\n","Epoch  3, Batch 159 -Loss:   743.8644 Validation Accuracy: 0.777344\n","Epoch  3, Batch 160 -Loss:   678.1019 Validation Accuracy: 0.781250\n","Epoch  3, Batch 161 -Loss:   975.6326 Validation Accuracy: 0.781250\n","Epoch  3, Batch 162 -Loss:   490.3682 Validation Accuracy: 0.781250\n","Epoch  3, Batch 163 -Loss:   542.5626 Validation Accuracy: 0.777344\n","Epoch  3, Batch 164 -Loss:   658.5289 Validation Accuracy: 0.781250\n","Epoch  3, Batch 165 -Loss:   679.4625 Validation Accuracy: 0.781250\n","Epoch  3, Batch 166 -Loss:   834.1431 Validation Accuracy: 0.777344\n","Epoch  3, Batch 167 -Loss:   679.5455 Validation Accuracy: 0.777344\n","Epoch  3, Batch 168 -Loss:   963.6360 Validation Accuracy: 0.777344\n","Epoch  3, Batch 169 -Loss:   723.5856 Validation Accuracy: 0.773438\n","Epoch  3, Batch 170 -Loss:   548.6238 Validation Accuracy: 0.785156\n","Epoch  3, Batch 171 -Loss:   704.0384 Validation Accuracy: 0.785156\n","Epoch  3, Batch 172 -Loss:   399.0263 Validation Accuracy: 0.785156\n","Epoch  3, Batch 173 -Loss:   479.8825 Validation Accuracy: 0.785156\n","Epoch  3, Batch 174 -Loss:   724.9037 Validation Accuracy: 0.769531\n","Epoch  3, Batch 175 -Loss:   678.2191 Validation Accuracy: 0.765625\n","Epoch  3, Batch 176 -Loss:   937.8273 Validation Accuracy: 0.769531\n","Epoch  3, Batch 177 -Loss:   754.1619 Validation Accuracy: 0.769531\n","Epoch  3, Batch 178 -Loss:   631.4583 Validation Accuracy: 0.773438\n","Epoch  3, Batch 179 -Loss:   537.5754 Validation Accuracy: 0.773438\n","Epoch  3, Batch 180 -Loss:   803.7493 Validation Accuracy: 0.785156\n","Epoch  3, Batch 181 -Loss:   440.8807 Validation Accuracy: 0.785156\n","Epoch  3, Batch 182 -Loss:   525.7424 Validation Accuracy: 0.785156\n","Epoch  3, Batch 183 -Loss:   737.4016 Validation Accuracy: 0.781250\n","Epoch  3, Batch 184 -Loss:   819.4952 Validation Accuracy: 0.789062\n","Epoch  3, Batch 185 -Loss:   662.7330 Validation Accuracy: 0.789062\n","Epoch  3, Batch 186 -Loss:   867.6146 Validation Accuracy: 0.785156\n","Epoch  3, Batch 187 -Loss:   424.0814 Validation Accuracy: 0.781250\n","Epoch  3, Batch 188 -Loss:   760.5787 Validation Accuracy: 0.781250\n","Epoch  3, Batch 189 -Loss:   499.9935 Validation Accuracy: 0.785156\n","Epoch  3, Batch 190 -Loss:   602.5485 Validation Accuracy: 0.785156\n","Epoch  3, Batch 191 -Loss:   510.7572 Validation Accuracy: 0.785156\n","Epoch  3, Batch 192 -Loss:   555.6212 Validation Accuracy: 0.781250\n","Epoch  3, Batch 193 -Loss:   903.2301 Validation Accuracy: 0.785156\n","Epoch  3, Batch 194 -Loss:   578.8589 Validation Accuracy: 0.785156\n","Epoch  3, Batch 195 -Loss:   566.9007 Validation Accuracy: 0.789062\n","Epoch  3, Batch 196 -Loss:   515.5344 Validation Accuracy: 0.785156\n","Epoch  3, Batch 197 -Loss:   795.2973 Validation Accuracy: 0.785156\n","Epoch  3, Batch 198 -Loss:   740.7942 Validation Accuracy: 0.781250\n","Epoch  3, Batch 199 -Loss:   653.9001 Validation Accuracy: 0.773438\n","Epoch  3, Batch 200 -Loss:   524.2330 Validation Accuracy: 0.781250\n","Epoch  3, Batch 201 -Loss:  1116.9692 Validation Accuracy: 0.773438\n","Epoch  3, Batch 202 -Loss:   839.4934 Validation Accuracy: 0.773438\n","Epoch  3, Batch 203 -Loss:   605.4781 Validation Accuracy: 0.773438\n","Epoch  3, Batch 204 -Loss:   638.2057 Validation Accuracy: 0.773438\n","Epoch  3, Batch 205 -Loss:   409.2618 Validation Accuracy: 0.777344\n","Epoch  3, Batch 206 -Loss:   412.6129 Validation Accuracy: 0.773438\n","Epoch  3, Batch 207 -Loss:   790.5273 Validation Accuracy: 0.769531\n","Epoch  3, Batch 208 -Loss:   424.8339 Validation Accuracy: 0.773438\n","Epoch  3, Batch 209 -Loss:   529.2024 Validation Accuracy: 0.777344\n","Epoch  3, Batch 210 -Loss:   824.4942 Validation Accuracy: 0.769531\n","Epoch  3, Batch 211 -Loss:   856.0586 Validation Accuracy: 0.777344\n","Epoch  3, Batch 212 -Loss:   361.3044 Validation Accuracy: 0.773438\n","Epoch  3, Batch 213 -Loss:   685.0884 Validation Accuracy: 0.773438\n","Epoch  3, Batch 214 -Loss:   655.2237 Validation Accuracy: 0.769531\n","Epoch  3, Batch 215 -Loss:   657.3220 Validation Accuracy: 0.769531\n","Epoch  3, Batch 216 -Loss:   644.2606 Validation Accuracy: 0.777344\n","Epoch  3, Batch 217 -Loss:   621.5502 Validation Accuracy: 0.777344\n","Epoch  3, Batch 218 -Loss:   685.2178 Validation Accuracy: 0.773438\n","Epoch  3, Batch 219 -Loss:   626.8095 Validation Accuracy: 0.769531\n","Epoch  3, Batch 220 -Loss:   441.2583 Validation Accuracy: 0.769531\n","Epoch  3, Batch 221 -Loss:   636.9117 Validation Accuracy: 0.777344\n","Epoch  3, Batch 222 -Loss:   772.5223 Validation Accuracy: 0.773438\n","Epoch  3, Batch 223 -Loss:   620.5098 Validation Accuracy: 0.769531\n","Epoch  3, Batch 224 -Loss:   626.1727 Validation Accuracy: 0.769531\n","Epoch  3, Batch 225 -Loss:   622.9406 Validation Accuracy: 0.777344\n","Epoch  3, Batch 226 -Loss:   843.7735 Validation Accuracy: 0.769531\n","Epoch  3, Batch 227 -Loss:   597.5887 Validation Accuracy: 0.777344\n","Epoch  3, Batch 228 -Loss:   511.0984 Validation Accuracy: 0.777344\n","Epoch  3, Batch 229 -Loss:   586.5490 Validation Accuracy: 0.777344\n","Epoch  3, Batch 230 -Loss:   705.4236 Validation Accuracy: 0.773438\n","Epoch  3, Batch 231 -Loss:   590.3051 Validation Accuracy: 0.773438\n","Epoch  3, Batch 232 -Loss:   845.1644 Validation Accuracy: 0.773438\n","Epoch  3, Batch 233 -Loss:   392.1687 Validation Accuracy: 0.773438\n","Epoch  3, Batch 234 -Loss:   704.5975 Validation Accuracy: 0.773438\n","Epoch  3, Batch 235 -Loss:   670.2872 Validation Accuracy: 0.773438\n","Epoch  3, Batch 236 -Loss:   464.2441 Validation Accuracy: 0.777344\n","Epoch  3, Batch 237 -Loss:   649.1724 Validation Accuracy: 0.777344\n","Epoch  3, Batch 238 -Loss:   804.8846 Validation Accuracy: 0.785156\n","Epoch  3, Batch 239 -Loss:   544.8984 Validation Accuracy: 0.785156\n","Epoch  3, Batch 240 -Loss:   500.8786 Validation Accuracy: 0.796875\n","Epoch  3, Batch 241 -Loss:   544.2042 Validation Accuracy: 0.796875\n","Epoch  3, Batch 242 -Loss:   309.3268 Validation Accuracy: 0.796875\n","Epoch  3, Batch 243 -Loss:  1012.0410 Validation Accuracy: 0.796875\n","Epoch  3, Batch 244 -Loss:   661.8115 Validation Accuracy: 0.789062\n","Epoch  3, Batch 245 -Loss:   522.9374 Validation Accuracy: 0.785156\n","Epoch  3, Batch 246 -Loss:   402.2710 Validation Accuracy: 0.792969\n","Epoch  3, Batch 247 -Loss:   438.7152 Validation Accuracy: 0.792969\n","Epoch  3, Batch 248 -Loss:   477.2194 Validation Accuracy: 0.785156\n","Epoch  3, Batch 249 -Loss:   511.0931 Validation Accuracy: 0.785156\n","Epoch  3, Batch 250 -Loss:   502.9313 Validation Accuracy: 0.789062\n","Epoch  3, Batch 251 -Loss:   847.1452 Validation Accuracy: 0.785156\n","Epoch  3, Batch 252 -Loss:   735.1731 Validation Accuracy: 0.789062\n","Epoch  3, Batch 253 -Loss:   487.1704 Validation Accuracy: 0.789062\n","Epoch  3, Batch 254 -Loss:   724.2435 Validation Accuracy: 0.789062\n","Epoch  3, Batch 255 -Loss:   579.5291 Validation Accuracy: 0.789062\n","Epoch  3, Batch 256 -Loss:   838.5190 Validation Accuracy: 0.789062\n","Epoch  3, Batch 257 -Loss:   547.2853 Validation Accuracy: 0.792969\n","Epoch  3, Batch 258 -Loss:   586.3336 Validation Accuracy: 0.796875\n","Epoch  3, Batch 259 -Loss:   802.2147 Validation Accuracy: 0.789062\n","Epoch  3, Batch 260 -Loss:   903.3300 Validation Accuracy: 0.785156\n","Epoch  3, Batch 261 -Loss:   588.8065 Validation Accuracy: 0.789062\n","Epoch  3, Batch 262 -Loss:   599.2589 Validation Accuracy: 0.789062\n","Epoch  3, Batch 263 -Loss:   636.4041 Validation Accuracy: 0.785156\n","Epoch  3, Batch 264 -Loss:   687.0458 Validation Accuracy: 0.785156\n","Epoch  3, Batch 265 -Loss:   544.4814 Validation Accuracy: 0.785156\n","Epoch  3, Batch 266 -Loss:   682.2027 Validation Accuracy: 0.785156\n","Epoch  3, Batch 267 -Loss:   656.5723 Validation Accuracy: 0.785156\n","Epoch  3, Batch 268 -Loss:   785.9062 Validation Accuracy: 0.785156\n","Epoch  3, Batch 269 -Loss:  1097.2947 Validation Accuracy: 0.785156\n","Epoch  3, Batch 270 -Loss:   730.6732 Validation Accuracy: 0.785156\n","Epoch  3, Batch 271 -Loss:   529.0121 Validation Accuracy: 0.785156\n","Epoch  3, Batch 272 -Loss:   722.7806 Validation Accuracy: 0.781250\n","Epoch  3, Batch 273 -Loss:   769.8618 Validation Accuracy: 0.777344\n","Epoch  3, Batch 274 -Loss:   630.9520 Validation Accuracy: 0.777344\n","Epoch  3, Batch 275 -Loss:   371.9126 Validation Accuracy: 0.781250\n","Epoch  3, Batch 276 -Loss:   921.7513 Validation Accuracy: 0.781250\n","Epoch  3, Batch 277 -Loss:   586.6096 Validation Accuracy: 0.781250\n","Epoch  3, Batch 278 -Loss:   634.3078 Validation Accuracy: 0.785156\n","Epoch  3, Batch 279 -Loss:   800.8540 Validation Accuracy: 0.785156\n","Epoch  3, Batch 280 -Loss:   764.1499 Validation Accuracy: 0.785156\n","Epoch  3, Batch 281 -Loss:   718.0348 Validation Accuracy: 0.789062\n","Epoch  3, Batch 282 -Loss:   421.6546 Validation Accuracy: 0.789062\n","Epoch  3, Batch 283 -Loss:   524.6517 Validation Accuracy: 0.789062\n","Epoch  3, Batch 284 -Loss:   528.1537 Validation Accuracy: 0.792969\n","Epoch  3, Batch 285 -Loss:   791.2960 Validation Accuracy: 0.789062\n","Epoch  3, Batch 286 -Loss:   556.2264 Validation Accuracy: 0.792969\n","Epoch  3, Batch 287 -Loss:   524.4185 Validation Accuracy: 0.792969\n","Epoch  3, Batch 288 -Loss:   600.4521 Validation Accuracy: 0.789062\n","Epoch  3, Batch 289 -Loss:   407.5095 Validation Accuracy: 0.789062\n","Epoch  3, Batch 290 -Loss:   809.6367 Validation Accuracy: 0.785156\n","Epoch  3, Batch 291 -Loss:   450.4083 Validation Accuracy: 0.789062\n","Epoch  3, Batch 292 -Loss:   428.2691 Validation Accuracy: 0.792969\n","Epoch  3, Batch 293 -Loss:   802.9035 Validation Accuracy: 0.785156\n","Epoch  3, Batch 294 -Loss:   704.1423 Validation Accuracy: 0.781250\n","Epoch  3, Batch 295 -Loss:   330.3404 Validation Accuracy: 0.785156\n","Epoch  3, Batch 296 -Loss:   728.3961 Validation Accuracy: 0.789062\n","Epoch  3, Batch 297 -Loss:   527.1503 Validation Accuracy: 0.785156\n","Epoch  3, Batch 298 -Loss:   478.4695 Validation Accuracy: 0.789062\n","Epoch  3, Batch 299 -Loss:   796.4629 Validation Accuracy: 0.792969\n","Epoch  3, Batch 300 -Loss:   566.4547 Validation Accuracy: 0.785156\n","Epoch  3, Batch 301 -Loss:   404.2915 Validation Accuracy: 0.792969\n","Epoch  3, Batch 302 -Loss:   611.9141 Validation Accuracy: 0.789062\n","Epoch  3, Batch 303 -Loss:   603.6082 Validation Accuracy: 0.781250\n","Epoch  3, Batch 304 -Loss:   537.3280 Validation Accuracy: 0.777344\n","Epoch  3, Batch 305 -Loss:   440.5795 Validation Accuracy: 0.781250\n","Epoch  3, Batch 306 -Loss:   640.3506 Validation Accuracy: 0.781250\n","Epoch  3, Batch 307 -Loss:   487.5321 Validation Accuracy: 0.785156\n","Epoch  3, Batch 308 -Loss:   566.9941 Validation Accuracy: 0.785156\n","Epoch  3, Batch 309 -Loss:   630.7360 Validation Accuracy: 0.789062\n","Epoch  3, Batch 310 -Loss:  1004.5043 Validation Accuracy: 0.789062\n","Epoch  3, Batch 311 -Loss:   474.3329 Validation Accuracy: 0.789062\n","Epoch  3, Batch 312 -Loss:   483.4875 Validation Accuracy: 0.785156\n","Epoch  3, Batch 313 -Loss:   428.6593 Validation Accuracy: 0.785156\n","Epoch  3, Batch 314 -Loss:   382.9104 Validation Accuracy: 0.789062\n","Epoch  3, Batch 315 -Loss:   429.6454 Validation Accuracy: 0.789062\n","Epoch  3, Batch 316 -Loss:   953.4176 Validation Accuracy: 0.789062\n","Epoch  3, Batch 317 -Loss:   466.4169 Validation Accuracy: 0.789062\n","Epoch  3, Batch 318 -Loss:   693.1813 Validation Accuracy: 0.789062\n","Epoch  3, Batch 319 -Loss:   477.1293 Validation Accuracy: 0.789062\n","Epoch  3, Batch 320 -Loss:   624.7405 Validation Accuracy: 0.781250\n","Epoch  3, Batch 321 -Loss:   750.3322 Validation Accuracy: 0.785156\n","Epoch  3, Batch 322 -Loss:   744.5326 Validation Accuracy: 0.789062\n","Epoch  3, Batch 323 -Loss:   476.1277 Validation Accuracy: 0.792969\n","Epoch  3, Batch 324 -Loss:   715.0818 Validation Accuracy: 0.785156\n","Epoch  3, Batch 325 -Loss:   782.5771 Validation Accuracy: 0.781250\n","Epoch  3, Batch 326 -Loss:   652.7651 Validation Accuracy: 0.781250\n","Epoch  3, Batch 327 -Loss:   561.4832 Validation Accuracy: 0.777344\n","Epoch  3, Batch 328 -Loss:   640.9275 Validation Accuracy: 0.777344\n","Epoch  3, Batch 329 -Loss:   686.9683 Validation Accuracy: 0.777344\n","Epoch  3, Batch 330 -Loss:   587.7975 Validation Accuracy: 0.781250\n","Epoch  3, Batch 331 -Loss:   657.2076 Validation Accuracy: 0.777344\n","Epoch  3, Batch 332 -Loss:   501.5601 Validation Accuracy: 0.781250\n","Epoch  3, Batch 333 -Loss:   506.3546 Validation Accuracy: 0.781250\n","Epoch  3, Batch 334 -Loss:   546.3701 Validation Accuracy: 0.785156\n","Epoch  3, Batch 335 -Loss:   326.4884 Validation Accuracy: 0.781250\n","Epoch  3, Batch 336 -Loss:   627.4480 Validation Accuracy: 0.785156\n","Epoch  3, Batch 337 -Loss:   559.5656 Validation Accuracy: 0.777344\n","Epoch  3, Batch 338 -Loss:   491.1790 Validation Accuracy: 0.777344\n","Epoch  3, Batch 339 -Loss:   549.6148 Validation Accuracy: 0.781250\n","Epoch  3, Batch 340 -Loss:   692.7966 Validation Accuracy: 0.781250\n","Epoch  3, Batch 341 -Loss:   697.4106 Validation Accuracy: 0.781250\n","Epoch  3, Batch 342 -Loss:   421.2480 Validation Accuracy: 0.785156\n","Epoch  3, Batch 343 -Loss:   545.0119 Validation Accuracy: 0.785156\n","Epoch  3, Batch 344 -Loss:   541.0529 Validation Accuracy: 0.781250\n","Epoch  3, Batch 345 -Loss:   432.8267 Validation Accuracy: 0.781250\n","Epoch  3, Batch 346 -Loss:   404.3388 Validation Accuracy: 0.781250\n","Epoch  3, Batch 347 -Loss:   455.1584 Validation Accuracy: 0.781250\n","Epoch  3, Batch 348 -Loss:   912.8596 Validation Accuracy: 0.781250\n","Epoch  3, Batch 349 -Loss:   503.1421 Validation Accuracy: 0.777344\n","Epoch  3, Batch 350 -Loss:   806.1306 Validation Accuracy: 0.777344\n","Epoch  3, Batch 351 -Loss:   599.6156 Validation Accuracy: 0.777344\n","Epoch  3, Batch 352 -Loss:   279.2681 Validation Accuracy: 0.781250\n","Epoch  3, Batch 353 -Loss:   674.7391 Validation Accuracy: 0.781250\n","Epoch  3, Batch 354 -Loss:   721.4318 Validation Accuracy: 0.781250\n","Epoch  3, Batch 355 -Loss:   487.6141 Validation Accuracy: 0.777344\n","Epoch  3, Batch 356 -Loss:   451.9734 Validation Accuracy: 0.777344\n","Epoch  3, Batch 357 -Loss:   504.1464 Validation Accuracy: 0.777344\n","Epoch  3, Batch 358 -Loss:   555.7806 Validation Accuracy: 0.777344\n","Epoch  3, Batch 359 -Loss:   463.9207 Validation Accuracy: 0.777344\n","Epoch  3, Batch 360 -Loss:   725.0639 Validation Accuracy: 0.781250\n","Epoch  3, Batch 361 -Loss:   238.5121 Validation Accuracy: 0.777344\n","Epoch  3, Batch 362 -Loss:   689.7296 Validation Accuracy: 0.781250\n","Epoch  3, Batch 363 -Loss:   533.9521 Validation Accuracy: 0.789062\n","Epoch  3, Batch 364 -Loss:   870.3836 Validation Accuracy: 0.781250\n","Epoch  3, Batch 365 -Loss:   502.1453 Validation Accuracy: 0.781250\n","Epoch  3, Batch 366 -Loss:   552.4276 Validation Accuracy: 0.789062\n","Epoch  3, Batch 367 -Loss:   344.1317 Validation Accuracy: 0.792969\n","Epoch  3, Batch 368 -Loss:   816.7053 Validation Accuracy: 0.781250\n","Epoch  3, Batch 369 -Loss:   641.3458 Validation Accuracy: 0.773438\n","Epoch  3, Batch 370 -Loss:   450.8449 Validation Accuracy: 0.777344\n","Epoch  3, Batch 371 -Loss:   571.1898 Validation Accuracy: 0.773438\n","Epoch  3, Batch 372 -Loss:   581.7651 Validation Accuracy: 0.773438\n","Epoch  3, Batch 373 -Loss:   579.1075 Validation Accuracy: 0.777344\n","Epoch  3, Batch 374 -Loss:   612.3826 Validation Accuracy: 0.777344\n","Epoch  3, Batch 375 -Loss:   699.7715 Validation Accuracy: 0.773438\n","Epoch  3, Batch 376 -Loss:   545.0120 Validation Accuracy: 0.773438\n","Epoch  3, Batch 377 -Loss:   806.2947 Validation Accuracy: 0.773438\n","Epoch  3, Batch 378 -Loss:   626.3218 Validation Accuracy: 0.777344\n","Epoch  3, Batch 379 -Loss:   708.2394 Validation Accuracy: 0.781250\n","Epoch  3, Batch 380 -Loss:   494.0691 Validation Accuracy: 0.785156\n","Epoch  3, Batch 381 -Loss:   575.4828 Validation Accuracy: 0.785156\n","Epoch  3, Batch 382 -Loss:   500.2060 Validation Accuracy: 0.785156\n","Epoch  3, Batch 383 -Loss:   467.6885 Validation Accuracy: 0.792969\n","Epoch  3, Batch 384 -Loss:   505.2207 Validation Accuracy: 0.781250\n","Epoch  3, Batch 385 -Loss:   448.9256 Validation Accuracy: 0.785156\n","Epoch  3, Batch 386 -Loss:   532.4685 Validation Accuracy: 0.785156\n","Epoch  3, Batch 387 -Loss:   482.4420 Validation Accuracy: 0.785156\n","Epoch  3, Batch 388 -Loss:   445.2565 Validation Accuracy: 0.789062\n","Epoch  3, Batch 389 -Loss:   666.8147 Validation Accuracy: 0.789062\n","Epoch  3, Batch 390 -Loss:   660.3059 Validation Accuracy: 0.796875\n","Epoch  3, Batch 391 -Loss:   783.3053 Validation Accuracy: 0.796875\n","Epoch  3, Batch 392 -Loss:   682.4480 Validation Accuracy: 0.796875\n","Epoch  3, Batch 393 -Loss:   678.5457 Validation Accuracy: 0.796875\n","Epoch  3, Batch 394 -Loss:   596.8168 Validation Accuracy: 0.800781\n","Epoch  3, Batch 395 -Loss:   571.7167 Validation Accuracy: 0.800781\n","Epoch  3, Batch 396 -Loss:   626.8759 Validation Accuracy: 0.789062\n","Epoch  3, Batch 397 -Loss:   656.8979 Validation Accuracy: 0.785156\n","Epoch  3, Batch 398 -Loss:   426.8702 Validation Accuracy: 0.781250\n","Epoch  3, Batch 399 -Loss:   697.7548 Validation Accuracy: 0.785156\n","Epoch  3, Batch 400 -Loss:   718.9932 Validation Accuracy: 0.785156\n","Epoch  3, Batch 401 -Loss:   538.9571 Validation Accuracy: 0.785156\n","Epoch  3, Batch 402 -Loss:   741.5237 Validation Accuracy: 0.785156\n","Epoch  3, Batch 403 -Loss:   618.6546 Validation Accuracy: 0.785156\n","Epoch  3, Batch 404 -Loss:   479.9373 Validation Accuracy: 0.785156\n","Epoch  3, Batch 405 -Loss:   562.9624 Validation Accuracy: 0.789062\n","Epoch  3, Batch 406 -Loss:   367.6031 Validation Accuracy: 0.789062\n","Epoch  3, Batch 407 -Loss:   510.8072 Validation Accuracy: 0.785156\n","Epoch  3, Batch 408 -Loss:   816.9252 Validation Accuracy: 0.785156\n","Epoch  3, Batch 409 -Loss:   639.8065 Validation Accuracy: 0.781250\n","Epoch  3, Batch 410 -Loss:   604.5247 Validation Accuracy: 0.773438\n","Epoch  3, Batch 411 -Loss:   491.9488 Validation Accuracy: 0.777344\n","Epoch  3, Batch 412 -Loss:   690.4266 Validation Accuracy: 0.781250\n","Epoch  3, Batch 413 -Loss:   568.3344 Validation Accuracy: 0.781250\n","Epoch  3, Batch 414 -Loss:   773.3668 Validation Accuracy: 0.777344\n","Epoch  3, Batch 415 -Loss:   560.2793 Validation Accuracy: 0.773438\n","Epoch  3, Batch 416 -Loss:   817.7827 Validation Accuracy: 0.777344\n","Epoch  3, Batch 417 -Loss:   325.0407 Validation Accuracy: 0.773438\n","Epoch  3, Batch 418 -Loss:   507.3190 Validation Accuracy: 0.765625\n","Epoch  3, Batch 419 -Loss:   507.3773 Validation Accuracy: 0.769531\n","Epoch  3, Batch 420 -Loss:   554.9334 Validation Accuracy: 0.765625\n","Epoch  3, Batch 421 -Loss:   542.8484 Validation Accuracy: 0.765625\n","Epoch  3, Batch 422 -Loss:   656.6657 Validation Accuracy: 0.773438\n","Epoch  3, Batch 423 -Loss:   515.9090 Validation Accuracy: 0.773438\n","Epoch  3, Batch 424 -Loss:   418.6653 Validation Accuracy: 0.769531\n","Epoch  3, Batch 425 -Loss:   534.7887 Validation Accuracy: 0.773438\n","Epoch  3, Batch 426 -Loss:   469.1909 Validation Accuracy: 0.773438\n","Epoch  3, Batch 427 -Loss:   691.6191 Validation Accuracy: 0.773438\n","Epoch  3, Batch 428 -Loss:   773.6038 Validation Accuracy: 0.769531\n","Epoch  3, Batch 429 -Loss:   830.3607 Validation Accuracy: 0.769531\n","Epoch  4, Batch   1 -Loss:   894.8040 Validation Accuracy: 0.777344\n","Epoch  4, Batch   2 -Loss:   739.1274 Validation Accuracy: 0.769531\n","Epoch  4, Batch   3 -Loss:   598.4790 Validation Accuracy: 0.777344\n","Epoch  4, Batch   4 -Loss:   605.2540 Validation Accuracy: 0.773438\n","Epoch  4, Batch   5 -Loss:   695.1228 Validation Accuracy: 0.769531\n","Epoch  4, Batch   6 -Loss:   577.7808 Validation Accuracy: 0.765625\n","Epoch  4, Batch   7 -Loss:   461.8400 Validation Accuracy: 0.765625\n","Epoch  4, Batch   8 -Loss:   912.8666 Validation Accuracy: 0.753906\n","Epoch  4, Batch   9 -Loss:   326.7745 Validation Accuracy: 0.753906\n","Epoch  4, Batch  10 -Loss:   389.1078 Validation Accuracy: 0.757812\n","Epoch  4, Batch  11 -Loss:   656.1701 Validation Accuracy: 0.765625\n","Epoch  4, Batch  12 -Loss:   603.8252 Validation Accuracy: 0.761719\n","Epoch  4, Batch  13 -Loss:   360.1307 Validation Accuracy: 0.761719\n","Epoch  4, Batch  14 -Loss:   352.0145 Validation Accuracy: 0.757812\n","Epoch  4, Batch  15 -Loss:   487.5194 Validation Accuracy: 0.761719\n","Epoch  4, Batch  16 -Loss:   516.0683 Validation Accuracy: 0.761719\n","Epoch  4, Batch  17 -Loss:   383.0492 Validation Accuracy: 0.757812\n","Epoch  4, Batch  18 -Loss:   751.7682 Validation Accuracy: 0.757812\n","Epoch  4, Batch  19 -Loss:   486.9950 Validation Accuracy: 0.769531\n","Epoch  4, Batch  20 -Loss:   452.0469 Validation Accuracy: 0.769531\n","Epoch  4, Batch  21 -Loss:   635.7796 Validation Accuracy: 0.769531\n","Epoch  4, Batch  22 -Loss:   769.9669 Validation Accuracy: 0.769531\n","Epoch  4, Batch  23 -Loss:   624.1140 Validation Accuracy: 0.769531\n","Epoch  4, Batch  24 -Loss:   522.7570 Validation Accuracy: 0.769531\n","Epoch  4, Batch  25 -Loss:   463.9091 Validation Accuracy: 0.769531\n","Epoch  4, Batch  26 -Loss:   483.0152 Validation Accuracy: 0.769531\n","Epoch  4, Batch  27 -Loss:   456.1897 Validation Accuracy: 0.761719\n","Epoch  4, Batch  28 -Loss:   549.4143 Validation Accuracy: 0.769531\n","Epoch  4, Batch  29 -Loss:   515.8652 Validation Accuracy: 0.773438\n","Epoch  4, Batch  30 -Loss:   516.3422 Validation Accuracy: 0.773438\n","Epoch  4, Batch  31 -Loss:   436.3361 Validation Accuracy: 0.777344\n","Epoch  4, Batch  32 -Loss:   259.9671 Validation Accuracy: 0.777344\n","Epoch  4, Batch  33 -Loss:   474.6747 Validation Accuracy: 0.777344\n","Epoch  4, Batch  34 -Loss:   470.7244 Validation Accuracy: 0.773438\n","Epoch  4, Batch  35 -Loss:   460.5953 Validation Accuracy: 0.773438\n","Epoch  4, Batch  36 -Loss:   417.1967 Validation Accuracy: 0.773438\n","Epoch  4, Batch  37 -Loss:   586.1918 Validation Accuracy: 0.769531\n","Epoch  4, Batch  38 -Loss:   551.6388 Validation Accuracy: 0.769531\n","Epoch  4, Batch  39 -Loss:   637.2878 Validation Accuracy: 0.773438\n","Epoch  4, Batch  40 -Loss:   472.2041 Validation Accuracy: 0.773438\n","Epoch  4, Batch  41 -Loss:   391.3887 Validation Accuracy: 0.777344\n","Epoch  4, Batch  42 -Loss:   592.8240 Validation Accuracy: 0.773438\n","Epoch  4, Batch  43 -Loss:   487.9054 Validation Accuracy: 0.773438\n","Epoch  4, Batch  44 -Loss:   765.6616 Validation Accuracy: 0.773438\n","Epoch  4, Batch  45 -Loss:   244.1247 Validation Accuracy: 0.773438\n","Epoch  4, Batch  46 -Loss:   493.6091 Validation Accuracy: 0.777344\n","Epoch  4, Batch  47 -Loss:   726.4994 Validation Accuracy: 0.781250\n","Epoch  4, Batch  48 -Loss:   351.9533 Validation Accuracy: 0.781250\n","Epoch  4, Batch  49 -Loss:   767.5217 Validation Accuracy: 0.777344\n","Epoch  4, Batch  50 -Loss:   696.5696 Validation Accuracy: 0.773438\n","Epoch  4, Batch  51 -Loss:   541.6978 Validation Accuracy: 0.769531\n","Epoch  4, Batch  52 -Loss:   467.9366 Validation Accuracy: 0.773438\n","Epoch  4, Batch  53 -Loss:   678.1370 Validation Accuracy: 0.773438\n","Epoch  4, Batch  54 -Loss:   740.9168 Validation Accuracy: 0.773438\n","Epoch  4, Batch  55 -Loss:   459.5595 Validation Accuracy: 0.765625\n","Epoch  4, Batch  56 -Loss:   772.1073 Validation Accuracy: 0.773438\n","Epoch  4, Batch  57 -Loss:   690.5588 Validation Accuracy: 0.773438\n","Epoch  4, Batch  58 -Loss:   655.0323 Validation Accuracy: 0.765625\n","Epoch  4, Batch  59 -Loss:   380.7838 Validation Accuracy: 0.769531\n","Epoch  4, Batch  60 -Loss:   629.5334 Validation Accuracy: 0.769531\n","Epoch  4, Batch  61 -Loss:   554.2976 Validation Accuracy: 0.773438\n","Epoch  4, Batch  62 -Loss:   390.8622 Validation Accuracy: 0.769531\n","Epoch  4, Batch  63 -Loss:   614.1334 Validation Accuracy: 0.773438\n","Epoch  4, Batch  64 -Loss:   227.3234 Validation Accuracy: 0.769531\n","Epoch  4, Batch  65 -Loss:   835.9591 Validation Accuracy: 0.765625\n","Epoch  4, Batch  66 -Loss:   564.5588 Validation Accuracy: 0.769531\n","Epoch  4, Batch  67 -Loss:   702.6305 Validation Accuracy: 0.765625\n","Epoch  4, Batch  68 -Loss:   525.5953 Validation Accuracy: 0.769531\n","Epoch  4, Batch  69 -Loss:   655.8713 Validation Accuracy: 0.765625\n","Epoch  4, Batch  70 -Loss:   784.1048 Validation Accuracy: 0.761719\n","Epoch  4, Batch  71 -Loss:   333.8220 Validation Accuracy: 0.765625\n","Epoch  4, Batch  72 -Loss:   666.8347 Validation Accuracy: 0.765625\n","Epoch  4, Batch  73 -Loss:   695.8067 Validation Accuracy: 0.765625\n","Epoch  4, Batch  74 -Loss:   280.7424 Validation Accuracy: 0.765625\n","Epoch  4, Batch  75 -Loss:   354.0375 Validation Accuracy: 0.769531\n","Epoch  4, Batch  76 -Loss:   601.0230 Validation Accuracy: 0.765625\n","Epoch  4, Batch  77 -Loss:   574.5532 Validation Accuracy: 0.765625\n","Epoch  4, Batch  78 -Loss:   507.4705 Validation Accuracy: 0.761719\n","Epoch  4, Batch  79 -Loss:   682.3493 Validation Accuracy: 0.765625\n","Epoch  4, Batch  80 -Loss:   534.7761 Validation Accuracy: 0.765625\n","Epoch  4, Batch  81 -Loss:   779.2089 Validation Accuracy: 0.765625\n","Epoch  4, Batch  82 -Loss:   429.8158 Validation Accuracy: 0.765625\n","Epoch  4, Batch  83 -Loss:   735.0086 Validation Accuracy: 0.765625\n","Epoch  4, Batch  84 -Loss:   724.4338 Validation Accuracy: 0.773438\n","Epoch  4, Batch  85 -Loss:   465.4081 Validation Accuracy: 0.773438\n","Epoch  4, Batch  86 -Loss:   419.2471 Validation Accuracy: 0.765625\n","Epoch  4, Batch  87 -Loss:   417.0129 Validation Accuracy: 0.765625\n","Epoch  4, Batch  88 -Loss:   440.0341 Validation Accuracy: 0.761719\n","Epoch  4, Batch  89 -Loss:   498.4304 Validation Accuracy: 0.757812\n","Epoch  4, Batch  90 -Loss:   516.1155 Validation Accuracy: 0.761719\n","Epoch  4, Batch  91 -Loss:   509.4421 Validation Accuracy: 0.765625\n","Epoch  4, Batch  92 -Loss:   471.3119 Validation Accuracy: 0.761719\n","Epoch  4, Batch  93 -Loss:   471.9700 Validation Accuracy: 0.769531\n","Epoch  4, Batch  94 -Loss:   487.2374 Validation Accuracy: 0.761719\n","Epoch  4, Batch  95 -Loss:   346.1329 Validation Accuracy: 0.761719\n","Epoch  4, Batch  96 -Loss:   488.6967 Validation Accuracy: 0.761719\n","Epoch  4, Batch  97 -Loss:   455.0267 Validation Accuracy: 0.761719\n","Epoch  4, Batch  98 -Loss:   615.0011 Validation Accuracy: 0.757812\n","Epoch  4, Batch  99 -Loss:   606.7025 Validation Accuracy: 0.761719\n","Epoch  4, Batch 100 -Loss:   704.6785 Validation Accuracy: 0.765625\n","Epoch  4, Batch 101 -Loss:   354.3159 Validation Accuracy: 0.765625\n","Epoch  4, Batch 102 -Loss:   577.7167 Validation Accuracy: 0.761719\n","Epoch  4, Batch 103 -Loss:   546.8533 Validation Accuracy: 0.757812\n","Epoch  4, Batch 104 -Loss:   243.6021 Validation Accuracy: 0.761719\n","Epoch  4, Batch 105 -Loss:   550.4401 Validation Accuracy: 0.753906\n","Epoch  4, Batch 106 -Loss:   327.3456 Validation Accuracy: 0.757812\n","Epoch  4, Batch 107 -Loss:   544.1108 Validation Accuracy: 0.757812\n","Epoch  4, Batch 108 -Loss:   567.9001 Validation Accuracy: 0.761719\n","Epoch  4, Batch 109 -Loss:   650.0273 Validation Accuracy: 0.757812\n","Epoch  4, Batch 110 -Loss:   431.1816 Validation Accuracy: 0.753906\n","Epoch  4, Batch 111 -Loss:   360.0092 Validation Accuracy: 0.761719\n","Epoch  4, Batch 112 -Loss:   532.6110 Validation Accuracy: 0.765625\n","Epoch  4, Batch 113 -Loss:   385.4660 Validation Accuracy: 0.769531\n","Epoch  4, Batch 114 -Loss:   562.7497 Validation Accuracy: 0.769531\n","Epoch  4, Batch 115 -Loss:   519.0366 Validation Accuracy: 0.769531\n","Epoch  4, Batch 116 -Loss:   262.7930 Validation Accuracy: 0.773438\n","Epoch  4, Batch 117 -Loss:   312.7106 Validation Accuracy: 0.777344\n","Epoch  4, Batch 118 -Loss:   537.8303 Validation Accuracy: 0.777344\n","Epoch  4, Batch 119 -Loss:   630.4509 Validation Accuracy: 0.777344\n","Epoch  4, Batch 120 -Loss:   856.3109 Validation Accuracy: 0.781250\n","Epoch  4, Batch 121 -Loss:   441.0363 Validation Accuracy: 0.773438\n","Epoch  4, Batch 122 -Loss:   334.4005 Validation Accuracy: 0.773438\n","Epoch  4, Batch 123 -Loss:   549.3154 Validation Accuracy: 0.765625\n","Epoch  4, Batch 124 -Loss:   496.3225 Validation Accuracy: 0.777344\n","Epoch  4, Batch 125 -Loss:   712.8092 Validation Accuracy: 0.769531\n","Epoch  4, Batch 126 -Loss:   641.0902 Validation Accuracy: 0.761719\n","Epoch  4, Batch 127 -Loss:   447.7518 Validation Accuracy: 0.757812\n","Epoch  4, Batch 128 -Loss:   714.4965 Validation Accuracy: 0.757812\n","Epoch  4, Batch 129 -Loss:   551.9548 Validation Accuracy: 0.757812\n","Epoch  4, Batch 130 -Loss:   406.2286 Validation Accuracy: 0.757812\n","Epoch  4, Batch 131 -Loss:   507.7666 Validation Accuracy: 0.753906\n","Epoch  4, Batch 132 -Loss:   579.7702 Validation Accuracy: 0.757812\n","Epoch  4, Batch 133 -Loss:   479.9080 Validation Accuracy: 0.757812\n","Epoch  4, Batch 134 -Loss:   402.1406 Validation Accuracy: 0.757812\n","Epoch  4, Batch 135 -Loss:   470.4056 Validation Accuracy: 0.761719\n","Epoch  4, Batch 136 -Loss:   337.3943 Validation Accuracy: 0.757812\n","Epoch  4, Batch 137 -Loss:   477.3702 Validation Accuracy: 0.757812\n","Epoch  4, Batch 138 -Loss:   581.3004 Validation Accuracy: 0.750000\n","Epoch  4, Batch 139 -Loss:   423.7834 Validation Accuracy: 0.757812\n","Epoch  4, Batch 140 -Loss:   587.3683 Validation Accuracy: 0.753906\n","Epoch  4, Batch 141 -Loss:   398.2577 Validation Accuracy: 0.757812\n","Epoch  4, Batch 142 -Loss:   449.6307 Validation Accuracy: 0.757812\n","Epoch  4, Batch 143 -Loss:   770.6520 Validation Accuracy: 0.765625\n","Epoch  4, Batch 144 -Loss:   621.4307 Validation Accuracy: 0.769531\n","Epoch  4, Batch 145 -Loss:   501.8696 Validation Accuracy: 0.761719\n","Epoch  4, Batch 146 -Loss:   357.9387 Validation Accuracy: 0.761719\n","Epoch  4, Batch 147 -Loss:   622.3138 Validation Accuracy: 0.773438\n","Epoch  4, Batch 148 -Loss:   477.8451 Validation Accuracy: 0.777344\n","Epoch  4, Batch 149 -Loss:   363.9075 Validation Accuracy: 0.757812\n","Epoch  4, Batch 150 -Loss:   469.6666 Validation Accuracy: 0.765625\n","Epoch  4, Batch 151 -Loss:   531.6118 Validation Accuracy: 0.765625\n","Epoch  4, Batch 152 -Loss:   620.4516 Validation Accuracy: 0.761719\n","Epoch  4, Batch 153 -Loss:   469.6633 Validation Accuracy: 0.765625\n","Epoch  4, Batch 154 -Loss:   587.1342 Validation Accuracy: 0.769531\n","Epoch  4, Batch 155 -Loss:   404.8618 Validation Accuracy: 0.773438\n","Epoch  4, Batch 156 -Loss:   336.2684 Validation Accuracy: 0.781250\n","Epoch  4, Batch 157 -Loss:   467.6151 Validation Accuracy: 0.773438\n","Epoch  4, Batch 158 -Loss:   661.5353 Validation Accuracy: 0.777344\n","Epoch  4, Batch 159 -Loss:   646.4605 Validation Accuracy: 0.769531\n","Epoch  4, Batch 160 -Loss:   505.5338 Validation Accuracy: 0.773438\n","Epoch  4, Batch 161 -Loss:   355.9100 Validation Accuracy: 0.781250\n","Epoch  4, Batch 162 -Loss:   636.6876 Validation Accuracy: 0.781250\n","Epoch  4, Batch 163 -Loss:   634.0087 Validation Accuracy: 0.777344\n","Epoch  4, Batch 164 -Loss:   556.1765 Validation Accuracy: 0.777344\n","Epoch  4, Batch 165 -Loss:   466.3258 Validation Accuracy: 0.785156\n","Epoch  4, Batch 166 -Loss:   488.8389 Validation Accuracy: 0.777344\n","Epoch  4, Batch 167 -Loss:   412.6278 Validation Accuracy: 0.777344\n","Epoch  4, Batch 168 -Loss:   515.5232 Validation Accuracy: 0.769531\n","Epoch  4, Batch 169 -Loss:   568.1771 Validation Accuracy: 0.777344\n","Epoch  4, Batch 170 -Loss:   548.2240 Validation Accuracy: 0.773438\n","Epoch  4, Batch 171 -Loss:   489.5089 Validation Accuracy: 0.773438\n","Epoch  4, Batch 172 -Loss:   678.0925 Validation Accuracy: 0.777344\n","Epoch  4, Batch 173 -Loss:   225.1377 Validation Accuracy: 0.777344\n","Epoch  4, Batch 174 -Loss:   497.1162 Validation Accuracy: 0.777344\n","Epoch  4, Batch 175 -Loss:   616.1228 Validation Accuracy: 0.773438\n","Epoch  4, Batch 176 -Loss:   306.0126 Validation Accuracy: 0.777344\n","Epoch  4, Batch 177 -Loss:   228.6624 Validation Accuracy: 0.777344\n","Epoch  4, Batch 178 -Loss:   421.3015 Validation Accuracy: 0.777344\n","Epoch  4, Batch 179 -Loss:   568.7925 Validation Accuracy: 0.785156\n","Epoch  4, Batch 180 -Loss:   483.7348 Validation Accuracy: 0.781250\n","Epoch  4, Batch 181 -Loss:   781.0932 Validation Accuracy: 0.785156\n","Epoch  4, Batch 182 -Loss:   499.7058 Validation Accuracy: 0.789062\n","Epoch  4, Batch 183 -Loss:   477.6030 Validation Accuracy: 0.789062\n","Epoch  4, Batch 184 -Loss:   499.4124 Validation Accuracy: 0.789062\n","Epoch  4, Batch 185 -Loss:   436.3291 Validation Accuracy: 0.789062\n","Epoch  4, Batch 186 -Loss:   407.0573 Validation Accuracy: 0.789062\n","Epoch  4, Batch 187 -Loss:   495.0562 Validation Accuracy: 0.789062\n","Epoch  4, Batch 188 -Loss:   284.1877 Validation Accuracy: 0.785156\n","Epoch  4, Batch 189 -Loss:   390.0736 Validation Accuracy: 0.781250\n","Epoch  4, Batch 190 -Loss:   433.9906 Validation Accuracy: 0.785156\n","Epoch  4, Batch 191 -Loss:   541.7188 Validation Accuracy: 0.789062\n","Epoch  4, Batch 192 -Loss:   596.7166 Validation Accuracy: 0.785156\n","Epoch  4, Batch 193 -Loss:   469.0857 Validation Accuracy: 0.777344\n","Epoch  4, Batch 194 -Loss:   555.5698 Validation Accuracy: 0.781250\n","Epoch  4, Batch 195 -Loss:   532.7214 Validation Accuracy: 0.785156\n","Epoch  4, Batch 196 -Loss:   539.2744 Validation Accuracy: 0.781250\n","Epoch  4, Batch 197 -Loss:   441.7827 Validation Accuracy: 0.781250\n","Epoch  4, Batch 198 -Loss:   609.9460 Validation Accuracy: 0.781250\n","Epoch  4, Batch 199 -Loss:   532.0958 Validation Accuracy: 0.781250\n","Epoch  4, Batch 200 -Loss:   442.7925 Validation Accuracy: 0.777344\n","Epoch  4, Batch 201 -Loss:   466.9729 Validation Accuracy: 0.773438\n","Epoch  4, Batch 202 -Loss:   572.3152 Validation Accuracy: 0.781250\n","Epoch  4, Batch 203 -Loss:   452.8430 Validation Accuracy: 0.777344\n","Epoch  4, Batch 204 -Loss:   566.1510 Validation Accuracy: 0.773438\n","Epoch  4, Batch 205 -Loss:   537.5300 Validation Accuracy: 0.777344\n","Epoch  4, Batch 206 -Loss:   455.4257 Validation Accuracy: 0.773438\n","Epoch  4, Batch 207 -Loss:   432.4021 Validation Accuracy: 0.769531\n","Epoch  4, Batch 208 -Loss:   473.5440 Validation Accuracy: 0.777344\n","Epoch  4, Batch 209 -Loss:   444.3041 Validation Accuracy: 0.773438\n","Epoch  4, Batch 210 -Loss:   444.1668 Validation Accuracy: 0.769531\n","Epoch  4, Batch 211 -Loss:   766.4254 Validation Accuracy: 0.781250\n","Epoch  4, Batch 212 -Loss:   531.7483 Validation Accuracy: 0.777344\n","Epoch  4, Batch 213 -Loss:   462.0572 Validation Accuracy: 0.777344\n","Epoch  4, Batch 214 -Loss:   549.1458 Validation Accuracy: 0.777344\n","Epoch  4, Batch 215 -Loss:   287.2512 Validation Accuracy: 0.785156\n","Epoch  4, Batch 216 -Loss:   342.4589 Validation Accuracy: 0.785156\n","Epoch  4, Batch 217 -Loss:   825.1151 Validation Accuracy: 0.785156\n","Epoch  4, Batch 218 -Loss:   501.1207 Validation Accuracy: 0.785156\n","Epoch  4, Batch 219 -Loss:   495.8705 Validation Accuracy: 0.781250\n","Epoch  4, Batch 220 -Loss:   519.6566 Validation Accuracy: 0.785156\n","Epoch  4, Batch 221 -Loss:   446.9636 Validation Accuracy: 0.773438\n","Epoch  4, Batch 222 -Loss:   757.5721 Validation Accuracy: 0.781250\n","Epoch  4, Batch 223 -Loss:   459.4675 Validation Accuracy: 0.773438\n","Epoch  4, Batch 224 -Loss:   511.8055 Validation Accuracy: 0.769531\n","Epoch  4, Batch 225 -Loss:   570.4731 Validation Accuracy: 0.773438\n","Epoch  4, Batch 226 -Loss:   709.5525 Validation Accuracy: 0.777344\n","Epoch  4, Batch 227 -Loss:   484.9354 Validation Accuracy: 0.781250\n","Epoch  4, Batch 228 -Loss:   589.4810 Validation Accuracy: 0.773438\n","Epoch  4, Batch 229 -Loss:   493.5540 Validation Accuracy: 0.777344\n","Epoch  4, Batch 230 -Loss:   498.7957 Validation Accuracy: 0.781250\n","Epoch  4, Batch 231 -Loss:   227.1287 Validation Accuracy: 0.781250\n","Epoch  4, Batch 232 -Loss:   450.5988 Validation Accuracy: 0.785156\n","Epoch  4, Batch 233 -Loss:   369.7990 Validation Accuracy: 0.781250\n","Epoch  4, Batch 234 -Loss:   373.6886 Validation Accuracy: 0.785156\n","Epoch  4, Batch 235 -Loss:   648.6648 Validation Accuracy: 0.789062\n","Epoch  4, Batch 236 -Loss:   351.0031 Validation Accuracy: 0.785156\n","Epoch  4, Batch 237 -Loss:   456.2879 Validation Accuracy: 0.792969\n","Epoch  4, Batch 238 -Loss:   483.4417 Validation Accuracy: 0.792969\n","Epoch  4, Batch 239 -Loss:   649.9728 Validation Accuracy: 0.785156\n","Epoch  4, Batch 240 -Loss:   403.8589 Validation Accuracy: 0.781250\n","Epoch  4, Batch 241 -Loss:   497.9487 Validation Accuracy: 0.785156\n","Epoch  4, Batch 242 -Loss:   550.5208 Validation Accuracy: 0.792969\n","Epoch  4, Batch 243 -Loss:   534.0133 Validation Accuracy: 0.792969\n","Epoch  4, Batch 244 -Loss:   413.1209 Validation Accuracy: 0.789062\n","Epoch  4, Batch 245 -Loss:   319.0482 Validation Accuracy: 0.789062\n","Epoch  4, Batch 246 -Loss:   489.7708 Validation Accuracy: 0.789062\n","Epoch  4, Batch 247 -Loss:   576.2095 Validation Accuracy: 0.792969\n","Epoch  4, Batch 248 -Loss:   234.4791 Validation Accuracy: 0.785156\n","Epoch  4, Batch 249 -Loss:   433.1337 Validation Accuracy: 0.785156\n","Epoch  4, Batch 250 -Loss:   511.7918 Validation Accuracy: 0.789062\n","Epoch  4, Batch 251 -Loss:   834.6758 Validation Accuracy: 0.781250\n","Epoch  4, Batch 252 -Loss:   619.2828 Validation Accuracy: 0.781250\n","Epoch  4, Batch 253 -Loss:   701.5153 Validation Accuracy: 0.773438\n","Epoch  4, Batch 254 -Loss:   432.2058 Validation Accuracy: 0.781250\n","Epoch  4, Batch 255 -Loss:   622.0103 Validation Accuracy: 0.785156\n","Epoch  4, Batch 256 -Loss:   267.9395 Validation Accuracy: 0.781250\n","Epoch  4, Batch 257 -Loss:   536.5096 Validation Accuracy: 0.789062\n","Epoch  4, Batch 258 -Loss:   570.0876 Validation Accuracy: 0.785156\n","Epoch  4, Batch 259 -Loss:   341.7814 Validation Accuracy: 0.785156\n","Epoch  4, Batch 260 -Loss:   238.7933 Validation Accuracy: 0.781250\n","Epoch  4, Batch 261 -Loss:   700.5129 Validation Accuracy: 0.781250\n","Epoch  4, Batch 262 -Loss:   616.9933 Validation Accuracy: 0.781250\n","Epoch  4, Batch 263 -Loss:   393.2762 Validation Accuracy: 0.781250\n","Epoch  4, Batch 264 -Loss:   388.5390 Validation Accuracy: 0.781250\n","Epoch  4, Batch 265 -Loss:   438.9081 Validation Accuracy: 0.789062\n","Epoch  4, Batch 266 -Loss:   403.7796 Validation Accuracy: 0.777344\n","Epoch  4, Batch 267 -Loss:   583.2448 Validation Accuracy: 0.777344\n","Epoch  4, Batch 268 -Loss:   348.9651 Validation Accuracy: 0.781250\n","Epoch  4, Batch 269 -Loss:   465.5758 Validation Accuracy: 0.785156\n","Epoch  4, Batch 270 -Loss:   350.0680 Validation Accuracy: 0.781250\n","Epoch  4, Batch 271 -Loss:   531.1574 Validation Accuracy: 0.792969\n","Epoch  4, Batch 272 -Loss:   357.0377 Validation Accuracy: 0.781250\n","Epoch  4, Batch 273 -Loss:   672.8613 Validation Accuracy: 0.781250\n","Epoch  4, Batch 274 -Loss:   283.5945 Validation Accuracy: 0.785156\n","Epoch  4, Batch 275 -Loss:   753.3116 Validation Accuracy: 0.781250\n","Epoch  4, Batch 276 -Loss:   350.5673 Validation Accuracy: 0.777344\n","Epoch  4, Batch 277 -Loss:   550.7048 Validation Accuracy: 0.781250\n","Epoch  4, Batch 278 -Loss:   417.9993 Validation Accuracy: 0.785156\n","Epoch  4, Batch 279 -Loss:   435.9937 Validation Accuracy: 0.789062\n","Epoch  4, Batch 280 -Loss:   354.5541 Validation Accuracy: 0.785156\n","Epoch  4, Batch 281 -Loss:   510.2438 Validation Accuracy: 0.789062\n","Epoch  4, Batch 282 -Loss:   466.5032 Validation Accuracy: 0.789062\n","Epoch  4, Batch 283 -Loss:   489.3970 Validation Accuracy: 0.789062\n","Epoch  4, Batch 284 -Loss:   530.0392 Validation Accuracy: 0.789062\n","Epoch  4, Batch 285 -Loss:   434.9503 Validation Accuracy: 0.789062\n","Epoch  4, Batch 286 -Loss:   484.0030 Validation Accuracy: 0.792969\n","Epoch  4, Batch 287 -Loss:   409.3729 Validation Accuracy: 0.789062\n","Epoch  4, Batch 288 -Loss:   446.3182 Validation Accuracy: 0.789062\n","Epoch  4, Batch 289 -Loss:   510.9426 Validation Accuracy: 0.792969\n","Epoch  4, Batch 290 -Loss:   395.7706 Validation Accuracy: 0.792969\n","Epoch  4, Batch 291 -Loss:   529.8849 Validation Accuracy: 0.792969\n","Epoch  4, Batch 292 -Loss:   347.8470 Validation Accuracy: 0.792969\n","Epoch  4, Batch 293 -Loss:   434.5118 Validation Accuracy: 0.796875\n","Epoch  4, Batch 294 -Loss:   595.4302 Validation Accuracy: 0.800781\n","Epoch  4, Batch 295 -Loss:   303.1344 Validation Accuracy: 0.789062\n","Epoch  4, Batch 296 -Loss:   692.2070 Validation Accuracy: 0.789062\n","Epoch  4, Batch 297 -Loss:   558.3253 Validation Accuracy: 0.792969\n","Epoch  4, Batch 298 -Loss:   545.1421 Validation Accuracy: 0.796875\n","Epoch  4, Batch 299 -Loss:   585.4960 Validation Accuracy: 0.789062\n","Epoch  4, Batch 300 -Loss:   633.3983 Validation Accuracy: 0.789062\n","Epoch  4, Batch 301 -Loss:   727.2815 Validation Accuracy: 0.789062\n","Epoch  4, Batch 302 -Loss:   651.2214 Validation Accuracy: 0.785156\n","Epoch  4, Batch 303 -Loss:   454.3658 Validation Accuracy: 0.789062\n","Epoch  4, Batch 304 -Loss:   400.1311 Validation Accuracy: 0.785156\n","Epoch  4, Batch 305 -Loss:   401.7953 Validation Accuracy: 0.785156\n","Epoch  4, Batch 306 -Loss:   406.4877 Validation Accuracy: 0.781250\n","Epoch  4, Batch 307 -Loss:   512.8364 Validation Accuracy: 0.781250\n","Epoch  4, Batch 308 -Loss:   420.7437 Validation Accuracy: 0.785156\n","Epoch  4, Batch 309 -Loss:   636.4033 Validation Accuracy: 0.781250\n","Epoch  4, Batch 310 -Loss:   544.0576 Validation Accuracy: 0.777344\n","Epoch  4, Batch 311 -Loss:   443.8567 Validation Accuracy: 0.781250\n","Epoch  4, Batch 312 -Loss:   459.8802 Validation Accuracy: 0.781250\n","Epoch  4, Batch 313 -Loss:   249.9859 Validation Accuracy: 0.777344\n","Epoch  4, Batch 314 -Loss:   433.0800 Validation Accuracy: 0.785156\n","Epoch  4, Batch 315 -Loss:   408.9859 Validation Accuracy: 0.781250\n","Epoch  4, Batch 316 -Loss:   405.8353 Validation Accuracy: 0.781250\n","Epoch  4, Batch 317 -Loss:   343.1140 Validation Accuracy: 0.781250\n","Epoch  4, Batch 318 -Loss:   605.3264 Validation Accuracy: 0.781250\n","Epoch  4, Batch 319 -Loss:   575.5421 Validation Accuracy: 0.773438\n","Epoch  4, Batch 320 -Loss:   501.8129 Validation Accuracy: 0.781250\n","Epoch  4, Batch 321 -Loss:   278.5436 Validation Accuracy: 0.773438\n","Epoch  4, Batch 322 -Loss:   427.7989 Validation Accuracy: 0.773438\n","Epoch  4, Batch 323 -Loss:   474.8837 Validation Accuracy: 0.785156\n","Epoch  4, Batch 324 -Loss:   506.4218 Validation Accuracy: 0.777344\n","Epoch  4, Batch 325 -Loss:   599.1163 Validation Accuracy: 0.781250\n","Epoch  4, Batch 326 -Loss:   466.0880 Validation Accuracy: 0.777344\n","Epoch  4, Batch 327 -Loss:   547.0360 Validation Accuracy: 0.777344\n","Epoch  4, Batch 328 -Loss:   515.5881 Validation Accuracy: 0.777344\n","Epoch  4, Batch 329 -Loss:   404.1026 Validation Accuracy: 0.781250\n","Epoch  4, Batch 330 -Loss:   636.8236 Validation Accuracy: 0.785156\n","Epoch  4, Batch 331 -Loss:   312.5057 Validation Accuracy: 0.789062\n","Epoch  4, Batch 332 -Loss:   451.4516 Validation Accuracy: 0.785156\n","Epoch  4, Batch 333 -Loss:   440.9895 Validation Accuracy: 0.789062\n","Epoch  4, Batch 334 -Loss:   778.5990 Validation Accuracy: 0.792969\n","Epoch  4, Batch 335 -Loss:   470.7901 Validation Accuracy: 0.792969\n","Epoch  4, Batch 336 -Loss:   348.4430 Validation Accuracy: 0.789062\n","Epoch  4, Batch 337 -Loss:   453.0166 Validation Accuracy: 0.792969\n","Epoch  4, Batch 338 -Loss:   697.6335 Validation Accuracy: 0.785156\n","Epoch  4, Batch 339 -Loss:   395.5327 Validation Accuracy: 0.792969\n","Epoch  4, Batch 340 -Loss:   567.1344 Validation Accuracy: 0.792969\n","Epoch  4, Batch 341 -Loss:   228.9268 Validation Accuracy: 0.796875\n","Epoch  4, Batch 342 -Loss:   443.4552 Validation Accuracy: 0.800781\n","Epoch  4, Batch 343 -Loss:   447.9022 Validation Accuracy: 0.796875\n","Epoch  4, Batch 344 -Loss:   614.9614 Validation Accuracy: 0.796875\n","Epoch  4, Batch 345 -Loss:   431.2485 Validation Accuracy: 0.796875\n","Epoch  4, Batch 346 -Loss:   562.9459 Validation Accuracy: 0.800781\n","Epoch  4, Batch 347 -Loss:   612.5823 Validation Accuracy: 0.796875\n","Epoch  4, Batch 348 -Loss:   669.6182 Validation Accuracy: 0.789062\n","Epoch  4, Batch 349 -Loss:   672.1611 Validation Accuracy: 0.789062\n","Epoch  4, Batch 350 -Loss:   561.5453 Validation Accuracy: 0.804688\n","Epoch  4, Batch 351 -Loss:   409.8428 Validation Accuracy: 0.789062\n","Epoch  4, Batch 352 -Loss:   506.3551 Validation Accuracy: 0.789062\n","Epoch  4, Batch 353 -Loss:   436.0580 Validation Accuracy: 0.792969\n","Epoch  4, Batch 354 -Loss:   330.8965 Validation Accuracy: 0.789062\n","Epoch  4, Batch 355 -Loss:   304.6965 Validation Accuracy: 0.789062\n","Epoch  4, Batch 356 -Loss:   325.2564 Validation Accuracy: 0.789062\n","Epoch  4, Batch 357 -Loss:   410.3864 Validation Accuracy: 0.792969\n","Epoch  4, Batch 358 -Loss:   439.6074 Validation Accuracy: 0.796875\n","Epoch  4, Batch 359 -Loss:   490.7878 Validation Accuracy: 0.800781\n","Epoch  4, Batch 360 -Loss:   553.1902 Validation Accuracy: 0.792969\n","Epoch  4, Batch 361 -Loss:   516.6254 Validation Accuracy: 0.792969\n","Epoch  4, Batch 362 -Loss:   610.2385 Validation Accuracy: 0.792969\n","Epoch  4, Batch 363 -Loss:   602.0377 Validation Accuracy: 0.792969\n","Epoch  4, Batch 364 -Loss:   647.8144 Validation Accuracy: 0.800781\n","Epoch  4, Batch 365 -Loss:   482.0101 Validation Accuracy: 0.796875\n","Epoch  4, Batch 366 -Loss:   555.3772 Validation Accuracy: 0.796875\n","Epoch  4, Batch 367 -Loss:   390.6406 Validation Accuracy: 0.808594\n","Epoch  4, Batch 368 -Loss:   465.1465 Validation Accuracy: 0.804688\n","Epoch  4, Batch 369 -Loss:   379.5882 Validation Accuracy: 0.804688\n","Epoch  4, Batch 370 -Loss:   397.5497 Validation Accuracy: 0.796875\n","Epoch  4, Batch 371 -Loss:   227.6221 Validation Accuracy: 0.800781\n","Epoch  4, Batch 372 -Loss:   411.2376 Validation Accuracy: 0.789062\n","Epoch  4, Batch 373 -Loss:   431.3270 Validation Accuracy: 0.789062\n","Epoch  4, Batch 374 -Loss:   378.3839 Validation Accuracy: 0.785156\n","Epoch  4, Batch 375 -Loss:   434.1068 Validation Accuracy: 0.789062\n","Epoch  4, Batch 376 -Loss:   588.8864 Validation Accuracy: 0.792969\n","Epoch  4, Batch 377 -Loss:   559.9785 Validation Accuracy: 0.792969\n","Epoch  4, Batch 378 -Loss:   582.1553 Validation Accuracy: 0.789062\n","Epoch  4, Batch 379 -Loss:   398.1546 Validation Accuracy: 0.792969\n","Epoch  4, Batch 380 -Loss:   421.5856 Validation Accuracy: 0.792969\n","Epoch  4, Batch 381 -Loss:   513.3345 Validation Accuracy: 0.789062\n","Epoch  4, Batch 382 -Loss:   486.3022 Validation Accuracy: 0.785156\n","Epoch  4, Batch 383 -Loss:   436.1847 Validation Accuracy: 0.792969\n","Epoch  4, Batch 384 -Loss:   558.3739 Validation Accuracy: 0.789062\n","Epoch  4, Batch 385 -Loss:   422.8618 Validation Accuracy: 0.785156\n","Epoch  4, Batch 386 -Loss:   383.4090 Validation Accuracy: 0.777344\n","Epoch  4, Batch 387 -Loss:   356.3926 Validation Accuracy: 0.785156\n","Epoch  4, Batch 388 -Loss:   589.2932 Validation Accuracy: 0.785156\n","Epoch  4, Batch 389 -Loss:   440.3015 Validation Accuracy: 0.785156\n","Epoch  4, Batch 390 -Loss:   475.2957 Validation Accuracy: 0.785156\n","Epoch  4, Batch 391 -Loss:   316.6421 Validation Accuracy: 0.789062\n","Epoch  4, Batch 392 -Loss:   583.5885 Validation Accuracy: 0.789062\n","Epoch  4, Batch 393 -Loss:   450.6818 Validation Accuracy: 0.792969\n","Epoch  4, Batch 394 -Loss:   335.8670 Validation Accuracy: 0.792969\n","Epoch  4, Batch 395 -Loss:   515.2075 Validation Accuracy: 0.792969\n","Epoch  4, Batch 396 -Loss:   471.4632 Validation Accuracy: 0.792969\n","Epoch  4, Batch 397 -Loss:   590.9745 Validation Accuracy: 0.792969\n","Epoch  4, Batch 398 -Loss:   344.0414 Validation Accuracy: 0.792969\n","Epoch  4, Batch 399 -Loss:   603.1933 Validation Accuracy: 0.796875\n","Epoch  4, Batch 400 -Loss:   539.6100 Validation Accuracy: 0.796875\n","Epoch  4, Batch 401 -Loss:   489.0104 Validation Accuracy: 0.792969\n","Epoch  4, Batch 402 -Loss:   500.0376 Validation Accuracy: 0.800781\n","Epoch  4, Batch 403 -Loss:   306.8746 Validation Accuracy: 0.796875\n","Epoch  4, Batch 404 -Loss:   443.9708 Validation Accuracy: 0.792969\n","Epoch  4, Batch 405 -Loss:   622.0721 Validation Accuracy: 0.804688\n","Epoch  4, Batch 406 -Loss:   804.9570 Validation Accuracy: 0.804688\n","Epoch  4, Batch 407 -Loss:   501.1837 Validation Accuracy: 0.800781\n","Epoch  4, Batch 408 -Loss:   621.8745 Validation Accuracy: 0.792969\n","Epoch  4, Batch 409 -Loss:   297.0322 Validation Accuracy: 0.796875\n","Epoch  4, Batch 410 -Loss:   273.7874 Validation Accuracy: 0.789062\n","Epoch  4, Batch 411 -Loss:   511.3870 Validation Accuracy: 0.792969\n","Epoch  4, Batch 412 -Loss:   460.0315 Validation Accuracy: 0.792969\n","Epoch  4, Batch 413 -Loss:   468.0274 Validation Accuracy: 0.804688\n","Epoch  4, Batch 414 -Loss:   503.6079 Validation Accuracy: 0.789062\n","Epoch  4, Batch 415 -Loss:   601.4196 Validation Accuracy: 0.792969\n","Epoch  4, Batch 416 -Loss:   559.0848 Validation Accuracy: 0.796875\n","Epoch  4, Batch 417 -Loss:   528.0665 Validation Accuracy: 0.789062\n","Epoch  4, Batch 418 -Loss:   471.3220 Validation Accuracy: 0.789062\n","Epoch  4, Batch 419 -Loss:   445.0113 Validation Accuracy: 0.792969\n","Epoch  4, Batch 420 -Loss:   526.2723 Validation Accuracy: 0.796875\n","Epoch  4, Batch 421 -Loss:   455.7563 Validation Accuracy: 0.792969\n","Epoch  4, Batch 422 -Loss:   273.9716 Validation Accuracy: 0.796875\n","Epoch  4, Batch 423 -Loss:   350.3771 Validation Accuracy: 0.792969\n","Epoch  4, Batch 424 -Loss:   510.2546 Validation Accuracy: 0.789062\n","Epoch  4, Batch 425 -Loss:   565.5658 Validation Accuracy: 0.789062\n","Epoch  4, Batch 426 -Loss:   480.9789 Validation Accuracy: 0.789062\n","Epoch  4, Batch 427 -Loss:   418.5679 Validation Accuracy: 0.792969\n","Epoch  4, Batch 428 -Loss:   723.9684 Validation Accuracy: 0.796875\n","Epoch  4, Batch 429 -Loss:   523.7612 Validation Accuracy: 0.796875\n","Epoch  5, Batch   1 -Loss:   425.3316 Validation Accuracy: 0.792969\n","Epoch  5, Batch   2 -Loss:   158.1252 Validation Accuracy: 0.796875\n","Epoch  5, Batch   3 -Loss:   492.8078 Validation Accuracy: 0.796875\n","Epoch  5, Batch   4 -Loss:   448.8682 Validation Accuracy: 0.796875\n","Epoch  5, Batch   5 -Loss:   476.9905 Validation Accuracy: 0.796875\n","Epoch  5, Batch   6 -Loss:   699.7740 Validation Accuracy: 0.792969\n","Epoch  5, Batch   7 -Loss:   502.7905 Validation Accuracy: 0.796875\n","Epoch  5, Batch   8 -Loss:   345.8837 Validation Accuracy: 0.796875\n","Epoch  5, Batch   9 -Loss:   756.5320 Validation Accuracy: 0.796875\n","Epoch  5, Batch  10 -Loss:   299.9439 Validation Accuracy: 0.796875\n","Epoch  5, Batch  11 -Loss:   322.2390 Validation Accuracy: 0.796875\n","Epoch  5, Batch  12 -Loss:   540.1309 Validation Accuracy: 0.792969\n","Epoch  5, Batch  13 -Loss:   451.8073 Validation Accuracy: 0.792969\n","Epoch  5, Batch  14 -Loss:   443.7939 Validation Accuracy: 0.789062\n","Epoch  5, Batch  15 -Loss:   429.7854 Validation Accuracy: 0.796875\n","Epoch  5, Batch  16 -Loss:   278.1379 Validation Accuracy: 0.800781\n","Epoch  5, Batch  17 -Loss:   540.1109 Validation Accuracy: 0.792969\n","Epoch  5, Batch  18 -Loss:   522.8115 Validation Accuracy: 0.796875\n","Epoch  5, Batch  19 -Loss:   417.9024 Validation Accuracy: 0.792969\n","Epoch  5, Batch  20 -Loss:   387.8933 Validation Accuracy: 0.796875\n","Epoch  5, Batch  21 -Loss:   609.7725 Validation Accuracy: 0.804688\n","Epoch  5, Batch  22 -Loss:   458.3647 Validation Accuracy: 0.800781\n","Epoch  5, Batch  23 -Loss:   710.3036 Validation Accuracy: 0.804688\n","Epoch  5, Batch  24 -Loss:   386.9637 Validation Accuracy: 0.804688\n","Epoch  5, Batch  25 -Loss:   470.4721 Validation Accuracy: 0.804688\n","Epoch  5, Batch  26 -Loss:   573.8137 Validation Accuracy: 0.804688\n","Epoch  5, Batch  27 -Loss:   259.9685 Validation Accuracy: 0.804688\n","Epoch  5, Batch  28 -Loss:   449.2197 Validation Accuracy: 0.804688\n","Epoch  5, Batch  29 -Loss:   419.5118 Validation Accuracy: 0.800781\n","Epoch  5, Batch  30 -Loss:   513.1131 Validation Accuracy: 0.804688\n","Epoch  5, Batch  31 -Loss:   582.2330 Validation Accuracy: 0.800781\n","Epoch  5, Batch  32 -Loss:   441.6804 Validation Accuracy: 0.804688\n","Epoch  5, Batch  33 -Loss:   471.9979 Validation Accuracy: 0.800781\n","Epoch  5, Batch  34 -Loss:   525.6715 Validation Accuracy: 0.796875\n","Epoch  5, Batch  35 -Loss:   426.1887 Validation Accuracy: 0.796875\n","Epoch  5, Batch  36 -Loss:   273.2418 Validation Accuracy: 0.804688\n","Epoch  5, Batch  37 -Loss:   406.8812 Validation Accuracy: 0.796875\n","Epoch  5, Batch  38 -Loss:   239.1562 Validation Accuracy: 0.796875\n","Epoch  5, Batch  39 -Loss:   435.5455 Validation Accuracy: 0.800781\n","Epoch  5, Batch  40 -Loss:   373.5182 Validation Accuracy: 0.789062\n","Epoch  5, Batch  41 -Loss:   644.8945 Validation Accuracy: 0.789062\n","Epoch  5, Batch  42 -Loss:   474.8707 Validation Accuracy: 0.781250\n","Epoch  5, Batch  43 -Loss:   368.6058 Validation Accuracy: 0.789062\n","Epoch  5, Batch  44 -Loss:   525.5043 Validation Accuracy: 0.785156\n","Epoch  5, Batch  45 -Loss:   479.4807 Validation Accuracy: 0.785156\n","Epoch  5, Batch  46 -Loss:   472.0724 Validation Accuracy: 0.785156\n","Epoch  5, Batch  47 -Loss:   438.0488 Validation Accuracy: 0.781250\n","Epoch  5, Batch  48 -Loss:   610.6268 Validation Accuracy: 0.785156\n","Epoch  5, Batch  49 -Loss:   417.1127 Validation Accuracy: 0.781250\n","Epoch  5, Batch  50 -Loss:   404.2834 Validation Accuracy: 0.789062\n","Epoch  5, Batch  51 -Loss:   395.6782 Validation Accuracy: 0.792969\n","Epoch  5, Batch  52 -Loss:   579.4117 Validation Accuracy: 0.796875\n","Epoch  5, Batch  53 -Loss:   627.2279 Validation Accuracy: 0.796875\n","Epoch  5, Batch  54 -Loss:   511.6910 Validation Accuracy: 0.789062\n","Epoch  5, Batch  55 -Loss:   331.8330 Validation Accuracy: 0.792969\n","Epoch  5, Batch  56 -Loss:   453.2162 Validation Accuracy: 0.792969\n","Epoch  5, Batch  57 -Loss:   187.3968 Validation Accuracy: 0.792969\n","Epoch  5, Batch  58 -Loss:   452.0180 Validation Accuracy: 0.789062\n","Epoch  5, Batch  59 -Loss:   499.5028 Validation Accuracy: 0.785156\n","Epoch  5, Batch  60 -Loss:   427.9633 Validation Accuracy: 0.785156\n","Epoch  5, Batch  61 -Loss:   753.6779 Validation Accuracy: 0.789062\n","Epoch  5, Batch  62 -Loss:   404.3636 Validation Accuracy: 0.792969\n","Epoch  5, Batch  63 -Loss:   660.8073 Validation Accuracy: 0.792969\n","Epoch  5, Batch  64 -Loss:   452.9817 Validation Accuracy: 0.796875\n","Epoch  5, Batch  65 -Loss:   532.2676 Validation Accuracy: 0.804688\n","Epoch  5, Batch  66 -Loss:   353.9818 Validation Accuracy: 0.796875\n","Epoch  5, Batch  67 -Loss:   401.7874 Validation Accuracy: 0.800781\n","Epoch  5, Batch  68 -Loss:   490.4637 Validation Accuracy: 0.792969\n","Epoch  5, Batch  69 -Loss:   510.1547 Validation Accuracy: 0.792969\n","Epoch  5, Batch  70 -Loss:   611.5316 Validation Accuracy: 0.792969\n","Epoch  5, Batch  71 -Loss:   441.1470 Validation Accuracy: 0.792969\n","Epoch  5, Batch  72 -Loss:   366.8606 Validation Accuracy: 0.800781\n","Epoch  5, Batch  73 -Loss:   350.9768 Validation Accuracy: 0.800781\n","Epoch  5, Batch  74 -Loss:   443.1422 Validation Accuracy: 0.792969\n","Epoch  5, Batch  75 -Loss:   478.1907 Validation Accuracy: 0.804688\n","Epoch  5, Batch  76 -Loss:   430.2848 Validation Accuracy: 0.796875\n","Epoch  5, Batch  77 -Loss:   400.8294 Validation Accuracy: 0.804688\n","Epoch  5, Batch  78 -Loss:   665.7723 Validation Accuracy: 0.804688\n","Epoch  5, Batch  79 -Loss:   487.5887 Validation Accuracy: 0.804688\n","Epoch  5, Batch  80 -Loss:   344.7461 Validation Accuracy: 0.796875\n","Epoch  5, Batch  81 -Loss:   393.3234 Validation Accuracy: 0.792969\n","Epoch  5, Batch  82 -Loss:   285.6772 Validation Accuracy: 0.800781\n","Epoch  5, Batch  83 -Loss:   574.4812 Validation Accuracy: 0.800781\n","Epoch  5, Batch  84 -Loss:   317.5816 Validation Accuracy: 0.804688\n","Epoch  5, Batch  85 -Loss:   301.2518 Validation Accuracy: 0.800781\n","Epoch  5, Batch  86 -Loss:   215.6605 Validation Accuracy: 0.804688\n","Epoch  5, Batch  87 -Loss:   483.5933 Validation Accuracy: 0.804688\n","Epoch  5, Batch  88 -Loss:   332.8737 Validation Accuracy: 0.804688\n","Epoch  5, Batch  89 -Loss:   539.4598 Validation Accuracy: 0.804688\n","Epoch  5, Batch  90 -Loss:   339.8818 Validation Accuracy: 0.808594\n","Epoch  5, Batch  91 -Loss:   546.4059 Validation Accuracy: 0.808594\n","Epoch  5, Batch  92 -Loss:   404.3150 Validation Accuracy: 0.804688\n","Epoch  5, Batch  93 -Loss:   498.9946 Validation Accuracy: 0.789062\n","Epoch  5, Batch  94 -Loss:   290.7168 Validation Accuracy: 0.789062\n","Epoch  5, Batch  95 -Loss:   375.7428 Validation Accuracy: 0.789062\n","Epoch  5, Batch  96 -Loss:   391.0878 Validation Accuracy: 0.796875\n","Epoch  5, Batch  97 -Loss:   370.8505 Validation Accuracy: 0.796875\n","Epoch  5, Batch  98 -Loss:   232.4094 Validation Accuracy: 0.800781\n","Epoch  5, Batch  99 -Loss:   575.6971 Validation Accuracy: 0.812500\n","Epoch  5, Batch 100 -Loss:   376.6039 Validation Accuracy: 0.812500\n","Epoch  5, Batch 101 -Loss:   325.0271 Validation Accuracy: 0.808594\n","Epoch  5, Batch 102 -Loss:   437.6083 Validation Accuracy: 0.804688\n","Epoch  5, Batch 103 -Loss:   317.2365 Validation Accuracy: 0.800781\n","Epoch  5, Batch 104 -Loss:   335.9914 Validation Accuracy: 0.800781\n","Epoch  5, Batch 105 -Loss:   393.1041 Validation Accuracy: 0.800781\n","Epoch  5, Batch 106 -Loss:   442.9886 Validation Accuracy: 0.800781\n","Epoch  5, Batch 107 -Loss:   204.8159 Validation Accuracy: 0.804688\n","Epoch  5, Batch 108 -Loss:   459.5684 Validation Accuracy: 0.804688\n","Epoch  5, Batch 109 -Loss:   397.2353 Validation Accuracy: 0.800781\n","Epoch  5, Batch 110 -Loss:   456.4972 Validation Accuracy: 0.796875\n","Epoch  5, Batch 111 -Loss:   477.6542 Validation Accuracy: 0.800781\n","Epoch  5, Batch 112 -Loss:   395.6744 Validation Accuracy: 0.796875\n","Epoch  5, Batch 113 -Loss:   385.1626 Validation Accuracy: 0.789062\n","Epoch  5, Batch 114 -Loss:   500.7589 Validation Accuracy: 0.789062\n","Epoch  5, Batch 115 -Loss:   415.2538 Validation Accuracy: 0.785156\n","Epoch  5, Batch 116 -Loss:   400.6195 Validation Accuracy: 0.785156\n","Epoch  5, Batch 117 -Loss:   321.5074 Validation Accuracy: 0.789062\n","Epoch  5, Batch 118 -Loss:   565.1786 Validation Accuracy: 0.785156\n","Epoch  5, Batch 119 -Loss:   318.1457 Validation Accuracy: 0.785156\n","Epoch  5, Batch 120 -Loss:   355.9445 Validation Accuracy: 0.781250\n","Epoch  5, Batch 121 -Loss:   297.0404 Validation Accuracy: 0.789062\n","Epoch  5, Batch 122 -Loss:   374.5806 Validation Accuracy: 0.785156\n","Epoch  5, Batch 123 -Loss:   228.6126 Validation Accuracy: 0.785156\n","Epoch  5, Batch 124 -Loss:   385.2671 Validation Accuracy: 0.781250\n","Epoch  5, Batch 125 -Loss:   359.4532 Validation Accuracy: 0.785156\n","Epoch  5, Batch 126 -Loss:   357.2386 Validation Accuracy: 0.781250\n","Epoch  5, Batch 127 -Loss:   496.9490 Validation Accuracy: 0.785156\n","Epoch  5, Batch 128 -Loss:   370.4387 Validation Accuracy: 0.785156\n","Epoch  5, Batch 129 -Loss:   383.7154 Validation Accuracy: 0.781250\n","Epoch  5, Batch 130 -Loss:   535.0105 Validation Accuracy: 0.785156\n","Epoch  5, Batch 131 -Loss:   453.1930 Validation Accuracy: 0.785156\n","Epoch  5, Batch 132 -Loss:   497.6262 Validation Accuracy: 0.796875\n","Epoch  5, Batch 133 -Loss:   431.4818 Validation Accuracy: 0.792969\n","Epoch  5, Batch 134 -Loss:   330.0019 Validation Accuracy: 0.792969\n","Epoch  5, Batch 135 -Loss:   388.2683 Validation Accuracy: 0.789062\n","Epoch  5, Batch 136 -Loss:   291.5353 Validation Accuracy: 0.785156\n","Epoch  5, Batch 137 -Loss:   447.6685 Validation Accuracy: 0.785156\n","Epoch  5, Batch 138 -Loss:   503.4906 Validation Accuracy: 0.789062\n","Epoch  5, Batch 139 -Loss:   403.6728 Validation Accuracy: 0.789062\n","Epoch  5, Batch 140 -Loss:   372.0364 Validation Accuracy: 0.785156\n","Epoch  5, Batch 141 -Loss:   363.6187 Validation Accuracy: 0.785156\n","Epoch  5, Batch 142 -Loss:   423.6038 Validation Accuracy: 0.781250\n","Epoch  5, Batch 143 -Loss:   430.1468 Validation Accuracy: 0.781250\n","Epoch  5, Batch 144 -Loss:   335.7387 Validation Accuracy: 0.781250\n","Epoch  5, Batch 145 -Loss:   412.5539 Validation Accuracy: 0.785156\n","Epoch  5, Batch 146 -Loss:   399.9058 Validation Accuracy: 0.777344\n","Epoch  5, Batch 147 -Loss:   447.0787 Validation Accuracy: 0.777344\n","Epoch  5, Batch 148 -Loss:   243.5999 Validation Accuracy: 0.777344\n","Epoch  5, Batch 149 -Loss:   456.0412 Validation Accuracy: 0.777344\n","Epoch  5, Batch 150 -Loss:   220.4594 Validation Accuracy: 0.773438\n","Epoch  5, Batch 151 -Loss:   544.2497 Validation Accuracy: 0.777344\n","Epoch  5, Batch 152 -Loss:   569.3989 Validation Accuracy: 0.773438\n","Epoch  5, Batch 153 -Loss:   395.2738 Validation Accuracy: 0.777344\n","Epoch  5, Batch 154 -Loss:   242.5057 Validation Accuracy: 0.777344\n","Epoch  5, Batch 155 -Loss:   385.0328 Validation Accuracy: 0.781250\n","Epoch  5, Batch 156 -Loss:   324.7840 Validation Accuracy: 0.781250\n","Epoch  5, Batch 157 -Loss:   372.7570 Validation Accuracy: 0.781250\n","Epoch  5, Batch 158 -Loss:   380.1541 Validation Accuracy: 0.785156\n","Epoch  5, Batch 159 -Loss:   411.8481 Validation Accuracy: 0.781250\n","Epoch  5, Batch 160 -Loss:   375.2070 Validation Accuracy: 0.781250\n","Epoch  5, Batch 161 -Loss:   404.0971 Validation Accuracy: 0.777344\n","Epoch  5, Batch 162 -Loss:   349.9140 Validation Accuracy: 0.785156\n","Epoch  5, Batch 163 -Loss:   549.0156 Validation Accuracy: 0.785156\n","Epoch  5, Batch 164 -Loss:   484.5634 Validation Accuracy: 0.777344\n","Epoch  5, Batch 165 -Loss:   444.1342 Validation Accuracy: 0.777344\n","Epoch  5, Batch 166 -Loss:   371.3646 Validation Accuracy: 0.781250\n","Epoch  5, Batch 167 -Loss:   643.8356 Validation Accuracy: 0.785156\n","Epoch  5, Batch 168 -Loss:   405.3121 Validation Accuracy: 0.781250\n","Epoch  5, Batch 169 -Loss:   362.9869 Validation Accuracy: 0.777344\n","Epoch  5, Batch 170 -Loss:   339.5564 Validation Accuracy: 0.781250\n","Epoch  5, Batch 171 -Loss:   483.6699 Validation Accuracy: 0.769531\n","Epoch  5, Batch 172 -Loss:   599.2161 Validation Accuracy: 0.781250\n","Epoch  5, Batch 173 -Loss:   568.4484 Validation Accuracy: 0.773438\n","Epoch  5, Batch 174 -Loss:   191.7061 Validation Accuracy: 0.781250\n","Epoch  5, Batch 175 -Loss:   519.7684 Validation Accuracy: 0.781250\n","Epoch  5, Batch 176 -Loss:   370.8421 Validation Accuracy: 0.781250\n","Epoch  5, Batch 177 -Loss:   357.2370 Validation Accuracy: 0.789062\n","Epoch  5, Batch 178 -Loss:   522.2272 Validation Accuracy: 0.789062\n","Epoch  5, Batch 179 -Loss:   490.8095 Validation Accuracy: 0.785156\n","Epoch  5, Batch 180 -Loss:   368.3815 Validation Accuracy: 0.789062\n","Epoch  5, Batch 181 -Loss:   397.5436 Validation Accuracy: 0.785156\n","Epoch  5, Batch 182 -Loss:   527.3436 Validation Accuracy: 0.785156\n","Epoch  5, Batch 183 -Loss:   484.3620 Validation Accuracy: 0.792969\n","Epoch  5, Batch 184 -Loss:   351.8951 Validation Accuracy: 0.789062\n","Epoch  5, Batch 185 -Loss:   406.5312 Validation Accuracy: 0.781250\n","Epoch  5, Batch 186 -Loss:   579.8420 Validation Accuracy: 0.781250\n","Epoch  5, Batch 187 -Loss:   682.6496 Validation Accuracy: 0.781250\n","Epoch  5, Batch 188 -Loss:   403.1522 Validation Accuracy: 0.785156\n","Epoch  5, Batch 189 -Loss:   592.5492 Validation Accuracy: 0.785156\n","Epoch  5, Batch 190 -Loss:   488.7320 Validation Accuracy: 0.781250\n","Epoch  5, Batch 191 -Loss:   571.4990 Validation Accuracy: 0.785156\n","Epoch  5, Batch 192 -Loss:   291.9475 Validation Accuracy: 0.785156\n","Epoch  5, Batch 193 -Loss:   482.4735 Validation Accuracy: 0.781250\n","Epoch  5, Batch 194 -Loss:   328.1448 Validation Accuracy: 0.781250\n","Epoch  5, Batch 195 -Loss:   278.6903 Validation Accuracy: 0.781250\n","Epoch  5, Batch 196 -Loss:   430.4420 Validation Accuracy: 0.781250\n","Epoch  5, Batch 197 -Loss:   279.6662 Validation Accuracy: 0.777344\n","Epoch  5, Batch 198 -Loss:   465.5558 Validation Accuracy: 0.789062\n","Epoch  5, Batch 199 -Loss:   421.1210 Validation Accuracy: 0.785156\n","Epoch  5, Batch 200 -Loss:   515.4308 Validation Accuracy: 0.792969\n","Epoch  5, Batch 201 -Loss:   593.0360 Validation Accuracy: 0.792969\n","Epoch  5, Batch 202 -Loss:   540.1401 Validation Accuracy: 0.792969\n","Epoch  5, Batch 203 -Loss:   389.3619 Validation Accuracy: 0.792969\n","Epoch  5, Batch 204 -Loss:   379.4588 Validation Accuracy: 0.792969\n","Epoch  5, Batch 205 -Loss:   479.8380 Validation Accuracy: 0.800781\n","Epoch  5, Batch 206 -Loss:   287.5052 Validation Accuracy: 0.800781\n","Epoch  5, Batch 207 -Loss:   374.5229 Validation Accuracy: 0.792969\n","Epoch  5, Batch 208 -Loss:   363.8818 Validation Accuracy: 0.792969\n","Epoch  5, Batch 209 -Loss:   311.6574 Validation Accuracy: 0.800781\n","Epoch  5, Batch 210 -Loss:   471.5098 Validation Accuracy: 0.800781\n","Epoch  5, Batch 211 -Loss:   571.0557 Validation Accuracy: 0.792969\n","Epoch  5, Batch 212 -Loss:   589.1056 Validation Accuracy: 0.804688\n","Epoch  5, Batch 213 -Loss:   439.1651 Validation Accuracy: 0.796875\n","Epoch  5, Batch 214 -Loss:   364.0007 Validation Accuracy: 0.789062\n","Epoch  5, Batch 215 -Loss:   500.9305 Validation Accuracy: 0.789062\n","Epoch  5, Batch 216 -Loss:   266.2153 Validation Accuracy: 0.785156\n","Epoch  5, Batch 217 -Loss:   586.4705 Validation Accuracy: 0.781250\n","Epoch  5, Batch 218 -Loss:   360.1832 Validation Accuracy: 0.781250\n","Epoch  5, Batch 219 -Loss:   219.9423 Validation Accuracy: 0.785156\n","Epoch  5, Batch 220 -Loss:   423.8666 Validation Accuracy: 0.789062\n","Epoch  5, Batch 221 -Loss:   588.2943 Validation Accuracy: 0.789062\n","Epoch  5, Batch 222 -Loss:   298.6970 Validation Accuracy: 0.781250\n","Epoch  5, Batch 223 -Loss:   398.6828 Validation Accuracy: 0.785156\n","Epoch  5, Batch 224 -Loss:   620.7688 Validation Accuracy: 0.792969\n","Epoch  5, Batch 225 -Loss:   463.6808 Validation Accuracy: 0.789062\n","Epoch  5, Batch 226 -Loss:   379.4551 Validation Accuracy: 0.789062\n","Epoch  5, Batch 227 -Loss:   458.0059 Validation Accuracy: 0.792969\n","Epoch  5, Batch 228 -Loss:   329.0390 Validation Accuracy: 0.792969\n","Epoch  5, Batch 229 -Loss:   418.9169 Validation Accuracy: 0.792969\n","Epoch  5, Batch 230 -Loss:   238.3957 Validation Accuracy: 0.789062\n","Epoch  5, Batch 231 -Loss:   360.6117 Validation Accuracy: 0.789062\n","Epoch  5, Batch 232 -Loss:   493.2125 Validation Accuracy: 0.792969\n","Epoch  5, Batch 233 -Loss:   323.5157 Validation Accuracy: 0.792969\n","Epoch  5, Batch 234 -Loss:   496.8798 Validation Accuracy: 0.792969\n","Epoch  5, Batch 235 -Loss:   475.8364 Validation Accuracy: 0.785156\n","Epoch  5, Batch 236 -Loss:   450.3790 Validation Accuracy: 0.789062\n","Epoch  5, Batch 237 -Loss:   344.9356 Validation Accuracy: 0.789062\n","Epoch  5, Batch 238 -Loss:   355.1979 Validation Accuracy: 0.789062\n","Epoch  5, Batch 239 -Loss:   463.7118 Validation Accuracy: 0.781250\n","Epoch  5, Batch 240 -Loss:   416.9570 Validation Accuracy: 0.785156\n","Epoch  5, Batch 241 -Loss:   245.9245 Validation Accuracy: 0.789062\n","Epoch  5, Batch 242 -Loss:   439.5074 Validation Accuracy: 0.789062\n","Epoch  5, Batch 243 -Loss:   452.9021 Validation Accuracy: 0.781250\n","Epoch  5, Batch 244 -Loss:   400.4207 Validation Accuracy: 0.789062\n","Epoch  5, Batch 245 -Loss:   455.2221 Validation Accuracy: 0.781250\n","Epoch  5, Batch 246 -Loss:   355.1650 Validation Accuracy: 0.785156\n","Epoch  5, Batch 247 -Loss:   375.5198 Validation Accuracy: 0.785156\n","Epoch  5, Batch 248 -Loss:   525.5068 Validation Accuracy: 0.785156\n","Epoch  5, Batch 249 -Loss:   542.8948 Validation Accuracy: 0.785156\n","Epoch  5, Batch 250 -Loss:   353.6846 Validation Accuracy: 0.785156\n","Epoch  5, Batch 251 -Loss:   254.0764 Validation Accuracy: 0.781250\n","Epoch  5, Batch 252 -Loss:   403.7770 Validation Accuracy: 0.781250\n","Epoch  5, Batch 253 -Loss:   305.6608 Validation Accuracy: 0.792969\n","Epoch  5, Batch 254 -Loss:   569.3466 Validation Accuracy: 0.789062\n","Epoch  5, Batch 255 -Loss:   348.4801 Validation Accuracy: 0.789062\n","Epoch  5, Batch 256 -Loss:   655.7925 Validation Accuracy: 0.796875\n","Epoch  5, Batch 257 -Loss:   494.6299 Validation Accuracy: 0.792969\n","Epoch  5, Batch 258 -Loss:   368.5559 Validation Accuracy: 0.796875\n","Epoch  5, Batch 259 -Loss:   462.7400 Validation Accuracy: 0.792969\n","Epoch  5, Batch 260 -Loss:   571.5567 Validation Accuracy: 0.785156\n","Epoch  5, Batch 261 -Loss:   430.4588 Validation Accuracy: 0.789062\n","Epoch  5, Batch 262 -Loss:   487.2064 Validation Accuracy: 0.785156\n","Epoch  5, Batch 263 -Loss:   262.3512 Validation Accuracy: 0.789062\n","Epoch  5, Batch 264 -Loss:   453.7433 Validation Accuracy: 0.781250\n","Epoch  5, Batch 265 -Loss:   366.1285 Validation Accuracy: 0.792969\n","Epoch  5, Batch 266 -Loss:   336.5929 Validation Accuracy: 0.785156\n","Epoch  5, Batch 267 -Loss:   426.2660 Validation Accuracy: 0.789062\n","Epoch  5, Batch 268 -Loss:   309.2485 Validation Accuracy: 0.789062\n","Epoch  5, Batch 269 -Loss:   471.0292 Validation Accuracy: 0.792969\n","Epoch  5, Batch 270 -Loss:   558.0599 Validation Accuracy: 0.792969\n","Epoch  5, Batch 271 -Loss:   419.6223 Validation Accuracy: 0.796875\n","Epoch  5, Batch 272 -Loss:   229.1849 Validation Accuracy: 0.792969\n","Epoch  5, Batch 273 -Loss:   265.1488 Validation Accuracy: 0.792969\n","Epoch  5, Batch 274 -Loss:   392.3878 Validation Accuracy: 0.796875\n","Epoch  5, Batch 275 -Loss:   364.1497 Validation Accuracy: 0.789062\n","Epoch  5, Batch 276 -Loss:   524.3060 Validation Accuracy: 0.789062\n","Epoch  5, Batch 277 -Loss:   469.2301 Validation Accuracy: 0.789062\n","Epoch  5, Batch 278 -Loss:   231.6842 Validation Accuracy: 0.785156\n","Epoch  5, Batch 279 -Loss:   266.5204 Validation Accuracy: 0.792969\n","Epoch  5, Batch 280 -Loss:   294.0125 Validation Accuracy: 0.789062\n","Epoch  5, Batch 281 -Loss:   267.0947 Validation Accuracy: 0.789062\n","Epoch  5, Batch 282 -Loss:   281.0740 Validation Accuracy: 0.789062\n","Epoch  5, Batch 283 -Loss:   456.1816 Validation Accuracy: 0.796875\n","Epoch  5, Batch 284 -Loss:   453.0030 Validation Accuracy: 0.789062\n","Epoch  5, Batch 285 -Loss:   362.2428 Validation Accuracy: 0.792969\n","Epoch  5, Batch 286 -Loss:   414.2316 Validation Accuracy: 0.792969\n","Epoch  5, Batch 287 -Loss:   466.6604 Validation Accuracy: 0.785156\n","Epoch  5, Batch 288 -Loss:   724.1490 Validation Accuracy: 0.785156\n","Epoch  5, Batch 289 -Loss:   406.4317 Validation Accuracy: 0.777344\n","Epoch  5, Batch 290 -Loss:   412.2602 Validation Accuracy: 0.785156\n","Epoch  5, Batch 291 -Loss:   324.6866 Validation Accuracy: 0.777344\n","Epoch  5, Batch 292 -Loss:   387.5203 Validation Accuracy: 0.781250\n","Epoch  5, Batch 293 -Loss:   364.4312 Validation Accuracy: 0.769531\n","Epoch  5, Batch 294 -Loss:   326.6711 Validation Accuracy: 0.785156\n","Epoch  5, Batch 295 -Loss:   505.9627 Validation Accuracy: 0.777344\n","Epoch  5, Batch 296 -Loss:   481.4402 Validation Accuracy: 0.773438\n","Epoch  5, Batch 297 -Loss:   229.6420 Validation Accuracy: 0.777344\n","Epoch  5, Batch 298 -Loss:   257.7673 Validation Accuracy: 0.785156\n","Epoch  5, Batch 299 -Loss:   368.3433 Validation Accuracy: 0.785156\n","Epoch  5, Batch 300 -Loss:   296.5253 Validation Accuracy: 0.789062\n","Epoch  5, Batch 301 -Loss:   240.3970 Validation Accuracy: 0.785156\n","Epoch  5, Batch 302 -Loss:   554.3181 Validation Accuracy: 0.789062\n","Epoch  5, Batch 303 -Loss:   380.3617 Validation Accuracy: 0.785156\n","Epoch  5, Batch 304 -Loss:   330.4707 Validation Accuracy: 0.781250\n","Epoch  5, Batch 305 -Loss:   446.1696 Validation Accuracy: 0.785156\n","Epoch  5, Batch 306 -Loss:   539.8118 Validation Accuracy: 0.785156\n","Epoch  5, Batch 307 -Loss:   310.6655 Validation Accuracy: 0.785156\n","Epoch  5, Batch 308 -Loss:   362.4566 Validation Accuracy: 0.781250\n","Epoch  5, Batch 309 -Loss:   473.0319 Validation Accuracy: 0.781250\n","Epoch  5, Batch 310 -Loss:   433.8696 Validation Accuracy: 0.781250\n","Epoch  5, Batch 311 -Loss:   566.9720 Validation Accuracy: 0.785156\n","Epoch  5, Batch 312 -Loss:   447.2925 Validation Accuracy: 0.785156\n","Epoch  5, Batch 313 -Loss:   369.2523 Validation Accuracy: 0.785156\n","Epoch  5, Batch 314 -Loss:   438.3648 Validation Accuracy: 0.781250\n","Epoch  5, Batch 315 -Loss:   352.9037 Validation Accuracy: 0.777344\n","Epoch  5, Batch 316 -Loss:   355.5977 Validation Accuracy: 0.789062\n","Epoch  5, Batch 317 -Loss:   386.2253 Validation Accuracy: 0.781250\n","Epoch  5, Batch 318 -Loss:   341.4365 Validation Accuracy: 0.785156\n","Epoch  5, Batch 319 -Loss:   569.2014 Validation Accuracy: 0.792969\n","Epoch  5, Batch 320 -Loss:   297.9226 Validation Accuracy: 0.789062\n","Epoch  5, Batch 321 -Loss:   486.4668 Validation Accuracy: 0.792969\n","Epoch  5, Batch 322 -Loss:   448.5308 Validation Accuracy: 0.796875\n","Epoch  5, Batch 323 -Loss:   314.3214 Validation Accuracy: 0.792969\n","Epoch  5, Batch 324 -Loss:   536.9291 Validation Accuracy: 0.792969\n","Epoch  5, Batch 325 -Loss:   297.8190 Validation Accuracy: 0.785156\n","Epoch  5, Batch 326 -Loss:   517.2682 Validation Accuracy: 0.792969\n","Epoch  5, Batch 327 -Loss:   263.7717 Validation Accuracy: 0.796875\n","Epoch  5, Batch 328 -Loss:   495.3788 Validation Accuracy: 0.796875\n","Epoch  5, Batch 329 -Loss:   287.0786 Validation Accuracy: 0.792969\n","Epoch  5, Batch 330 -Loss:   195.5775 Validation Accuracy: 0.796875\n","Epoch  5, Batch 331 -Loss:   413.2842 Validation Accuracy: 0.789062\n","Epoch  5, Batch 332 -Loss:   325.5383 Validation Accuracy: 0.792969\n","Epoch  5, Batch 333 -Loss:   375.7029 Validation Accuracy: 0.789062\n","Epoch  5, Batch 334 -Loss:   511.0824 Validation Accuracy: 0.789062\n","Epoch  5, Batch 335 -Loss:   342.2067 Validation Accuracy: 0.789062\n","Epoch  5, Batch 336 -Loss:   437.9723 Validation Accuracy: 0.792969\n","Epoch  5, Batch 337 -Loss:   278.7874 Validation Accuracy: 0.792969\n","Epoch  5, Batch 338 -Loss:   261.6202 Validation Accuracy: 0.800781\n","Epoch  5, Batch 339 -Loss:   674.1204 Validation Accuracy: 0.796875\n","Epoch  5, Batch 340 -Loss:   331.0436 Validation Accuracy: 0.796875\n","Epoch  5, Batch 341 -Loss:   398.7541 Validation Accuracy: 0.796875\n","Epoch  5, Batch 342 -Loss:   211.8580 Validation Accuracy: 0.792969\n","Epoch  5, Batch 343 -Loss:   383.4913 Validation Accuracy: 0.796875\n","Epoch  5, Batch 344 -Loss:   403.6024 Validation Accuracy: 0.789062\n","Epoch  5, Batch 345 -Loss:   316.6104 Validation Accuracy: 0.789062\n","Epoch  5, Batch 346 -Loss:   348.2557 Validation Accuracy: 0.785156\n","Epoch  5, Batch 347 -Loss:   408.7094 Validation Accuracy: 0.789062\n","Epoch  5, Batch 348 -Loss:   404.1828 Validation Accuracy: 0.789062\n","Epoch  5, Batch 349 -Loss:   387.8907 Validation Accuracy: 0.792969\n","Epoch  5, Batch 350 -Loss:   435.3253 Validation Accuracy: 0.792969\n","Epoch  5, Batch 351 -Loss:   545.9380 Validation Accuracy: 0.789062\n","Epoch  5, Batch 352 -Loss:   534.7271 Validation Accuracy: 0.789062\n","Epoch  5, Batch 353 -Loss:   247.3837 Validation Accuracy: 0.796875\n","Epoch  5, Batch 354 -Loss:   408.4488 Validation Accuracy: 0.792969\n","Epoch  5, Batch 355 -Loss:   436.6432 Validation Accuracy: 0.792969\n","Epoch  5, Batch 356 -Loss:   444.5670 Validation Accuracy: 0.789062\n","Epoch  5, Batch 357 -Loss:   373.5984 Validation Accuracy: 0.796875\n","Epoch  5, Batch 358 -Loss:   391.3323 Validation Accuracy: 0.804688\n","Epoch  5, Batch 359 -Loss:   370.4173 Validation Accuracy: 0.804688\n","Epoch  5, Batch 360 -Loss:   290.0612 Validation Accuracy: 0.804688\n","Epoch  5, Batch 361 -Loss:   383.5389 Validation Accuracy: 0.800781\n","Epoch  5, Batch 362 -Loss:   263.7495 Validation Accuracy: 0.800781\n","Epoch  5, Batch 363 -Loss:   277.0628 Validation Accuracy: 0.792969\n","Epoch  5, Batch 364 -Loss:   395.1089 Validation Accuracy: 0.792969\n","Epoch  5, Batch 365 -Loss:   469.5993 Validation Accuracy: 0.792969\n","Epoch  5, Batch 366 -Loss:   493.7827 Validation Accuracy: 0.796875\n","Epoch  5, Batch 367 -Loss:   184.1416 Validation Accuracy: 0.808594\n","Epoch  5, Batch 368 -Loss:   298.5265 Validation Accuracy: 0.804688\n","Epoch  5, Batch 369 -Loss:   523.0545 Validation Accuracy: 0.800781\n","Epoch  5, Batch 370 -Loss:   405.0879 Validation Accuracy: 0.796875\n","Epoch  5, Batch 371 -Loss:   318.8605 Validation Accuracy: 0.804688\n","Epoch  5, Batch 372 -Loss:   524.2542 Validation Accuracy: 0.804688\n","Epoch  5, Batch 373 -Loss:   478.9355 Validation Accuracy: 0.796875\n","Epoch  5, Batch 374 -Loss:   436.6070 Validation Accuracy: 0.792969\n","Epoch  5, Batch 375 -Loss:   377.7852 Validation Accuracy: 0.785156\n","Epoch  5, Batch 376 -Loss:   469.5831 Validation Accuracy: 0.792969\n","Epoch  5, Batch 377 -Loss:   332.0937 Validation Accuracy: 0.785156\n","Epoch  5, Batch 378 -Loss:   230.5595 Validation Accuracy: 0.785156\n","Epoch  5, Batch 379 -Loss:   378.3003 Validation Accuracy: 0.789062\n","Epoch  5, Batch 380 -Loss:   229.0534 Validation Accuracy: 0.785156\n","Epoch  5, Batch 381 -Loss:   325.5716 Validation Accuracy: 0.792969\n","Epoch  5, Batch 382 -Loss:   561.6988 Validation Accuracy: 0.789062\n","Epoch  5, Batch 383 -Loss:   427.0941 Validation Accuracy: 0.792969\n","Epoch  5, Batch 384 -Loss:   525.9441 Validation Accuracy: 0.792969\n","Epoch  5, Batch 385 -Loss:   464.4739 Validation Accuracy: 0.789062\n","Epoch  5, Batch 386 -Loss:   368.2630 Validation Accuracy: 0.789062\n","Epoch  5, Batch 387 -Loss:   425.9218 Validation Accuracy: 0.785156\n","Epoch  5, Batch 388 -Loss:   539.3777 Validation Accuracy: 0.789062\n","Epoch  5, Batch 389 -Loss:   304.0985 Validation Accuracy: 0.792969\n","Epoch  5, Batch 390 -Loss:   528.5894 Validation Accuracy: 0.785156\n","Epoch  5, Batch 391 -Loss:   289.1350 Validation Accuracy: 0.789062\n","Epoch  5, Batch 392 -Loss:   223.4364 Validation Accuracy: 0.785156\n","Epoch  5, Batch 393 -Loss:   439.3156 Validation Accuracy: 0.789062\n","Epoch  5, Batch 394 -Loss:   427.7242 Validation Accuracy: 0.789062\n","Epoch  5, Batch 395 -Loss:   285.4799 Validation Accuracy: 0.789062\n","Epoch  5, Batch 396 -Loss:   364.8555 Validation Accuracy: 0.792969\n","Epoch  5, Batch 397 -Loss:   502.5966 Validation Accuracy: 0.792969\n","Epoch  5, Batch 398 -Loss:   395.5269 Validation Accuracy: 0.792969\n","Epoch  5, Batch 399 -Loss:   361.3572 Validation Accuracy: 0.792969\n","Epoch  5, Batch 400 -Loss:   686.9856 Validation Accuracy: 0.800781\n","Epoch  5, Batch 401 -Loss:   421.1044 Validation Accuracy: 0.792969\n","Epoch  5, Batch 402 -Loss:   370.9946 Validation Accuracy: 0.792969\n","Epoch  5, Batch 403 -Loss:   255.1873 Validation Accuracy: 0.800781\n","Epoch  5, Batch 404 -Loss:   277.3293 Validation Accuracy: 0.792969\n","Epoch  5, Batch 405 -Loss:   336.5639 Validation Accuracy: 0.792969\n","Epoch  5, Batch 406 -Loss:   540.3923 Validation Accuracy: 0.781250\n","Epoch  5, Batch 407 -Loss:   453.6005 Validation Accuracy: 0.796875\n","Epoch  5, Batch 408 -Loss:   163.6096 Validation Accuracy: 0.789062\n","Epoch  5, Batch 409 -Loss:   359.5608 Validation Accuracy: 0.800781\n","Epoch  5, Batch 410 -Loss:   591.0891 Validation Accuracy: 0.800781\n","Epoch  5, Batch 411 -Loss:   384.8506 Validation Accuracy: 0.800781\n","Epoch  5, Batch 412 -Loss:   452.3132 Validation Accuracy: 0.796875\n","Epoch  5, Batch 413 -Loss:   376.8617 Validation Accuracy: 0.796875\n","Epoch  5, Batch 414 -Loss:   287.9844 Validation Accuracy: 0.796875\n","Epoch  5, Batch 415 -Loss:   589.4193 Validation Accuracy: 0.792969\n","Epoch  5, Batch 416 -Loss:   229.7157 Validation Accuracy: 0.796875\n","Epoch  5, Batch 417 -Loss:   438.1932 Validation Accuracy: 0.796875\n","Epoch  5, Batch 418 -Loss:   294.5453 Validation Accuracy: 0.800781\n","Epoch  5, Batch 419 -Loss:   350.1601 Validation Accuracy: 0.800781\n","Epoch  5, Batch 420 -Loss:   182.9393 Validation Accuracy: 0.800781\n","Epoch  5, Batch 421 -Loss:   368.0903 Validation Accuracy: 0.796875\n","Epoch  5, Batch 422 -Loss:   381.2077 Validation Accuracy: 0.800781\n","Epoch  5, Batch 423 -Loss:   181.7373 Validation Accuracy: 0.800781\n","Epoch  5, Batch 424 -Loss:   355.8786 Validation Accuracy: 0.800781\n","Epoch  5, Batch 425 -Loss:   442.1908 Validation Accuracy: 0.792969\n","Epoch  5, Batch 426 -Loss:   218.0570 Validation Accuracy: 0.792969\n","Epoch  5, Batch 427 -Loss:   479.3906 Validation Accuracy: 0.800781\n","Epoch  5, Batch 428 -Loss:   491.9221 Validation Accuracy: 0.804688\n","Epoch  5, Batch 429 -Loss:   109.8944 Validation Accuracy: 0.796875\n","Epoch  6, Batch   1 -Loss:   353.3824 Validation Accuracy: 0.800781\n","Epoch  6, Batch   2 -Loss:   328.4927 Validation Accuracy: 0.789062\n","Epoch  6, Batch   3 -Loss:   441.1503 Validation Accuracy: 0.796875\n","Epoch  6, Batch   4 -Loss:   444.2746 Validation Accuracy: 0.800781\n","Epoch  6, Batch   5 -Loss:   255.2567 Validation Accuracy: 0.796875\n","Epoch  6, Batch   6 -Loss:   246.0639 Validation Accuracy: 0.800781\n","Epoch  6, Batch   7 -Loss:   278.1615 Validation Accuracy: 0.800781\n","Epoch  6, Batch   8 -Loss:   442.6348 Validation Accuracy: 0.796875\n","Epoch  6, Batch   9 -Loss:   548.5266 Validation Accuracy: 0.800781\n","Epoch  6, Batch  10 -Loss:   414.5862 Validation Accuracy: 0.804688\n","Epoch  6, Batch  11 -Loss:   427.8916 Validation Accuracy: 0.804688\n","Epoch  6, Batch  12 -Loss:   393.3385 Validation Accuracy: 0.804688\n","Epoch  6, Batch  13 -Loss:   512.0610 Validation Accuracy: 0.808594\n","Epoch  6, Batch  14 -Loss:   364.3829 Validation Accuracy: 0.808594\n","Epoch  6, Batch  15 -Loss:   479.6834 Validation Accuracy: 0.808594\n","Epoch  6, Batch  16 -Loss:   327.5299 Validation Accuracy: 0.808594\n","Epoch  6, Batch  17 -Loss:   270.5604 Validation Accuracy: 0.808594\n","Epoch  6, Batch  18 -Loss:   420.5825 Validation Accuracy: 0.804688\n","Epoch  6, Batch  19 -Loss:   262.2262 Validation Accuracy: 0.804688\n","Epoch  6, Batch  20 -Loss:   436.6562 Validation Accuracy: 0.804688\n","Epoch  6, Batch  21 -Loss:   362.3563 Validation Accuracy: 0.808594\n","Epoch  6, Batch  22 -Loss:   284.2338 Validation Accuracy: 0.804688\n","Epoch  6, Batch  23 -Loss:   341.9966 Validation Accuracy: 0.800781\n","Epoch  6, Batch  24 -Loss:   339.9259 Validation Accuracy: 0.804688\n","Epoch  6, Batch  25 -Loss:   256.7444 Validation Accuracy: 0.796875\n","Epoch  6, Batch  26 -Loss:   375.4670 Validation Accuracy: 0.792969\n","Epoch  6, Batch  27 -Loss:   409.3096 Validation Accuracy: 0.796875\n","Epoch  6, Batch  28 -Loss:   498.1817 Validation Accuracy: 0.792969\n","Epoch  6, Batch  29 -Loss:   379.7618 Validation Accuracy: 0.789062\n","Epoch  6, Batch  30 -Loss:   603.5909 Validation Accuracy: 0.789062\n","Epoch  6, Batch  31 -Loss:   428.3795 Validation Accuracy: 0.785156\n","Epoch  6, Batch  32 -Loss:   395.0378 Validation Accuracy: 0.789062\n","Epoch  6, Batch  33 -Loss:   344.8010 Validation Accuracy: 0.785156\n","Epoch  6, Batch  34 -Loss:   452.1937 Validation Accuracy: 0.781250\n","Epoch  6, Batch  35 -Loss:   233.7465 Validation Accuracy: 0.781250\n","Epoch  6, Batch  36 -Loss:   352.8536 Validation Accuracy: 0.789062\n","Epoch  6, Batch  37 -Loss:   515.0669 Validation Accuracy: 0.789062\n","Epoch  6, Batch  38 -Loss:   473.3364 Validation Accuracy: 0.792969\n","Epoch  6, Batch  39 -Loss:   368.6891 Validation Accuracy: 0.792969\n","Epoch  6, Batch  40 -Loss:   336.1392 Validation Accuracy: 0.796875\n","Epoch  6, Batch  41 -Loss:   351.6347 Validation Accuracy: 0.792969\n","Epoch  6, Batch  42 -Loss:   180.3421 Validation Accuracy: 0.789062\n","Epoch  6, Batch  43 -Loss:   420.0427 Validation Accuracy: 0.796875\n","Epoch  6, Batch  44 -Loss:   261.3113 Validation Accuracy: 0.796875\n","Epoch  6, Batch  45 -Loss:   281.3375 Validation Accuracy: 0.792969\n","Epoch  6, Batch  46 -Loss:   365.0767 Validation Accuracy: 0.789062\n","Epoch  6, Batch  47 -Loss:   290.9015 Validation Accuracy: 0.789062\n","Epoch  6, Batch  48 -Loss:   480.9068 Validation Accuracy: 0.792969\n","Epoch  6, Batch  49 -Loss:   252.2495 Validation Accuracy: 0.796875\n","Epoch  6, Batch  50 -Loss:   539.6862 Validation Accuracy: 0.796875\n","Epoch  6, Batch  51 -Loss:   466.8653 Validation Accuracy: 0.800781\n","Epoch  6, Batch  52 -Loss:   463.7520 Validation Accuracy: 0.796875\n","Epoch  6, Batch  53 -Loss:   481.5492 Validation Accuracy: 0.800781\n","Epoch  6, Batch  54 -Loss:   524.7295 Validation Accuracy: 0.800781\n","Epoch  6, Batch  55 -Loss:   396.2743 Validation Accuracy: 0.792969\n","Epoch  6, Batch  56 -Loss:   448.5328 Validation Accuracy: 0.789062\n","Epoch  6, Batch  57 -Loss:   304.7899 Validation Accuracy: 0.796875\n","Epoch  6, Batch  58 -Loss:   547.6028 Validation Accuracy: 0.796875\n","Epoch  6, Batch  59 -Loss:   311.5689 Validation Accuracy: 0.796875\n","Epoch  6, Batch  60 -Loss:   363.9758 Validation Accuracy: 0.796875\n","Epoch  6, Batch  61 -Loss:   566.2350 Validation Accuracy: 0.789062\n","Epoch  6, Batch  62 -Loss:   415.5931 Validation Accuracy: 0.792969\n","Epoch  6, Batch  63 -Loss:   483.4852 Validation Accuracy: 0.792969\n","Epoch  6, Batch  64 -Loss:   480.7006 Validation Accuracy: 0.789062\n","Epoch  6, Batch  65 -Loss:   314.2322 Validation Accuracy: 0.792969\n","Epoch  6, Batch  66 -Loss:   273.1164 Validation Accuracy: 0.796875\n","Epoch  6, Batch  67 -Loss:   255.1668 Validation Accuracy: 0.796875\n","Epoch  6, Batch  68 -Loss:   543.3495 Validation Accuracy: 0.789062\n","Epoch  6, Batch  69 -Loss:   418.2018 Validation Accuracy: 0.785156\n","Epoch  6, Batch  70 -Loss:   238.3376 Validation Accuracy: 0.792969\n","Epoch  6, Batch  71 -Loss:   425.8901 Validation Accuracy: 0.792969\n","Epoch  6, Batch  72 -Loss:   381.7812 Validation Accuracy: 0.796875\n","Epoch  6, Batch  73 -Loss:   321.4376 Validation Accuracy: 0.800781\n","Epoch  6, Batch  74 -Loss:   516.6122 Validation Accuracy: 0.792969\n","Epoch  6, Batch  75 -Loss:   360.0473 Validation Accuracy: 0.789062\n","Epoch  6, Batch  76 -Loss:   470.6163 Validation Accuracy: 0.792969\n","Epoch  6, Batch  77 -Loss:   555.8376 Validation Accuracy: 0.792969\n","Epoch  6, Batch  78 -Loss:   322.3743 Validation Accuracy: 0.792969\n","Epoch  6, Batch  79 -Loss:   254.2688 Validation Accuracy: 0.796875\n","Epoch  6, Batch  80 -Loss:   397.2516 Validation Accuracy: 0.792969\n","Epoch  6, Batch  81 -Loss:   343.5362 Validation Accuracy: 0.796875\n","Epoch  6, Batch  82 -Loss:   403.4629 Validation Accuracy: 0.789062\n","Epoch  6, Batch  83 -Loss:   295.9082 Validation Accuracy: 0.789062\n","Epoch  6, Batch  84 -Loss:   240.4752 Validation Accuracy: 0.792969\n","Epoch  6, Batch  85 -Loss:   585.6171 Validation Accuracy: 0.796875\n","Epoch  6, Batch  86 -Loss:   441.4389 Validation Accuracy: 0.800781\n","Epoch  6, Batch  87 -Loss:   421.1395 Validation Accuracy: 0.800781\n","Epoch  6, Batch  88 -Loss:   375.9073 Validation Accuracy: 0.796875\n","Epoch  6, Batch  89 -Loss:   440.2254 Validation Accuracy: 0.796875\n","Epoch  6, Batch  90 -Loss:   388.5355 Validation Accuracy: 0.796875\n","Epoch  6, Batch  91 -Loss:   348.6470 Validation Accuracy: 0.796875\n","Epoch  6, Batch  92 -Loss:   473.0332 Validation Accuracy: 0.800781\n","Epoch  6, Batch  93 -Loss:   303.0059 Validation Accuracy: 0.800781\n","Epoch  6, Batch  94 -Loss:   347.4916 Validation Accuracy: 0.796875\n","Epoch  6, Batch  95 -Loss:   345.3754 Validation Accuracy: 0.796875\n","Epoch  6, Batch  96 -Loss:   584.3984 Validation Accuracy: 0.796875\n","Epoch  6, Batch  97 -Loss:   556.7264 Validation Accuracy: 0.796875\n","Epoch  6, Batch  98 -Loss:   382.5908 Validation Accuracy: 0.796875\n","Epoch  6, Batch  99 -Loss:   230.0971 Validation Accuracy: 0.792969\n","Epoch  6, Batch 100 -Loss:   220.0451 Validation Accuracy: 0.792969\n","Epoch  6, Batch 101 -Loss:   501.0595 Validation Accuracy: 0.792969\n","Epoch  6, Batch 102 -Loss:   507.4276 Validation Accuracy: 0.792969\n","Epoch  6, Batch 103 -Loss:   330.9305 Validation Accuracy: 0.792969\n","Epoch  6, Batch 104 -Loss:   343.7303 Validation Accuracy: 0.796875\n","Epoch  6, Batch 105 -Loss:   479.5345 Validation Accuracy: 0.796875\n","Epoch  6, Batch 106 -Loss:   249.0270 Validation Accuracy: 0.796875\n","Epoch  6, Batch 107 -Loss:   315.1179 Validation Accuracy: 0.800781\n","Epoch  6, Batch 108 -Loss:   349.4979 Validation Accuracy: 0.800781\n","Epoch  6, Batch 109 -Loss:   364.2354 Validation Accuracy: 0.796875\n","Epoch  6, Batch 110 -Loss:   484.2537 Validation Accuracy: 0.796875\n","Epoch  6, Batch 111 -Loss:   490.5110 Validation Accuracy: 0.796875\n","Epoch  6, Batch 112 -Loss:   300.2364 Validation Accuracy: 0.796875\n","Epoch  6, Batch 113 -Loss:   429.5785 Validation Accuracy: 0.800781\n","Epoch  6, Batch 114 -Loss:   471.0029 Validation Accuracy: 0.796875\n","Epoch  6, Batch 115 -Loss:   340.0558 Validation Accuracy: 0.796875\n","Epoch  6, Batch 116 -Loss:   442.3256 Validation Accuracy: 0.796875\n","Epoch  6, Batch 117 -Loss:   284.9844 Validation Accuracy: 0.796875\n","Epoch  6, Batch 118 -Loss:   311.4955 Validation Accuracy: 0.808594\n","Epoch  6, Batch 119 -Loss:   557.6471 Validation Accuracy: 0.812500\n","Epoch  6, Batch 120 -Loss:   366.5314 Validation Accuracy: 0.804688\n","Epoch  6, Batch 121 -Loss:   341.6930 Validation Accuracy: 0.808594\n","Epoch  6, Batch 122 -Loss:   366.4496 Validation Accuracy: 0.808594\n","Epoch  6, Batch 123 -Loss:   299.1094 Validation Accuracy: 0.808594\n","Epoch  6, Batch 124 -Loss:   414.7983 Validation Accuracy: 0.808594\n","Epoch  6, Batch 125 -Loss:   368.2868 Validation Accuracy: 0.808594\n","Epoch  6, Batch 126 -Loss:   188.1495 Validation Accuracy: 0.808594\n","Epoch  6, Batch 127 -Loss:   292.3752 Validation Accuracy: 0.808594\n","Epoch  6, Batch 128 -Loss:   400.7188 Validation Accuracy: 0.808594\n","Epoch  6, Batch 129 -Loss:   263.4720 Validation Accuracy: 0.808594\n","Epoch  6, Batch 130 -Loss:   420.4991 Validation Accuracy: 0.808594\n","Epoch  6, Batch 131 -Loss:   302.7340 Validation Accuracy: 0.808594\n","Epoch  6, Batch 132 -Loss:   188.0750 Validation Accuracy: 0.808594\n","Epoch  6, Batch 133 -Loss:   471.9391 Validation Accuracy: 0.804688\n","Epoch  6, Batch 134 -Loss:   404.8639 Validation Accuracy: 0.804688\n","Epoch  6, Batch 135 -Loss:   337.6995 Validation Accuracy: 0.808594\n","Epoch  6, Batch 136 -Loss:   146.4781 Validation Accuracy: 0.808594\n","Epoch  6, Batch 137 -Loss:   172.1263 Validation Accuracy: 0.812500\n","Epoch  6, Batch 138 -Loss:   338.9719 Validation Accuracy: 0.808594\n","Epoch  6, Batch 139 -Loss:   479.7929 Validation Accuracy: 0.804688\n","Epoch  6, Batch 140 -Loss:   332.9145 Validation Accuracy: 0.808594\n","Epoch  6, Batch 141 -Loss:   344.2317 Validation Accuracy: 0.812500\n","Epoch  6, Batch 142 -Loss:   272.8739 Validation Accuracy: 0.808594\n","Epoch  6, Batch 143 -Loss:   387.6808 Validation Accuracy: 0.812500\n","Epoch  6, Batch 144 -Loss:   388.1028 Validation Accuracy: 0.812500\n","Epoch  6, Batch 145 -Loss:   282.1339 Validation Accuracy: 0.812500\n","Epoch  6, Batch 146 -Loss:   370.6412 Validation Accuracy: 0.812500\n","Epoch  6, Batch 147 -Loss:   425.8870 Validation Accuracy: 0.808594\n","Epoch  6, Batch 148 -Loss:   398.5303 Validation Accuracy: 0.808594\n","Epoch  6, Batch 149 -Loss:   377.8766 Validation Accuracy: 0.804688\n","Epoch  6, Batch 150 -Loss:   517.9506 Validation Accuracy: 0.808594\n","Epoch  6, Batch 151 -Loss:   455.5789 Validation Accuracy: 0.804688\n","Epoch  6, Batch 152 -Loss:   297.0656 Validation Accuracy: 0.800781\n","Epoch  6, Batch 153 -Loss:   353.8568 Validation Accuracy: 0.800781\n","Epoch  6, Batch 154 -Loss:   537.0167 Validation Accuracy: 0.800781\n","Epoch  6, Batch 155 -Loss:   499.9009 Validation Accuracy: 0.796875\n","Epoch  6, Batch 156 -Loss:   328.6369 Validation Accuracy: 0.800781\n","Epoch  6, Batch 157 -Loss:   328.3529 Validation Accuracy: 0.796875\n","Epoch  6, Batch 158 -Loss:   378.8623 Validation Accuracy: 0.800781\n","Epoch  6, Batch 159 -Loss:   350.1661 Validation Accuracy: 0.800781\n","Epoch  6, Batch 160 -Loss:   512.2964 Validation Accuracy: 0.800781\n","Epoch  6, Batch 161 -Loss:   208.1144 Validation Accuracy: 0.800781\n","Epoch  6, Batch 162 -Loss:   547.6149 Validation Accuracy: 0.804688\n","Epoch  6, Batch 163 -Loss:   409.0556 Validation Accuracy: 0.804688\n","Epoch  6, Batch 164 -Loss:   233.3338 Validation Accuracy: 0.800781\n","Epoch  6, Batch 165 -Loss:   580.7941 Validation Accuracy: 0.800781\n","Epoch  6, Batch 166 -Loss:   261.7291 Validation Accuracy: 0.796875\n","Epoch  6, Batch 167 -Loss:   237.5072 Validation Accuracy: 0.796875\n","Epoch  6, Batch 168 -Loss:   165.5247 Validation Accuracy: 0.796875\n","Epoch  6, Batch 169 -Loss:   296.7878 Validation Accuracy: 0.800781\n","Epoch  6, Batch 170 -Loss:   427.5600 Validation Accuracy: 0.800781\n","Epoch  6, Batch 171 -Loss:   545.3217 Validation Accuracy: 0.800781\n","Epoch  6, Batch 172 -Loss:   363.2048 Validation Accuracy: 0.800781\n","Epoch  6, Batch 173 -Loss:   427.0699 Validation Accuracy: 0.800781\n","Epoch  6, Batch 174 -Loss:   206.1146 Validation Accuracy: 0.800781\n","Epoch  6, Batch 175 -Loss:   606.8322 Validation Accuracy: 0.800781\n","Epoch  6, Batch 176 -Loss:   280.0619 Validation Accuracy: 0.800781\n","Epoch  6, Batch 177 -Loss:   284.8620 Validation Accuracy: 0.804688\n","Epoch  6, Batch 178 -Loss:   419.4871 Validation Accuracy: 0.804688\n","Epoch  6, Batch 179 -Loss:   312.3866 Validation Accuracy: 0.804688\n","Epoch  6, Batch 180 -Loss:   411.2741 Validation Accuracy: 0.800781\n","Epoch  6, Batch 181 -Loss:   461.7792 Validation Accuracy: 0.796875\n","Epoch  6, Batch 182 -Loss:   431.0763 Validation Accuracy: 0.796875\n","Epoch  6, Batch 183 -Loss:   381.5667 Validation Accuracy: 0.796875\n","Epoch  6, Batch 184 -Loss:   389.3597 Validation Accuracy: 0.800781\n","Epoch  6, Batch 185 -Loss:   423.1897 Validation Accuracy: 0.796875\n","Epoch  6, Batch 186 -Loss:   372.4346 Validation Accuracy: 0.800781\n","Epoch  6, Batch 187 -Loss:   434.1224 Validation Accuracy: 0.792969\n","Epoch  6, Batch 188 -Loss:   448.5029 Validation Accuracy: 0.804688\n","Epoch  6, Batch 189 -Loss:   380.1125 Validation Accuracy: 0.804688\n","Epoch  6, Batch 190 -Loss:   451.4116 Validation Accuracy: 0.800781\n","Epoch  6, Batch 191 -Loss:   580.0359 Validation Accuracy: 0.800781\n","Epoch  6, Batch 192 -Loss:   396.5527 Validation Accuracy: 0.800781\n","Epoch  6, Batch 193 -Loss:   326.1237 Validation Accuracy: 0.800781\n","Epoch  6, Batch 194 -Loss:   280.5740 Validation Accuracy: 0.789062\n","Epoch  6, Batch 195 -Loss:   209.0610 Validation Accuracy: 0.789062\n","Epoch  6, Batch 196 -Loss:   269.4768 Validation Accuracy: 0.792969\n","Epoch  6, Batch 197 -Loss:   343.6859 Validation Accuracy: 0.796875\n","Epoch  6, Batch 198 -Loss:   355.5744 Validation Accuracy: 0.796875\n","Epoch  6, Batch 199 -Loss:   363.7382 Validation Accuracy: 0.792969\n","Epoch  6, Batch 200 -Loss:   262.1768 Validation Accuracy: 0.796875\n","Epoch  6, Batch 201 -Loss:   336.0581 Validation Accuracy: 0.789062\n","Epoch  6, Batch 202 -Loss:   377.0114 Validation Accuracy: 0.796875\n","Epoch  6, Batch 203 -Loss:   430.0358 Validation Accuracy: 0.796875\n","Epoch  6, Batch 204 -Loss:   401.6881 Validation Accuracy: 0.800781\n","Epoch  6, Batch 205 -Loss:   562.5540 Validation Accuracy: 0.796875\n","Epoch  6, Batch 206 -Loss:   313.4661 Validation Accuracy: 0.800781\n","Epoch  6, Batch 207 -Loss:   452.9553 Validation Accuracy: 0.796875\n","Epoch  6, Batch 208 -Loss:   485.3209 Validation Accuracy: 0.789062\n","Epoch  6, Batch 209 -Loss:   292.3811 Validation Accuracy: 0.792969\n","Epoch  6, Batch 210 -Loss:   268.8629 Validation Accuracy: 0.792969\n","Epoch  6, Batch 211 -Loss:   302.4720 Validation Accuracy: 0.792969\n","Epoch  6, Batch 212 -Loss:   353.3865 Validation Accuracy: 0.789062\n","Epoch  6, Batch 213 -Loss:   430.4539 Validation Accuracy: 0.789062\n","Epoch  6, Batch 214 -Loss:   258.0508 Validation Accuracy: 0.792969\n","Epoch  6, Batch 215 -Loss:   305.5312 Validation Accuracy: 0.796875\n","Epoch  6, Batch 216 -Loss:   279.8594 Validation Accuracy: 0.785156\n","Epoch  6, Batch 217 -Loss:   555.9208 Validation Accuracy: 0.781250\n","Epoch  6, Batch 218 -Loss:   366.5875 Validation Accuracy: 0.789062\n","Epoch  6, Batch 219 -Loss:   324.1288 Validation Accuracy: 0.789062\n","Epoch  6, Batch 220 -Loss:   388.5424 Validation Accuracy: 0.785156\n","Epoch  6, Batch 221 -Loss:   211.8115 Validation Accuracy: 0.792969\n","Epoch  6, Batch 222 -Loss:   359.2126 Validation Accuracy: 0.789062\n","Epoch  6, Batch 223 -Loss:   202.8553 Validation Accuracy: 0.792969\n","Epoch  6, Batch 224 -Loss:   339.8260 Validation Accuracy: 0.792969\n","Epoch  6, Batch 225 -Loss:   266.2201 Validation Accuracy: 0.792969\n","Epoch  6, Batch 226 -Loss:   253.8577 Validation Accuracy: 0.792969\n","Epoch  6, Batch 227 -Loss:   309.3679 Validation Accuracy: 0.800781\n","Epoch  6, Batch 228 -Loss:   345.4027 Validation Accuracy: 0.800781\n","Epoch  6, Batch 229 -Loss:   375.4805 Validation Accuracy: 0.800781\n","Epoch  6, Batch 230 -Loss:   295.8336 Validation Accuracy: 0.808594\n","Epoch  6, Batch 231 -Loss:   466.2423 Validation Accuracy: 0.800781\n","Epoch  6, Batch 232 -Loss:   346.2516 Validation Accuracy: 0.796875\n","Epoch  6, Batch 233 -Loss:   258.8010 Validation Accuracy: 0.796875\n","Epoch  6, Batch 234 -Loss:   229.4409 Validation Accuracy: 0.792969\n","Epoch  6, Batch 235 -Loss:   277.3413 Validation Accuracy: 0.796875\n","Epoch  6, Batch 236 -Loss:   296.7452 Validation Accuracy: 0.800781\n","Epoch  6, Batch 237 -Loss:   260.0535 Validation Accuracy: 0.804688\n","Epoch  6, Batch 238 -Loss:   314.5939 Validation Accuracy: 0.804688\n","Epoch  6, Batch 239 -Loss:   337.5211 Validation Accuracy: 0.796875\n","Epoch  6, Batch 240 -Loss:   429.9301 Validation Accuracy: 0.796875\n","Epoch  6, Batch 241 -Loss:   356.8596 Validation Accuracy: 0.800781\n","Epoch  6, Batch 242 -Loss:   330.3254 Validation Accuracy: 0.800781\n","Epoch  6, Batch 243 -Loss:   263.5351 Validation Accuracy: 0.796875\n","Epoch  6, Batch 244 -Loss:   377.6722 Validation Accuracy: 0.792969\n","Epoch  6, Batch 245 -Loss:   277.1606 Validation Accuracy: 0.792969\n","Epoch  6, Batch 246 -Loss:   346.0343 Validation Accuracy: 0.792969\n","Epoch  6, Batch 247 -Loss:   353.4404 Validation Accuracy: 0.800781\n","Epoch  6, Batch 248 -Loss:   336.3623 Validation Accuracy: 0.796875\n","Epoch  6, Batch 249 -Loss:   451.6304 Validation Accuracy: 0.796875\n","Epoch  6, Batch 250 -Loss:   396.2516 Validation Accuracy: 0.796875\n","Epoch  6, Batch 251 -Loss:   154.2208 Validation Accuracy: 0.800781\n","Epoch  6, Batch 252 -Loss:   268.9745 Validation Accuracy: 0.800781\n","Epoch  6, Batch 253 -Loss:   329.8084 Validation Accuracy: 0.800781\n","Epoch  6, Batch 254 -Loss:   469.2130 Validation Accuracy: 0.800781\n","Epoch  6, Batch 255 -Loss:   218.2025 Validation Accuracy: 0.796875\n","Epoch  6, Batch 256 -Loss:   242.7816 Validation Accuracy: 0.800781\n","Epoch  6, Batch 257 -Loss:   184.6378 Validation Accuracy: 0.800781\n","Epoch  6, Batch 258 -Loss:   453.2361 Validation Accuracy: 0.800781\n","Epoch  6, Batch 259 -Loss:   223.9380 Validation Accuracy: 0.800781\n","Epoch  6, Batch 260 -Loss:   469.5127 Validation Accuracy: 0.796875\n","Epoch  6, Batch 261 -Loss:   322.9517 Validation Accuracy: 0.792969\n","Epoch  6, Batch 262 -Loss:   346.9980 Validation Accuracy: 0.796875\n","Epoch  6, Batch 263 -Loss:   318.1128 Validation Accuracy: 0.804688\n","Epoch  6, Batch 264 -Loss:   173.7808 Validation Accuracy: 0.792969\n","Epoch  6, Batch 265 -Loss:   339.3357 Validation Accuracy: 0.796875\n","Epoch  6, Batch 266 -Loss:   439.8586 Validation Accuracy: 0.796875\n","Epoch  6, Batch 267 -Loss:   516.3642 Validation Accuracy: 0.796875\n","Epoch  6, Batch 268 -Loss:   480.0422 Validation Accuracy: 0.796875\n","Epoch  6, Batch 269 -Loss:   263.1281 Validation Accuracy: 0.792969\n","Epoch  6, Batch 270 -Loss:   189.8232 Validation Accuracy: 0.792969\n","Epoch  6, Batch 271 -Loss:   280.5808 Validation Accuracy: 0.792969\n","Epoch  6, Batch 272 -Loss:   210.2408 Validation Accuracy: 0.796875\n","Epoch  6, Batch 273 -Loss:   509.0305 Validation Accuracy: 0.789062\n","Epoch  6, Batch 274 -Loss:   268.5913 Validation Accuracy: 0.796875\n","Epoch  6, Batch 275 -Loss:   181.1467 Validation Accuracy: 0.792969\n","Epoch  6, Batch 276 -Loss:   411.5859 Validation Accuracy: 0.792969\n","Epoch  6, Batch 277 -Loss:   456.8836 Validation Accuracy: 0.792969\n","Epoch  6, Batch 278 -Loss:   424.4147 Validation Accuracy: 0.796875\n","Epoch  6, Batch 279 -Loss:   228.3270 Validation Accuracy: 0.800781\n","Epoch  6, Batch 280 -Loss:   315.2603 Validation Accuracy: 0.796875\n","Epoch  6, Batch 281 -Loss:   375.4933 Validation Accuracy: 0.796875\n","Epoch  6, Batch 282 -Loss:   267.4252 Validation Accuracy: 0.800781\n","Epoch  6, Batch 283 -Loss:   403.3016 Validation Accuracy: 0.796875\n","Epoch  6, Batch 284 -Loss:   277.7887 Validation Accuracy: 0.796875\n","Epoch  6, Batch 285 -Loss:   316.8544 Validation Accuracy: 0.792969\n","Epoch  6, Batch 286 -Loss:   205.2879 Validation Accuracy: 0.800781\n","Epoch  6, Batch 287 -Loss:   422.1213 Validation Accuracy: 0.796875\n","Epoch  6, Batch 288 -Loss:   444.6047 Validation Accuracy: 0.792969\n","Epoch  6, Batch 289 -Loss:   323.6137 Validation Accuracy: 0.789062\n","Epoch  6, Batch 290 -Loss:   470.3274 Validation Accuracy: 0.792969\n","Epoch  6, Batch 291 -Loss:   315.8196 Validation Accuracy: 0.792969\n","Epoch  6, Batch 292 -Loss:   352.8552 Validation Accuracy: 0.789062\n","Epoch  6, Batch 293 -Loss:   304.0082 Validation Accuracy: 0.789062\n","Epoch  6, Batch 294 -Loss:   230.1256 Validation Accuracy: 0.789062\n","Epoch  6, Batch 295 -Loss:   212.2321 Validation Accuracy: 0.796875\n","Epoch  6, Batch 296 -Loss:   361.0964 Validation Accuracy: 0.796875\n","Epoch  6, Batch 297 -Loss:   463.1121 Validation Accuracy: 0.796875\n","Epoch  6, Batch 298 -Loss:   242.3244 Validation Accuracy: 0.800781\n","Epoch  6, Batch 299 -Loss:   269.4229 Validation Accuracy: 0.800781\n","Epoch  6, Batch 300 -Loss:   301.1720 Validation Accuracy: 0.800781\n","Epoch  6, Batch 301 -Loss:   232.5817 Validation Accuracy: 0.800781\n","Epoch  6, Batch 302 -Loss:   222.3977 Validation Accuracy: 0.800781\n","Epoch  6, Batch 303 -Loss:   266.1724 Validation Accuracy: 0.800781\n","Epoch  6, Batch 304 -Loss:   328.7685 Validation Accuracy: 0.800781\n","Epoch  6, Batch 305 -Loss:   368.4199 Validation Accuracy: 0.796875\n","Epoch  6, Batch 306 -Loss:   365.8624 Validation Accuracy: 0.800781\n","Epoch  6, Batch 307 -Loss:   416.9860 Validation Accuracy: 0.789062\n","Epoch  6, Batch 308 -Loss:   233.6373 Validation Accuracy: 0.789062\n","Epoch  6, Batch 309 -Loss:   252.1178 Validation Accuracy: 0.792969\n","Epoch  6, Batch 310 -Loss:   353.8438 Validation Accuracy: 0.789062\n","Epoch  6, Batch 311 -Loss:   406.5571 Validation Accuracy: 0.792969\n","Epoch  6, Batch 312 -Loss:   352.1295 Validation Accuracy: 0.789062\n","Epoch  6, Batch 313 -Loss:   324.0333 Validation Accuracy: 0.800781\n","Epoch  6, Batch 314 -Loss:   262.6219 Validation Accuracy: 0.804688\n","Epoch  6, Batch 315 -Loss:   358.8690 Validation Accuracy: 0.804688\n","Epoch  6, Batch 316 -Loss:   301.0670 Validation Accuracy: 0.796875\n","Epoch  6, Batch 317 -Loss:   350.5020 Validation Accuracy: 0.800781\n","Epoch  6, Batch 318 -Loss:   390.3268 Validation Accuracy: 0.804688\n","Epoch  6, Batch 319 -Loss:   403.6373 Validation Accuracy: 0.792969\n","Epoch  6, Batch 320 -Loss:   366.1049 Validation Accuracy: 0.789062\n","Epoch  6, Batch 321 -Loss:   361.2489 Validation Accuracy: 0.789062\n","Epoch  6, Batch 322 -Loss:   392.3841 Validation Accuracy: 0.792969\n","Epoch  6, Batch 323 -Loss:   227.0865 Validation Accuracy: 0.792969\n","Epoch  6, Batch 324 -Loss:   227.6212 Validation Accuracy: 0.785156\n","Epoch  6, Batch 325 -Loss:   211.3231 Validation Accuracy: 0.777344\n","Epoch  6, Batch 326 -Loss:   473.7744 Validation Accuracy: 0.781250\n","Epoch  6, Batch 327 -Loss:   630.7284 Validation Accuracy: 0.789062\n","Epoch  6, Batch 328 -Loss:   235.5326 Validation Accuracy: 0.789062\n","Epoch  6, Batch 329 -Loss:   467.7867 Validation Accuracy: 0.789062\n","Epoch  6, Batch 330 -Loss:   339.4126 Validation Accuracy: 0.789062\n","Epoch  6, Batch 331 -Loss:   283.3187 Validation Accuracy: 0.789062\n","Epoch  6, Batch 332 -Loss:   477.7944 Validation Accuracy: 0.796875\n","Epoch  6, Batch 333 -Loss:   272.0037 Validation Accuracy: 0.796875\n","Epoch  6, Batch 334 -Loss:   348.0755 Validation Accuracy: 0.796875\n","Epoch  6, Batch 335 -Loss:   351.9936 Validation Accuracy: 0.785156\n","Epoch  6, Batch 336 -Loss:   427.6566 Validation Accuracy: 0.789062\n","Epoch  6, Batch 337 -Loss:   418.5463 Validation Accuracy: 0.792969\n","Epoch  6, Batch 338 -Loss:   323.6258 Validation Accuracy: 0.789062\n","Epoch  6, Batch 339 -Loss:   388.6839 Validation Accuracy: 0.796875\n","Epoch  6, Batch 340 -Loss:   375.1656 Validation Accuracy: 0.792969\n","Epoch  6, Batch 341 -Loss:   452.5837 Validation Accuracy: 0.796875\n","Epoch  6, Batch 342 -Loss:   372.6426 Validation Accuracy: 0.792969\n","Epoch  6, Batch 343 -Loss:   335.7674 Validation Accuracy: 0.792969\n","Epoch  6, Batch 344 -Loss:   365.0417 Validation Accuracy: 0.792969\n","Epoch  6, Batch 345 -Loss:   471.8878 Validation Accuracy: 0.792969\n","Epoch  6, Batch 346 -Loss:   226.0902 Validation Accuracy: 0.792969\n","Epoch  6, Batch 347 -Loss:   376.3272 Validation Accuracy: 0.792969\n","Epoch  6, Batch 348 -Loss:   270.6661 Validation Accuracy: 0.792969\n","Epoch  6, Batch 349 -Loss:   340.2218 Validation Accuracy: 0.792969\n","Epoch  6, Batch 350 -Loss:   208.8667 Validation Accuracy: 0.792969\n","Epoch  6, Batch 351 -Loss:   398.2133 Validation Accuracy: 0.796875\n","Epoch  6, Batch 352 -Loss:   303.5096 Validation Accuracy: 0.796875\n","Epoch  6, Batch 353 -Loss:   279.4030 Validation Accuracy: 0.796875\n","Epoch  6, Batch 354 -Loss:   449.6315 Validation Accuracy: 0.800781\n","Epoch  6, Batch 355 -Loss:   474.0475 Validation Accuracy: 0.792969\n","Epoch  6, Batch 356 -Loss:   309.1949 Validation Accuracy: 0.792969\n","Epoch  6, Batch 357 -Loss:   369.2334 Validation Accuracy: 0.796875\n","Epoch  6, Batch 358 -Loss:   244.7267 Validation Accuracy: 0.796875\n","Epoch  6, Batch 359 -Loss:   201.0180 Validation Accuracy: 0.792969\n","Epoch  6, Batch 360 -Loss:   202.8559 Validation Accuracy: 0.792969\n","Epoch  6, Batch 361 -Loss:   358.8108 Validation Accuracy: 0.789062\n","Epoch  6, Batch 362 -Loss:   386.6036 Validation Accuracy: 0.789062\n","Epoch  6, Batch 363 -Loss:   331.3007 Validation Accuracy: 0.792969\n","Epoch  6, Batch 364 -Loss:   228.4820 Validation Accuracy: 0.785156\n","Epoch  6, Batch 365 -Loss:   570.1241 Validation Accuracy: 0.789062\n","Epoch  6, Batch 366 -Loss:   237.4688 Validation Accuracy: 0.789062\n","Epoch  6, Batch 367 -Loss:   350.7442 Validation Accuracy: 0.789062\n","Epoch  6, Batch 368 -Loss:   409.3196 Validation Accuracy: 0.796875\n","Epoch  6, Batch 369 -Loss:   332.7032 Validation Accuracy: 0.796875\n","Epoch  6, Batch 370 -Loss:   270.7365 Validation Accuracy: 0.800781\n","Epoch  6, Batch 371 -Loss:   309.5493 Validation Accuracy: 0.804688\n","Epoch  6, Batch 372 -Loss:   396.0805 Validation Accuracy: 0.800781\n","Epoch  6, Batch 373 -Loss:   422.3745 Validation Accuracy: 0.796875\n","Epoch  6, Batch 374 -Loss:   255.8671 Validation Accuracy: 0.800781\n","Epoch  6, Batch 375 -Loss:   320.1698 Validation Accuracy: 0.796875\n","Epoch  6, Batch 376 -Loss:   357.2549 Validation Accuracy: 0.804688\n","Epoch  6, Batch 377 -Loss:   281.0219 Validation Accuracy: 0.804688\n","Epoch  6, Batch 378 -Loss:   385.4236 Validation Accuracy: 0.792969\n","Epoch  6, Batch 379 -Loss:   187.7798 Validation Accuracy: 0.789062\n","Epoch  6, Batch 380 -Loss:   255.5663 Validation Accuracy: 0.792969\n","Epoch  6, Batch 381 -Loss:   332.0597 Validation Accuracy: 0.792969\n","Epoch  6, Batch 382 -Loss:   435.9713 Validation Accuracy: 0.804688\n","Epoch  6, Batch 383 -Loss:   359.5941 Validation Accuracy: 0.800781\n","Epoch  6, Batch 384 -Loss:   385.4668 Validation Accuracy: 0.804688\n","Epoch  6, Batch 385 -Loss:   342.6932 Validation Accuracy: 0.808594\n","Epoch  6, Batch 386 -Loss:   416.4589 Validation Accuracy: 0.808594\n","Epoch  6, Batch 387 -Loss:   516.2200 Validation Accuracy: 0.808594\n","Epoch  6, Batch 388 -Loss:   113.3281 Validation Accuracy: 0.808594\n","Epoch  6, Batch 389 -Loss:   326.0959 Validation Accuracy: 0.808594\n","Epoch  6, Batch 390 -Loss:   393.3008 Validation Accuracy: 0.808594\n","Epoch  6, Batch 391 -Loss:   224.7156 Validation Accuracy: 0.808594\n","Epoch  6, Batch 392 -Loss:   381.4417 Validation Accuracy: 0.808594\n","Epoch  6, Batch 393 -Loss:   329.3244 Validation Accuracy: 0.796875\n","Epoch  6, Batch 394 -Loss:   294.9421 Validation Accuracy: 0.800781\n","Epoch  6, Batch 395 -Loss:   288.6104 Validation Accuracy: 0.804688\n","Epoch  6, Batch 396 -Loss:   280.6223 Validation Accuracy: 0.804688\n","Epoch  6, Batch 397 -Loss:   216.4699 Validation Accuracy: 0.804688\n","Epoch  6, Batch 398 -Loss:   298.9827 Validation Accuracy: 0.804688\n","Epoch  6, Batch 399 -Loss:   321.5933 Validation Accuracy: 0.808594\n","Epoch  6, Batch 400 -Loss:   335.7369 Validation Accuracy: 0.804688\n","Epoch  6, Batch 401 -Loss:   277.2081 Validation Accuracy: 0.804688\n","Epoch  6, Batch 402 -Loss:   284.5659 Validation Accuracy: 0.804688\n","Epoch  6, Batch 403 -Loss:   494.4734 Validation Accuracy: 0.804688\n","Epoch  6, Batch 404 -Loss:   295.9794 Validation Accuracy: 0.804688\n","Epoch  6, Batch 405 -Loss:   295.1849 Validation Accuracy: 0.804688\n","Epoch  6, Batch 406 -Loss:   221.6330 Validation Accuracy: 0.804688\n","Epoch  6, Batch 407 -Loss:   287.2127 Validation Accuracy: 0.800781\n","Epoch  6, Batch 408 -Loss:   335.7313 Validation Accuracy: 0.796875\n","Epoch  6, Batch 409 -Loss:   502.2511 Validation Accuracy: 0.804688\n","Epoch  6, Batch 410 -Loss:   415.4114 Validation Accuracy: 0.804688\n","Epoch  6, Batch 411 -Loss:   373.3457 Validation Accuracy: 0.804688\n","Epoch  6, Batch 412 -Loss:   337.3706 Validation Accuracy: 0.796875\n","Epoch  6, Batch 413 -Loss:   206.5243 Validation Accuracy: 0.808594\n","Epoch  6, Batch 414 -Loss:   292.4931 Validation Accuracy: 0.804688\n","Epoch  6, Batch 415 -Loss:   528.4764 Validation Accuracy: 0.804688\n","Epoch  6, Batch 416 -Loss:   461.0176 Validation Accuracy: 0.808594\n","Epoch  6, Batch 417 -Loss:   300.9435 Validation Accuracy: 0.804688\n","Epoch  6, Batch 418 -Loss:   252.8263 Validation Accuracy: 0.808594\n","Epoch  6, Batch 419 -Loss:   241.3188 Validation Accuracy: 0.804688\n","Epoch  6, Batch 420 -Loss:   339.8574 Validation Accuracy: 0.808594\n","Epoch  6, Batch 421 -Loss:   388.9236 Validation Accuracy: 0.808594\n","Epoch  6, Batch 422 -Loss:   357.3935 Validation Accuracy: 0.808594\n","Epoch  6, Batch 423 -Loss:   272.0424 Validation Accuracy: 0.808594\n","Epoch  6, Batch 424 -Loss:   328.8780 Validation Accuracy: 0.808594\n","Epoch  6, Batch 425 -Loss:   270.8276 Validation Accuracy: 0.816406\n","Epoch  6, Batch 426 -Loss:   470.9362 Validation Accuracy: 0.812500\n","Epoch  6, Batch 427 -Loss:   402.3095 Validation Accuracy: 0.816406\n","Epoch  6, Batch 428 -Loss:   258.5797 Validation Accuracy: 0.812500\n","Epoch  6, Batch 429 -Loss:   304.1407 Validation Accuracy: 0.808594\n","Epoch  7, Batch   1 -Loss:   415.0609 Validation Accuracy: 0.808594\n","Epoch  7, Batch   2 -Loss:   434.5222 Validation Accuracy: 0.812500\n","Epoch  7, Batch   3 -Loss:   275.5274 Validation Accuracy: 0.808594\n","Epoch  7, Batch   4 -Loss:   202.4089 Validation Accuracy: 0.808594\n","Epoch  7, Batch   5 -Loss:   364.7520 Validation Accuracy: 0.808594\n","Epoch  7, Batch   6 -Loss:   433.5846 Validation Accuracy: 0.812500\n","Epoch  7, Batch   7 -Loss:   433.9080 Validation Accuracy: 0.804688\n","Epoch  7, Batch   8 -Loss:   245.9447 Validation Accuracy: 0.800781\n","Epoch  7, Batch   9 -Loss:   331.9043 Validation Accuracy: 0.800781\n","Epoch  7, Batch  10 -Loss:   291.5721 Validation Accuracy: 0.804688\n","Epoch  7, Batch  11 -Loss:   357.5242 Validation Accuracy: 0.804688\n","Epoch  7, Batch  12 -Loss:   213.9191 Validation Accuracy: 0.796875\n","Epoch  7, Batch  13 -Loss:   407.0026 Validation Accuracy: 0.800781\n","Epoch  7, Batch  14 -Loss:   379.0821 Validation Accuracy: 0.792969\n","Epoch  7, Batch  15 -Loss:   378.3607 Validation Accuracy: 0.800781\n","Epoch  7, Batch  16 -Loss:   309.3149 Validation Accuracy: 0.796875\n","Epoch  7, Batch  17 -Loss:   443.6824 Validation Accuracy: 0.796875\n","Epoch  7, Batch  18 -Loss:   471.6358 Validation Accuracy: 0.792969\n","Epoch  7, Batch  19 -Loss:   373.9444 Validation Accuracy: 0.800781\n","Epoch  7, Batch  20 -Loss:   297.4251 Validation Accuracy: 0.800781\n","Epoch  7, Batch  21 -Loss:   492.0823 Validation Accuracy: 0.796875\n","Epoch  7, Batch  22 -Loss:   259.1422 Validation Accuracy: 0.789062\n","Epoch  7, Batch  23 -Loss:   291.4809 Validation Accuracy: 0.789062\n","Epoch  7, Batch  24 -Loss:   168.5152 Validation Accuracy: 0.789062\n","Epoch  7, Batch  25 -Loss:   214.5160 Validation Accuracy: 0.789062\n","Epoch  7, Batch  26 -Loss:   402.1870 Validation Accuracy: 0.789062\n","Epoch  7, Batch  27 -Loss:   480.7615 Validation Accuracy: 0.792969\n","Epoch  7, Batch  28 -Loss:   174.1256 Validation Accuracy: 0.789062\n","Epoch  7, Batch  29 -Loss:   517.7916 Validation Accuracy: 0.796875\n","Epoch  7, Batch  30 -Loss:   397.4167 Validation Accuracy: 0.796875\n","Epoch  7, Batch  31 -Loss:   286.6840 Validation Accuracy: 0.796875\n","Epoch  7, Batch  32 -Loss:   229.4867 Validation Accuracy: 0.800781\n","Epoch  7, Batch  33 -Loss:   279.5309 Validation Accuracy: 0.804688\n","Epoch  7, Batch  34 -Loss:   272.3883 Validation Accuracy: 0.804688\n","Epoch  7, Batch  35 -Loss:   358.8402 Validation Accuracy: 0.812500\n","Epoch  7, Batch  36 -Loss:   424.1678 Validation Accuracy: 0.800781\n","Epoch  7, Batch  37 -Loss:   326.4199 Validation Accuracy: 0.800781\n","Epoch  7, Batch  38 -Loss:   163.0537 Validation Accuracy: 0.804688\n","Epoch  7, Batch  39 -Loss:   276.9388 Validation Accuracy: 0.796875\n","Epoch  7, Batch  40 -Loss:   389.3056 Validation Accuracy: 0.800781\n","Epoch  7, Batch  41 -Loss:   316.8582 Validation Accuracy: 0.792969\n","Epoch  7, Batch  42 -Loss:   221.2080 Validation Accuracy: 0.785156\n","Epoch  7, Batch  43 -Loss:   262.4147 Validation Accuracy: 0.789062\n","Epoch  7, Batch  44 -Loss:   304.0627 Validation Accuracy: 0.789062\n","Epoch  7, Batch  45 -Loss:   382.9155 Validation Accuracy: 0.789062\n","Epoch  7, Batch  46 -Loss:   439.8983 Validation Accuracy: 0.789062\n","Epoch  7, Batch  47 -Loss:   160.8782 Validation Accuracy: 0.789062\n","Epoch  7, Batch  48 -Loss:   223.5092 Validation Accuracy: 0.796875\n","Epoch  7, Batch  49 -Loss:   300.0831 Validation Accuracy: 0.796875\n","Epoch  7, Batch  50 -Loss:   316.0337 Validation Accuracy: 0.792969\n","Epoch  7, Batch  51 -Loss:   295.3415 Validation Accuracy: 0.792969\n","Epoch  7, Batch  52 -Loss:   484.1751 Validation Accuracy: 0.792969\n","Epoch  7, Batch  53 -Loss:   311.6379 Validation Accuracy: 0.792969\n","Epoch  7, Batch  54 -Loss:   236.3679 Validation Accuracy: 0.796875\n","Epoch  7, Batch  55 -Loss:   296.4426 Validation Accuracy: 0.796875\n","Epoch  7, Batch  56 -Loss:   561.4513 Validation Accuracy: 0.796875\n","Epoch  7, Batch  57 -Loss:   277.2062 Validation Accuracy: 0.792969\n","Epoch  7, Batch  58 -Loss:   358.8022 Validation Accuracy: 0.800781\n","Epoch  7, Batch  59 -Loss:   358.9620 Validation Accuracy: 0.800781\n","Epoch  7, Batch  60 -Loss:   253.6570 Validation Accuracy: 0.792969\n","Epoch  7, Batch  61 -Loss:   435.6331 Validation Accuracy: 0.796875\n","Epoch  7, Batch  62 -Loss:   349.0979 Validation Accuracy: 0.789062\n","Epoch  7, Batch  63 -Loss:   160.4676 Validation Accuracy: 0.789062\n","Epoch  7, Batch  64 -Loss:   246.6886 Validation Accuracy: 0.792969\n","Epoch  7, Batch  65 -Loss:   320.8359 Validation Accuracy: 0.789062\n","Epoch  7, Batch  66 -Loss:   238.7449 Validation Accuracy: 0.792969\n","Epoch  7, Batch  67 -Loss:   308.3519 Validation Accuracy: 0.785156\n","Epoch  7, Batch  68 -Loss:   259.7551 Validation Accuracy: 0.789062\n","Epoch  7, Batch  69 -Loss:   304.1863 Validation Accuracy: 0.785156\n","Epoch  7, Batch  70 -Loss:   275.0055 Validation Accuracy: 0.792969\n","Epoch  7, Batch  71 -Loss:   321.3889 Validation Accuracy: 0.785156\n","Epoch  7, Batch  72 -Loss:   345.1434 Validation Accuracy: 0.789062\n","Epoch  7, Batch  73 -Loss:   439.7612 Validation Accuracy: 0.792969\n","Epoch  7, Batch  74 -Loss:   406.0541 Validation Accuracy: 0.792969\n","Epoch  7, Batch  75 -Loss:   303.8096 Validation Accuracy: 0.792969\n","Epoch  7, Batch  76 -Loss:   289.3469 Validation Accuracy: 0.796875\n","Epoch  7, Batch  77 -Loss:   400.9351 Validation Accuracy: 0.792969\n","Epoch  7, Batch  78 -Loss:   249.1536 Validation Accuracy: 0.792969\n","Epoch  7, Batch  79 -Loss:   432.9675 Validation Accuracy: 0.792969\n","Epoch  7, Batch  80 -Loss:   548.2491 Validation Accuracy: 0.789062\n","Epoch  7, Batch  81 -Loss:   307.6726 Validation Accuracy: 0.781250\n","Epoch  7, Batch  82 -Loss:   216.2788 Validation Accuracy: 0.789062\n","Epoch  7, Batch  83 -Loss:   244.6407 Validation Accuracy: 0.792969\n","Epoch  7, Batch  84 -Loss:   264.5704 Validation Accuracy: 0.789062\n","Epoch  7, Batch  85 -Loss:   225.5718 Validation Accuracy: 0.792969\n","Epoch  7, Batch  86 -Loss:   132.5613 Validation Accuracy: 0.785156\n","Epoch  7, Batch  87 -Loss:   381.3489 Validation Accuracy: 0.781250\n","Epoch  7, Batch  88 -Loss:   341.7411 Validation Accuracy: 0.773438\n","Epoch  7, Batch  89 -Loss:   302.3484 Validation Accuracy: 0.777344\n","Epoch  7, Batch  90 -Loss:   313.5282 Validation Accuracy: 0.781250\n","Epoch  7, Batch  91 -Loss:   225.1612 Validation Accuracy: 0.785156\n","Epoch  7, Batch  92 -Loss:   364.5949 Validation Accuracy: 0.781250\n","Epoch  7, Batch  93 -Loss:   372.5706 Validation Accuracy: 0.785156\n","Epoch  7, Batch  94 -Loss:   355.3853 Validation Accuracy: 0.781250\n","Epoch  7, Batch  95 -Loss:   334.2747 Validation Accuracy: 0.785156\n","Epoch  7, Batch  96 -Loss:   380.2079 Validation Accuracy: 0.781250\n","Epoch  7, Batch  97 -Loss:   267.7765 Validation Accuracy: 0.781250\n","Epoch  7, Batch  98 -Loss:   250.2598 Validation Accuracy: 0.785156\n","Epoch  7, Batch  99 -Loss:   159.9256 Validation Accuracy: 0.781250\n","Epoch  7, Batch 100 -Loss:   312.0079 Validation Accuracy: 0.777344\n","Epoch  7, Batch 101 -Loss:   298.0641 Validation Accuracy: 0.777344\n","Epoch  7, Batch 102 -Loss:   259.3611 Validation Accuracy: 0.773438\n","Epoch  7, Batch 103 -Loss:   365.3273 Validation Accuracy: 0.777344\n","Epoch  7, Batch 104 -Loss:   371.5308 Validation Accuracy: 0.781250\n","Epoch  7, Batch 105 -Loss:   344.5713 Validation Accuracy: 0.785156\n","Epoch  7, Batch 106 -Loss:   449.6740 Validation Accuracy: 0.781250\n","Epoch  7, Batch 107 -Loss:   345.8628 Validation Accuracy: 0.785156\n","Epoch  7, Batch 108 -Loss:   488.6755 Validation Accuracy: 0.777344\n","Epoch  7, Batch 109 -Loss:   193.4267 Validation Accuracy: 0.773438\n","Epoch  7, Batch 110 -Loss:   219.9545 Validation Accuracy: 0.773438\n","Epoch  7, Batch 111 -Loss:   365.2478 Validation Accuracy: 0.777344\n","Epoch  7, Batch 112 -Loss:   275.2562 Validation Accuracy: 0.785156\n","Epoch  7, Batch 113 -Loss:   305.8585 Validation Accuracy: 0.781250\n","Epoch  7, Batch 114 -Loss:   372.3125 Validation Accuracy: 0.777344\n","Epoch  7, Batch 115 -Loss:   405.0446 Validation Accuracy: 0.785156\n","Epoch  7, Batch 116 -Loss:   274.6529 Validation Accuracy: 0.785156\n","Epoch  7, Batch 117 -Loss:   254.3796 Validation Accuracy: 0.789062\n","Epoch  7, Batch 118 -Loss:   252.2740 Validation Accuracy: 0.789062\n","Epoch  7, Batch 119 -Loss:   414.9612 Validation Accuracy: 0.785156\n","Epoch  7, Batch 120 -Loss:   179.9214 Validation Accuracy: 0.789062\n","Epoch  7, Batch 121 -Loss:   363.4707 Validation Accuracy: 0.789062\n","Epoch  7, Batch 122 -Loss:   349.7863 Validation Accuracy: 0.792969\n","Epoch  7, Batch 123 -Loss:   229.4316 Validation Accuracy: 0.789062\n","Epoch  7, Batch 124 -Loss:   289.7786 Validation Accuracy: 0.792969\n","Epoch  7, Batch 125 -Loss:   488.8005 Validation Accuracy: 0.785156\n","Epoch  7, Batch 126 -Loss:   288.0191 Validation Accuracy: 0.789062\n","Epoch  7, Batch 127 -Loss:   329.0266 Validation Accuracy: 0.792969\n","Epoch  7, Batch 128 -Loss:   399.4775 Validation Accuracy: 0.792969\n","Epoch  7, Batch 129 -Loss:   273.3924 Validation Accuracy: 0.785156\n","Epoch  7, Batch 130 -Loss:   184.6084 Validation Accuracy: 0.792969\n","Epoch  7, Batch 131 -Loss:   364.4127 Validation Accuracy: 0.792969\n","Epoch  7, Batch 132 -Loss:   189.6688 Validation Accuracy: 0.796875\n","Epoch  7, Batch 133 -Loss:   452.2613 Validation Accuracy: 0.796875\n","Epoch  7, Batch 134 -Loss:   280.8679 Validation Accuracy: 0.800781\n","Epoch  7, Batch 135 -Loss:   185.8467 Validation Accuracy: 0.800781\n","Epoch  7, Batch 136 -Loss:   283.3879 Validation Accuracy: 0.800781\n","Epoch  7, Batch 137 -Loss:   341.5670 Validation Accuracy: 0.796875\n","Epoch  7, Batch 138 -Loss:   305.5630 Validation Accuracy: 0.792969\n","Epoch  7, Batch 139 -Loss:   429.5909 Validation Accuracy: 0.792969\n","Epoch  7, Batch 140 -Loss:   257.4693 Validation Accuracy: 0.792969\n","Epoch  7, Batch 141 -Loss:   296.2575 Validation Accuracy: 0.796875\n","Epoch  7, Batch 142 -Loss:   288.0320 Validation Accuracy: 0.796875\n","Epoch  7, Batch 143 -Loss:   333.4336 Validation Accuracy: 0.796875\n","Epoch  7, Batch 144 -Loss:   421.1288 Validation Accuracy: 0.796875\n","Epoch  7, Batch 145 -Loss:   381.8195 Validation Accuracy: 0.796875\n","Epoch  7, Batch 146 -Loss:   274.4516 Validation Accuracy: 0.796875\n","Epoch  7, Batch 147 -Loss:   449.7820 Validation Accuracy: 0.792969\n","Epoch  7, Batch 148 -Loss:   374.6869 Validation Accuracy: 0.792969\n","Epoch  7, Batch 149 -Loss:   446.5756 Validation Accuracy: 0.789062\n","Epoch  7, Batch 150 -Loss:   197.9044 Validation Accuracy: 0.792969\n","Epoch  7, Batch 151 -Loss:   334.2773 Validation Accuracy: 0.796875\n","Epoch  7, Batch 152 -Loss:   442.4100 Validation Accuracy: 0.792969\n","Epoch  7, Batch 153 -Loss:   325.7379 Validation Accuracy: 0.792969\n","Epoch  7, Batch 154 -Loss:   397.8832 Validation Accuracy: 0.789062\n","Epoch  7, Batch 155 -Loss:   266.3600 Validation Accuracy: 0.789062\n","Epoch  7, Batch 156 -Loss:   314.9583 Validation Accuracy: 0.789062\n","Epoch  7, Batch 157 -Loss:   229.0739 Validation Accuracy: 0.789062\n","Epoch  7, Batch 158 -Loss:   204.0245 Validation Accuracy: 0.792969\n","Epoch  7, Batch 159 -Loss:   315.4750 Validation Accuracy: 0.792969\n","Epoch  7, Batch 160 -Loss:   347.8052 Validation Accuracy: 0.796875\n","Epoch  7, Batch 161 -Loss:   363.8378 Validation Accuracy: 0.800781\n","Epoch  7, Batch 162 -Loss:   306.3800 Validation Accuracy: 0.800781\n","Epoch  7, Batch 163 -Loss:   264.1443 Validation Accuracy: 0.800781\n","Epoch  7, Batch 164 -Loss:   288.0034 Validation Accuracy: 0.800781\n","Epoch  7, Batch 165 -Loss:   420.7790 Validation Accuracy: 0.800781\n","Epoch  7, Batch 166 -Loss:   392.6833 Validation Accuracy: 0.796875\n","Epoch  7, Batch 167 -Loss:   319.3516 Validation Accuracy: 0.800781\n","Epoch  7, Batch 168 -Loss:   308.2245 Validation Accuracy: 0.800781\n","Epoch  7, Batch 169 -Loss:   391.3698 Validation Accuracy: 0.796875\n","Epoch  7, Batch 170 -Loss:   368.9267 Validation Accuracy: 0.800781\n","Epoch  7, Batch 171 -Loss:   506.0314 Validation Accuracy: 0.792969\n","Epoch  7, Batch 172 -Loss:   469.9526 Validation Accuracy: 0.792969\n","Epoch  7, Batch 173 -Loss:   311.8951 Validation Accuracy: 0.796875\n","Epoch  7, Batch 174 -Loss:   215.9541 Validation Accuracy: 0.792969\n","Epoch  7, Batch 175 -Loss:   226.4063 Validation Accuracy: 0.800781\n","Epoch  7, Batch 176 -Loss:   160.4352 Validation Accuracy: 0.804688\n","Epoch  7, Batch 177 -Loss:   412.0457 Validation Accuracy: 0.796875\n","Epoch  7, Batch 178 -Loss:   280.9868 Validation Accuracy: 0.796875\n","Epoch  7, Batch 179 -Loss:   266.0071 Validation Accuracy: 0.796875\n","Epoch  7, Batch 180 -Loss:   212.4832 Validation Accuracy: 0.796875\n","Epoch  7, Batch 181 -Loss:   381.9085 Validation Accuracy: 0.800781\n","Epoch  7, Batch 182 -Loss:   307.0838 Validation Accuracy: 0.800781\n","Epoch  7, Batch 183 -Loss:   301.9217 Validation Accuracy: 0.792969\n","Epoch  7, Batch 184 -Loss:   379.9154 Validation Accuracy: 0.792969\n","Epoch  7, Batch 185 -Loss:   343.7603 Validation Accuracy: 0.792969\n","Epoch  7, Batch 186 -Loss:   371.1383 Validation Accuracy: 0.792969\n","Epoch  7, Batch 187 -Loss:   337.1342 Validation Accuracy: 0.796875\n","Epoch  7, Batch 188 -Loss:   295.4891 Validation Accuracy: 0.792969\n","Epoch  7, Batch 189 -Loss:   456.2675 Validation Accuracy: 0.792969\n","Epoch  7, Batch 190 -Loss:   273.5217 Validation Accuracy: 0.792969\n","Epoch  7, Batch 191 -Loss:   358.3358 Validation Accuracy: 0.789062\n","Epoch  7, Batch 192 -Loss:   261.1652 Validation Accuracy: 0.792969\n","Epoch  7, Batch 193 -Loss:   368.3557 Validation Accuracy: 0.792969\n","Epoch  7, Batch 194 -Loss:   311.5992 Validation Accuracy: 0.792969\n","Epoch  7, Batch 195 -Loss:   222.7313 Validation Accuracy: 0.792969\n","Epoch  7, Batch 196 -Loss:   352.3366 Validation Accuracy: 0.792969\n","Epoch  7, Batch 197 -Loss:   316.4814 Validation Accuracy: 0.792969\n","Epoch  7, Batch 198 -Loss:   270.8501 Validation Accuracy: 0.792969\n","Epoch  7, Batch 199 -Loss:   167.5955 Validation Accuracy: 0.800781\n","Epoch  7, Batch 200 -Loss:   249.3117 Validation Accuracy: 0.800781\n","Epoch  7, Batch 201 -Loss:   268.7119 Validation Accuracy: 0.808594\n","Epoch  7, Batch 202 -Loss:   236.1994 Validation Accuracy: 0.812500\n","Epoch  7, Batch 203 -Loss:   224.6460 Validation Accuracy: 0.800781\n","Epoch  7, Batch 204 -Loss:   309.7794 Validation Accuracy: 0.792969\n","Epoch  7, Batch 205 -Loss:   206.6638 Validation Accuracy: 0.792969\n","Epoch  7, Batch 206 -Loss:   248.8526 Validation Accuracy: 0.792969\n","Epoch  7, Batch 207 -Loss:   299.8286 Validation Accuracy: 0.796875\n","Epoch  7, Batch 208 -Loss:   309.5040 Validation Accuracy: 0.792969\n","Epoch  7, Batch 209 -Loss:   432.9470 Validation Accuracy: 0.789062\n","Epoch  7, Batch 210 -Loss:   361.7109 Validation Accuracy: 0.789062\n","Epoch  7, Batch 211 -Loss:   447.0645 Validation Accuracy: 0.796875\n","Epoch  7, Batch 212 -Loss:   274.8782 Validation Accuracy: 0.792969\n","Epoch  7, Batch 213 -Loss:   438.6647 Validation Accuracy: 0.792969\n","Epoch  7, Batch 214 -Loss:   334.7597 Validation Accuracy: 0.796875\n","Epoch  7, Batch 215 -Loss:   257.6584 Validation Accuracy: 0.796875\n","Epoch  7, Batch 216 -Loss:   326.5129 Validation Accuracy: 0.789062\n","Epoch  7, Batch 217 -Loss:   269.2711 Validation Accuracy: 0.792969\n","Epoch  7, Batch 218 -Loss:   234.6614 Validation Accuracy: 0.796875\n","Epoch  7, Batch 219 -Loss:   265.8011 Validation Accuracy: 0.792969\n","Epoch  7, Batch 220 -Loss:   382.1169 Validation Accuracy: 0.789062\n","Epoch  7, Batch 221 -Loss:   220.2310 Validation Accuracy: 0.789062\n","Epoch  7, Batch 222 -Loss:   352.2931 Validation Accuracy: 0.792969\n","Epoch  7, Batch 223 -Loss:   263.7219 Validation Accuracy: 0.789062\n","Epoch  7, Batch 224 -Loss:   413.7991 Validation Accuracy: 0.789062\n","Epoch  7, Batch 225 -Loss:   323.0455 Validation Accuracy: 0.796875\n","Epoch  7, Batch 226 -Loss:   280.0247 Validation Accuracy: 0.796875\n","Epoch  7, Batch 227 -Loss:   250.3886 Validation Accuracy: 0.804688\n","Epoch  7, Batch 228 -Loss:   349.6311 Validation Accuracy: 0.804688\n","Epoch  7, Batch 229 -Loss:   299.2350 Validation Accuracy: 0.804688\n","Epoch  7, Batch 230 -Loss:   213.7563 Validation Accuracy: 0.804688\n","Epoch  7, Batch 231 -Loss:   287.0842 Validation Accuracy: 0.804688\n","Epoch  7, Batch 232 -Loss:   268.0710 Validation Accuracy: 0.800781\n","Epoch  7, Batch 233 -Loss:   306.5253 Validation Accuracy: 0.796875\n","Epoch  7, Batch 234 -Loss:   368.8914 Validation Accuracy: 0.796875\n","Epoch  7, Batch 235 -Loss:   292.2960 Validation Accuracy: 0.800781\n","Epoch  7, Batch 236 -Loss:   350.2281 Validation Accuracy: 0.800781\n","Epoch  7, Batch 237 -Loss:   317.5377 Validation Accuracy: 0.804688\n","Epoch  7, Batch 238 -Loss:   186.3508 Validation Accuracy: 0.808594\n","Epoch  7, Batch 239 -Loss:   444.3393 Validation Accuracy: 0.816406\n","Epoch  7, Batch 240 -Loss:   347.2581 Validation Accuracy: 0.808594\n","Epoch  7, Batch 241 -Loss:   329.8012 Validation Accuracy: 0.808594\n","Epoch  7, Batch 242 -Loss:   351.1378 Validation Accuracy: 0.812500\n","Epoch  7, Batch 243 -Loss:   425.4543 Validation Accuracy: 0.808594\n","Epoch  7, Batch 244 -Loss:   234.1283 Validation Accuracy: 0.804688\n","Epoch  7, Batch 245 -Loss:   242.9624 Validation Accuracy: 0.808594\n","Epoch  7, Batch 246 -Loss:   192.3438 Validation Accuracy: 0.808594\n","Epoch  7, Batch 247 -Loss:   290.6619 Validation Accuracy: 0.804688\n","Epoch  7, Batch 248 -Loss:   265.7133 Validation Accuracy: 0.804688\n","Epoch  7, Batch 249 -Loss:   207.6967 Validation Accuracy: 0.800781\n","Epoch  7, Batch 250 -Loss:   177.6203 Validation Accuracy: 0.800781\n","Epoch  7, Batch 251 -Loss:   422.7977 Validation Accuracy: 0.804688\n","Epoch  7, Batch 252 -Loss:   456.6588 Validation Accuracy: 0.804688\n","Epoch  7, Batch 253 -Loss:   203.7987 Validation Accuracy: 0.804688\n","Epoch  7, Batch 254 -Loss:   250.3583 Validation Accuracy: 0.800781\n","Epoch  7, Batch 255 -Loss:   363.2433 Validation Accuracy: 0.804688\n","Epoch  7, Batch 256 -Loss:   169.6551 Validation Accuracy: 0.808594\n","Epoch  7, Batch 257 -Loss:   262.7671 Validation Accuracy: 0.800781\n","Epoch  7, Batch 258 -Loss:   325.9035 Validation Accuracy: 0.800781\n","Epoch  7, Batch 259 -Loss:   143.4533 Validation Accuracy: 0.800781\n","Epoch  7, Batch 260 -Loss:   472.9863 Validation Accuracy: 0.804688\n","Epoch  7, Batch 261 -Loss:   391.9048 Validation Accuracy: 0.808594\n","Epoch  7, Batch 262 -Loss:   218.5374 Validation Accuracy: 0.808594\n","Epoch  7, Batch 263 -Loss:   409.9398 Validation Accuracy: 0.808594\n","Epoch  7, Batch 264 -Loss:   365.5855 Validation Accuracy: 0.808594\n","Epoch  7, Batch 265 -Loss:   360.8642 Validation Accuracy: 0.804688\n","Epoch  7, Batch 266 -Loss:   246.5758 Validation Accuracy: 0.808594\n","Epoch  7, Batch 267 -Loss:   433.4194 Validation Accuracy: 0.808594\n","Epoch  7, Batch 268 -Loss:   264.4559 Validation Accuracy: 0.808594\n","Epoch  7, Batch 269 -Loss:   213.0838 Validation Accuracy: 0.808594\n","Epoch  7, Batch 270 -Loss:   420.6063 Validation Accuracy: 0.808594\n","Epoch  7, Batch 271 -Loss:   168.8638 Validation Accuracy: 0.808594\n","Epoch  7, Batch 272 -Loss:   410.2312 Validation Accuracy: 0.808594\n","Epoch  7, Batch 273 -Loss:   266.7455 Validation Accuracy: 0.808594\n","Epoch  7, Batch 274 -Loss:   290.5428 Validation Accuracy: 0.808594\n","Epoch  7, Batch 275 -Loss:   285.5860 Validation Accuracy: 0.804688\n","Epoch  7, Batch 276 -Loss:   466.1599 Validation Accuracy: 0.808594\n","Epoch  7, Batch 277 -Loss:   302.6791 Validation Accuracy: 0.804688\n","Epoch  7, Batch 278 -Loss:   261.0771 Validation Accuracy: 0.804688\n","Epoch  7, Batch 279 -Loss:   317.6487 Validation Accuracy: 0.804688\n","Epoch  7, Batch 280 -Loss:   190.2733 Validation Accuracy: 0.800781\n","Epoch  7, Batch 281 -Loss:   370.9171 Validation Accuracy: 0.800781\n","Epoch  7, Batch 282 -Loss:   188.2267 Validation Accuracy: 0.796875\n","Epoch  7, Batch 283 -Loss:   195.1625 Validation Accuracy: 0.792969\n","Epoch  7, Batch 284 -Loss:   278.7920 Validation Accuracy: 0.796875\n","Epoch  7, Batch 285 -Loss:   282.2282 Validation Accuracy: 0.796875\n","Epoch  7, Batch 286 -Loss:   312.9548 Validation Accuracy: 0.792969\n","Epoch  7, Batch 287 -Loss:   340.1147 Validation Accuracy: 0.796875\n","Epoch  7, Batch 288 -Loss:   443.3146 Validation Accuracy: 0.796875\n","Epoch  7, Batch 289 -Loss:   365.5292 Validation Accuracy: 0.800781\n","Epoch  7, Batch 290 -Loss:   281.5945 Validation Accuracy: 0.796875\n","Epoch  7, Batch 291 -Loss:   244.4128 Validation Accuracy: 0.796875\n","Epoch  7, Batch 292 -Loss:   179.4087 Validation Accuracy: 0.796875\n","Epoch  7, Batch 293 -Loss:   334.4334 Validation Accuracy: 0.800781\n","Epoch  7, Batch 294 -Loss:   282.1260 Validation Accuracy: 0.800781\n","Epoch  7, Batch 295 -Loss:   411.8712 Validation Accuracy: 0.804688\n","Epoch  7, Batch 296 -Loss:   368.2772 Validation Accuracy: 0.808594\n","Epoch  7, Batch 297 -Loss:   330.6847 Validation Accuracy: 0.804688\n","Epoch  7, Batch 298 -Loss:   239.6795 Validation Accuracy: 0.804688\n","Epoch  7, Batch 299 -Loss:   351.3475 Validation Accuracy: 0.796875\n","Epoch  7, Batch 300 -Loss:   404.4997 Validation Accuracy: 0.800781\n","Epoch  7, Batch 301 -Loss:   344.7567 Validation Accuracy: 0.804688\n","Epoch  7, Batch 302 -Loss:   322.6191 Validation Accuracy: 0.804688\n","Epoch  7, Batch 303 -Loss:   236.8974 Validation Accuracy: 0.808594\n","Epoch  7, Batch 304 -Loss:   236.4749 Validation Accuracy: 0.808594\n","Epoch  7, Batch 305 -Loss:   304.7449 Validation Accuracy: 0.800781\n","Epoch  7, Batch 306 -Loss:   334.6416 Validation Accuracy: 0.800781\n","Epoch  7, Batch 307 -Loss:   377.5295 Validation Accuracy: 0.800781\n","Epoch  7, Batch 308 -Loss:   360.9895 Validation Accuracy: 0.804688\n","Epoch  7, Batch 309 -Loss:   312.8893 Validation Accuracy: 0.808594\n","Epoch  7, Batch 310 -Loss:   335.3914 Validation Accuracy: 0.804688\n","Epoch  7, Batch 311 -Loss:   497.4473 Validation Accuracy: 0.804688\n","Epoch  7, Batch 312 -Loss:   364.4223 Validation Accuracy: 0.800781\n","Epoch  7, Batch 313 -Loss:   238.0262 Validation Accuracy: 0.800781\n","Epoch  7, Batch 314 -Loss:   217.2363 Validation Accuracy: 0.804688\n","Epoch  7, Batch 315 -Loss:   195.9023 Validation Accuracy: 0.804688\n","Epoch  7, Batch 316 -Loss:   208.2151 Validation Accuracy: 0.804688\n","Epoch  7, Batch 317 -Loss:   159.6690 Validation Accuracy: 0.804688\n","Epoch  7, Batch 318 -Loss:   246.2804 Validation Accuracy: 0.800781\n","Epoch  7, Batch 319 -Loss:   309.7230 Validation Accuracy: 0.804688\n","Epoch  7, Batch 320 -Loss:   377.0117 Validation Accuracy: 0.800781\n","Epoch  7, Batch 321 -Loss:   346.1740 Validation Accuracy: 0.804688\n","Epoch  7, Batch 322 -Loss:   386.9532 Validation Accuracy: 0.808594\n","Epoch  7, Batch 323 -Loss:   368.6262 Validation Accuracy: 0.804688\n","Epoch  7, Batch 324 -Loss:   285.0634 Validation Accuracy: 0.804688\n","Epoch  7, Batch 325 -Loss:   248.7915 Validation Accuracy: 0.804688\n","Epoch  7, Batch 326 -Loss:   306.6371 Validation Accuracy: 0.804688\n","Epoch  7, Batch 327 -Loss:   162.5587 Validation Accuracy: 0.804688\n","Epoch  7, Batch 328 -Loss:   391.5874 Validation Accuracy: 0.796875\n","Epoch  7, Batch 329 -Loss:   275.7787 Validation Accuracy: 0.800781\n","Epoch  7, Batch 330 -Loss:   344.0889 Validation Accuracy: 0.800781\n","Epoch  7, Batch 331 -Loss:   179.4176 Validation Accuracy: 0.796875\n","Epoch  7, Batch 332 -Loss:   251.9567 Validation Accuracy: 0.800781\n","Epoch  7, Batch 333 -Loss:   241.1002 Validation Accuracy: 0.796875\n","Epoch  7, Batch 334 -Loss:   279.8998 Validation Accuracy: 0.796875\n","Epoch  7, Batch 335 -Loss:   492.8194 Validation Accuracy: 0.796875\n","Epoch  7, Batch 336 -Loss:   332.2050 Validation Accuracy: 0.796875\n","Epoch  7, Batch 337 -Loss:   250.2902 Validation Accuracy: 0.792969\n","Epoch  7, Batch 338 -Loss:   370.3532 Validation Accuracy: 0.792969\n","Epoch  7, Batch 339 -Loss:   277.5663 Validation Accuracy: 0.792969\n","Epoch  7, Batch 340 -Loss:   322.6904 Validation Accuracy: 0.792969\n","Epoch  7, Batch 341 -Loss:   310.0647 Validation Accuracy: 0.796875\n","Epoch  7, Batch 342 -Loss:   443.0320 Validation Accuracy: 0.796875\n","Epoch  7, Batch 343 -Loss:   426.3069 Validation Accuracy: 0.800781\n","Epoch  7, Batch 344 -Loss:   248.1587 Validation Accuracy: 0.804688\n","Epoch  7, Batch 345 -Loss:   405.7665 Validation Accuracy: 0.804688\n","Epoch  7, Batch 346 -Loss:   258.7916 Validation Accuracy: 0.804688\n","Epoch  7, Batch 347 -Loss:   252.2310 Validation Accuracy: 0.804688\n","Epoch  7, Batch 348 -Loss:   166.8865 Validation Accuracy: 0.804688\n","Epoch  7, Batch 349 -Loss:   381.1516 Validation Accuracy: 0.804688\n","Epoch  7, Batch 350 -Loss:   326.9420 Validation Accuracy: 0.804688\n","Epoch  7, Batch 351 -Loss:   334.7133 Validation Accuracy: 0.804688\n","Epoch  7, Batch 352 -Loss:   235.4899 Validation Accuracy: 0.804688\n","Epoch  7, Batch 353 -Loss:   336.3757 Validation Accuracy: 0.800781\n","Epoch  7, Batch 354 -Loss:   343.1346 Validation Accuracy: 0.800781\n","Epoch  7, Batch 355 -Loss:   238.4384 Validation Accuracy: 0.800781\n","Epoch  7, Batch 356 -Loss:   218.3148 Validation Accuracy: 0.800781\n","Epoch  7, Batch 357 -Loss:   245.4673 Validation Accuracy: 0.800781\n","Epoch  7, Batch 358 -Loss:   357.1447 Validation Accuracy: 0.800781\n","Epoch  7, Batch 359 -Loss:   292.2148 Validation Accuracy: 0.796875\n","Epoch  7, Batch 360 -Loss:   295.8298 Validation Accuracy: 0.796875\n","Epoch  7, Batch 361 -Loss:   361.3221 Validation Accuracy: 0.796875\n","Epoch  7, Batch 362 -Loss:   312.0717 Validation Accuracy: 0.804688\n","Epoch  7, Batch 363 -Loss:   373.7905 Validation Accuracy: 0.804688\n","Epoch  7, Batch 364 -Loss:   282.8812 Validation Accuracy: 0.804688\n","Epoch  7, Batch 365 -Loss:   230.3447 Validation Accuracy: 0.804688\n","Epoch  7, Batch 366 -Loss:   376.4577 Validation Accuracy: 0.804688\n","Epoch  7, Batch 367 -Loss:   391.8293 Validation Accuracy: 0.804688\n","Epoch  7, Batch 368 -Loss:   273.9344 Validation Accuracy: 0.800781\n","Epoch  7, Batch 369 -Loss:   342.3048 Validation Accuracy: 0.800781\n","Epoch  7, Batch 370 -Loss:   288.0128 Validation Accuracy: 0.800781\n","Epoch  7, Batch 371 -Loss:   307.4890 Validation Accuracy: 0.800781\n","Epoch  7, Batch 372 -Loss:   280.1922 Validation Accuracy: 0.796875\n","Epoch  7, Batch 373 -Loss:   230.7118 Validation Accuracy: 0.800781\n","Epoch  7, Batch 374 -Loss:   232.5418 Validation Accuracy: 0.800781\n","Epoch  7, Batch 375 -Loss:   315.1677 Validation Accuracy: 0.800781\n","Epoch  7, Batch 376 -Loss:   313.6308 Validation Accuracy: 0.800781\n","Epoch  7, Batch 377 -Loss:   220.1717 Validation Accuracy: 0.804688\n","Epoch  7, Batch 378 -Loss:   285.1915 Validation Accuracy: 0.804688\n","Epoch  7, Batch 379 -Loss:   271.3368 Validation Accuracy: 0.796875\n","Epoch  7, Batch 380 -Loss:   402.8115 Validation Accuracy: 0.796875\n","Epoch  7, Batch 381 -Loss:   256.4651 Validation Accuracy: 0.796875\n","Epoch  7, Batch 382 -Loss:   459.8762 Validation Accuracy: 0.800781\n","Epoch  7, Batch 383 -Loss:   330.2277 Validation Accuracy: 0.800781\n","Epoch  7, Batch 384 -Loss:   358.2664 Validation Accuracy: 0.804688\n","Epoch  7, Batch 385 -Loss:   287.4277 Validation Accuracy: 0.804688\n","Epoch  7, Batch 386 -Loss:   392.0535 Validation Accuracy: 0.800781\n","Epoch  7, Batch 387 -Loss:   197.9346 Validation Accuracy: 0.800781\n","Epoch  7, Batch 388 -Loss:   256.0338 Validation Accuracy: 0.800781\n","Epoch  7, Batch 389 -Loss:   248.2517 Validation Accuracy: 0.800781\n","Epoch  7, Batch 390 -Loss:   285.8871 Validation Accuracy: 0.804688\n","Epoch  7, Batch 391 -Loss:   233.0850 Validation Accuracy: 0.804688\n","Epoch  7, Batch 392 -Loss:   295.2899 Validation Accuracy: 0.804688\n","Epoch  7, Batch 393 -Loss:   295.5322 Validation Accuracy: 0.804688\n","Epoch  7, Batch 394 -Loss:   283.5590 Validation Accuracy: 0.808594\n","Epoch  7, Batch 395 -Loss:   534.6539 Validation Accuracy: 0.800781\n","Epoch  7, Batch 396 -Loss:   438.0594 Validation Accuracy: 0.800781\n","Epoch  7, Batch 397 -Loss:   273.7162 Validation Accuracy: 0.808594\n","Epoch  7, Batch 398 -Loss:   447.8405 Validation Accuracy: 0.808594\n","Epoch  7, Batch 399 -Loss:   229.6924 Validation Accuracy: 0.808594\n","Epoch  7, Batch 400 -Loss:   321.7882 Validation Accuracy: 0.804688\n","Epoch  7, Batch 401 -Loss:   266.0443 Validation Accuracy: 0.804688\n","Epoch  7, Batch 402 -Loss:   235.0359 Validation Accuracy: 0.800781\n","Epoch  7, Batch 403 -Loss:   148.8762 Validation Accuracy: 0.804688\n","Epoch  7, Batch 404 -Loss:   420.7663 Validation Accuracy: 0.804688\n","Epoch  7, Batch 405 -Loss:   276.8079 Validation Accuracy: 0.800781\n","Epoch  7, Batch 406 -Loss:   472.5975 Validation Accuracy: 0.796875\n","Epoch  7, Batch 407 -Loss:   333.6227 Validation Accuracy: 0.796875\n","Epoch  7, Batch 408 -Loss:   270.4413 Validation Accuracy: 0.800781\n","Epoch  7, Batch 409 -Loss:   197.8612 Validation Accuracy: 0.804688\n","Epoch  7, Batch 410 -Loss:   385.3631 Validation Accuracy: 0.800781\n","Epoch  7, Batch 411 -Loss:   287.9388 Validation Accuracy: 0.800781\n","Epoch  7, Batch 412 -Loss:   316.7509 Validation Accuracy: 0.800781\n","Epoch  7, Batch 413 -Loss:   221.2029 Validation Accuracy: 0.800781\n","Epoch  7, Batch 414 -Loss:   286.5993 Validation Accuracy: 0.800781\n","Epoch  7, Batch 415 -Loss:   352.9864 Validation Accuracy: 0.796875\n","Epoch  7, Batch 416 -Loss:   141.2669 Validation Accuracy: 0.808594\n","Epoch  7, Batch 417 -Loss:   194.1112 Validation Accuracy: 0.804688\n","Epoch  7, Batch 418 -Loss:   196.6100 Validation Accuracy: 0.804688\n","Epoch  7, Batch 419 -Loss:   401.6761 Validation Accuracy: 0.804688\n","Epoch  7, Batch 420 -Loss:   167.5775 Validation Accuracy: 0.804688\n","Epoch  7, Batch 421 -Loss:   465.3746 Validation Accuracy: 0.808594\n","Epoch  7, Batch 422 -Loss:   371.7908 Validation Accuracy: 0.800781\n","Epoch  7, Batch 423 -Loss:   259.8261 Validation Accuracy: 0.800781\n","Epoch  7, Batch 424 -Loss:   352.7792 Validation Accuracy: 0.796875\n","Epoch  7, Batch 425 -Loss:   277.5850 Validation Accuracy: 0.796875\n","Epoch  7, Batch 426 -Loss:   280.5910 Validation Accuracy: 0.796875\n","Epoch  7, Batch 427 -Loss:   180.8978 Validation Accuracy: 0.796875\n","Epoch  7, Batch 428 -Loss:   334.0977 Validation Accuracy: 0.796875\n","Epoch  7, Batch 429 -Loss:   307.6432 Validation Accuracy: 0.796875\n","Epoch  8, Batch   1 -Loss:   303.6823 Validation Accuracy: 0.796875\n","Epoch  8, Batch   2 -Loss:   277.1556 Validation Accuracy: 0.796875\n","Epoch  8, Batch   3 -Loss:   274.8554 Validation Accuracy: 0.792969\n","Epoch  8, Batch   4 -Loss:   539.0075 Validation Accuracy: 0.792969\n","Epoch  8, Batch   5 -Loss:   210.8682 Validation Accuracy: 0.792969\n","Epoch  8, Batch   6 -Loss:   218.9034 Validation Accuracy: 0.796875\n","Epoch  8, Batch   7 -Loss:   328.3693 Validation Accuracy: 0.796875\n","Epoch  8, Batch   8 -Loss:   206.5791 Validation Accuracy: 0.792969\n","Epoch  8, Batch   9 -Loss:   347.0270 Validation Accuracy: 0.792969\n","Epoch  8, Batch  10 -Loss:   261.7896 Validation Accuracy: 0.789062\n","Epoch  8, Batch  11 -Loss:   206.3818 Validation Accuracy: 0.792969\n","Epoch  8, Batch  12 -Loss:   329.1110 Validation Accuracy: 0.792969\n","Epoch  8, Batch  13 -Loss:   180.0585 Validation Accuracy: 0.796875\n","Epoch  8, Batch  14 -Loss:   280.1703 Validation Accuracy: 0.796875\n","Epoch  8, Batch  15 -Loss:   302.2032 Validation Accuracy: 0.800781\n","Epoch  8, Batch  16 -Loss:   163.3854 Validation Accuracy: 0.800781\n","Epoch  8, Batch  17 -Loss:   336.8187 Validation Accuracy: 0.800781\n","Epoch  8, Batch  18 -Loss:   319.0936 Validation Accuracy: 0.796875\n","Epoch  8, Batch  19 -Loss:   251.8508 Validation Accuracy: 0.796875\n","Epoch  8, Batch  20 -Loss:   280.3621 Validation Accuracy: 0.796875\n","Epoch  8, Batch  21 -Loss:   194.9325 Validation Accuracy: 0.796875\n","Epoch  8, Batch  22 -Loss:   201.3586 Validation Accuracy: 0.796875\n","Epoch  8, Batch  23 -Loss:   310.7991 Validation Accuracy: 0.796875\n","Epoch  8, Batch  24 -Loss:   353.9217 Validation Accuracy: 0.796875\n","Epoch  8, Batch  25 -Loss:   298.3932 Validation Accuracy: 0.792969\n","Epoch  8, Batch  26 -Loss:   218.7391 Validation Accuracy: 0.796875\n","Epoch  8, Batch  27 -Loss:   403.2870 Validation Accuracy: 0.796875\n","Epoch  8, Batch  28 -Loss:   355.4634 Validation Accuracy: 0.796875\n","Epoch  8, Batch  29 -Loss:   246.8213 Validation Accuracy: 0.800781\n","Epoch  8, Batch  30 -Loss:   177.9694 Validation Accuracy: 0.800781\n","Epoch  8, Batch  31 -Loss:   302.8178 Validation Accuracy: 0.796875\n","Epoch  8, Batch  32 -Loss:   122.6915 Validation Accuracy: 0.796875\n","Epoch  8, Batch  33 -Loss:   399.2170 Validation Accuracy: 0.792969\n","Epoch  8, Batch  34 -Loss:   171.8420 Validation Accuracy: 0.796875\n","Epoch  8, Batch  35 -Loss:   233.8481 Validation Accuracy: 0.796875\n","Epoch  8, Batch  36 -Loss:   340.7564 Validation Accuracy: 0.796875\n","Epoch  8, Batch  37 -Loss:   289.3329 Validation Accuracy: 0.792969\n","Epoch  8, Batch  38 -Loss:   341.3390 Validation Accuracy: 0.792969\n","Epoch  8, Batch  39 -Loss:   316.2277 Validation Accuracy: 0.796875\n","Epoch  8, Batch  40 -Loss:   168.9036 Validation Accuracy: 0.796875\n","Epoch  8, Batch  41 -Loss:   330.2520 Validation Accuracy: 0.796875\n","Epoch  8, Batch  42 -Loss:   223.8523 Validation Accuracy: 0.796875\n","Epoch  8, Batch  43 -Loss:   271.3010 Validation Accuracy: 0.796875\n","Epoch  8, Batch  44 -Loss:   244.7679 Validation Accuracy: 0.796875\n","Epoch  8, Batch  45 -Loss:   311.0429 Validation Accuracy: 0.796875\n","Epoch  8, Batch  46 -Loss:   248.8367 Validation Accuracy: 0.796875\n","Epoch  8, Batch  47 -Loss:   196.5588 Validation Accuracy: 0.796875\n","Epoch  8, Batch  48 -Loss:   260.7125 Validation Accuracy: 0.800781\n","Epoch  8, Batch  49 -Loss:   348.7249 Validation Accuracy: 0.800781\n","Epoch  8, Batch  50 -Loss:   204.1846 Validation Accuracy: 0.796875\n","Epoch  8, Batch  51 -Loss:   158.2607 Validation Accuracy: 0.796875\n","Epoch  8, Batch  52 -Loss:   183.3735 Validation Accuracy: 0.796875\n","Epoch  8, Batch  53 -Loss:   416.5776 Validation Accuracy: 0.800781\n","Epoch  8, Batch  54 -Loss:   234.6538 Validation Accuracy: 0.800781\n","Epoch  8, Batch  55 -Loss:   273.7846 Validation Accuracy: 0.796875\n","Epoch  8, Batch  56 -Loss:   226.0699 Validation Accuracy: 0.796875\n","Epoch  8, Batch  57 -Loss:   354.7712 Validation Accuracy: 0.796875\n","Epoch  8, Batch  58 -Loss:   215.4169 Validation Accuracy: 0.792969\n","Epoch  8, Batch  59 -Loss:   372.7104 Validation Accuracy: 0.792969\n","Epoch  8, Batch  60 -Loss:   404.6276 Validation Accuracy: 0.792969\n","Epoch  8, Batch  61 -Loss:   284.0580 Validation Accuracy: 0.796875\n","Epoch  8, Batch  62 -Loss:   216.1850 Validation Accuracy: 0.792969\n","Epoch  8, Batch  63 -Loss:   314.0066 Validation Accuracy: 0.792969\n","Epoch  8, Batch  64 -Loss:   249.6390 Validation Accuracy: 0.792969\n","Epoch  8, Batch  65 -Loss:   238.3736 Validation Accuracy: 0.792969\n","Epoch  8, Batch  66 -Loss:   317.7834 Validation Accuracy: 0.796875\n","Epoch  8, Batch  67 -Loss:   295.1265 Validation Accuracy: 0.796875\n","Epoch  8, Batch  68 -Loss:   332.6824 Validation Accuracy: 0.796875\n","Epoch  8, Batch  69 -Loss:   320.0596 Validation Accuracy: 0.796875\n","Epoch  8, Batch  70 -Loss:   348.4445 Validation Accuracy: 0.796875\n","Epoch  8, Batch  71 -Loss:   328.3537 Validation Accuracy: 0.796875\n","Epoch  8, Batch  72 -Loss:   233.1600 Validation Accuracy: 0.796875\n","Epoch  8, Batch  73 -Loss:   274.8053 Validation Accuracy: 0.796875\n","Epoch  8, Batch  74 -Loss:   315.4844 Validation Accuracy: 0.796875\n","Epoch  8, Batch  75 -Loss:   269.3601 Validation Accuracy: 0.796875\n","Epoch  8, Batch  76 -Loss:   367.3679 Validation Accuracy: 0.796875\n","Epoch  8, Batch  77 -Loss:   474.7355 Validation Accuracy: 0.796875\n","Epoch  8, Batch  78 -Loss:   260.6841 Validation Accuracy: 0.800781\n","Epoch  8, Batch  79 -Loss:   339.0959 Validation Accuracy: 0.800781\n","Epoch  8, Batch  80 -Loss:   265.0603 Validation Accuracy: 0.796875\n","Epoch  8, Batch  81 -Loss:   178.8397 Validation Accuracy: 0.796875\n","Epoch  8, Batch  82 -Loss:   168.5801 Validation Accuracy: 0.796875\n","Epoch  8, Batch  83 -Loss:   140.6085 Validation Accuracy: 0.796875\n","Epoch  8, Batch  84 -Loss:   339.2253 Validation Accuracy: 0.792969\n","Epoch  8, Batch  85 -Loss:   287.8474 Validation Accuracy: 0.792969\n","Epoch  8, Batch  86 -Loss:   231.9089 Validation Accuracy: 0.792969\n","Epoch  8, Batch  87 -Loss:   266.4448 Validation Accuracy: 0.792969\n","Epoch  8, Batch  88 -Loss:   419.2861 Validation Accuracy: 0.792969\n","Epoch  8, Batch  89 -Loss:   362.0133 Validation Accuracy: 0.792969\n","Epoch  8, Batch  90 -Loss:   271.3243 Validation Accuracy: 0.792969\n","Epoch  8, Batch  91 -Loss:   291.4308 Validation Accuracy: 0.792969\n","Epoch  8, Batch  92 -Loss:   432.8857 Validation Accuracy: 0.792969\n","Epoch  8, Batch  93 -Loss:   223.4761 Validation Accuracy: 0.792969\n","Epoch  8, Batch  94 -Loss:   447.4940 Validation Accuracy: 0.792969\n","Epoch  8, Batch  95 -Loss:   342.4124 Validation Accuracy: 0.796875\n","Epoch  8, Batch  96 -Loss:   361.2569 Validation Accuracy: 0.796875\n","Epoch  8, Batch  97 -Loss:   215.6214 Validation Accuracy: 0.796875\n","Epoch  8, Batch  98 -Loss:   286.3677 Validation Accuracy: 0.792969\n","Epoch  8, Batch  99 -Loss:   296.6736 Validation Accuracy: 0.792969\n","Epoch  8, Batch 100 -Loss:   204.5453 Validation Accuracy: 0.792969\n","Epoch  8, Batch 101 -Loss:   374.1453 Validation Accuracy: 0.789062\n","Epoch  8, Batch 102 -Loss:   246.1079 Validation Accuracy: 0.789062\n","Epoch  8, Batch 103 -Loss:   314.9800 Validation Accuracy: 0.789062\n","Epoch  8, Batch 104 -Loss:   164.0123 Validation Accuracy: 0.789062\n","Epoch  8, Batch 105 -Loss:   266.7867 Validation Accuracy: 0.789062\n","Epoch  8, Batch 106 -Loss:   344.5281 Validation Accuracy: 0.789062\n","Epoch  8, Batch 107 -Loss:   152.0160 Validation Accuracy: 0.792969\n","Epoch  8, Batch 108 -Loss:   240.9017 Validation Accuracy: 0.792969\n","Epoch  8, Batch 109 -Loss:   247.6527 Validation Accuracy: 0.792969\n","Epoch  8, Batch 110 -Loss:   200.8789 Validation Accuracy: 0.792969\n","Epoch  8, Batch 111 -Loss:   253.5061 Validation Accuracy: 0.785156\n","Epoch  8, Batch 112 -Loss:   263.6784 Validation Accuracy: 0.792969\n","Epoch  8, Batch 113 -Loss:   251.5962 Validation Accuracy: 0.796875\n","Epoch  8, Batch 114 -Loss:   256.7450 Validation Accuracy: 0.792969\n","Epoch  8, Batch 115 -Loss:   222.0249 Validation Accuracy: 0.792969\n","Epoch  8, Batch 116 -Loss:   300.4586 Validation Accuracy: 0.792969\n","Epoch  8, Batch 117 -Loss:   191.0749 Validation Accuracy: 0.792969\n","Epoch  8, Batch 118 -Loss:   293.1317 Validation Accuracy: 0.792969\n","Epoch  8, Batch 119 -Loss:   180.3550 Validation Accuracy: 0.796875\n","Epoch  8, Batch 120 -Loss:   161.6888 Validation Accuracy: 0.796875\n","Epoch  8, Batch 121 -Loss:   264.1702 Validation Accuracy: 0.800781\n","Epoch  8, Batch 122 -Loss:   243.4024 Validation Accuracy: 0.796875\n","Epoch  8, Batch 123 -Loss:   267.5780 Validation Accuracy: 0.792969\n","Epoch  8, Batch 124 -Loss:   340.3915 Validation Accuracy: 0.792969\n","Epoch  8, Batch 125 -Loss:   188.4513 Validation Accuracy: 0.792969\n","Epoch  8, Batch 126 -Loss:   269.6924 Validation Accuracy: 0.792969\n","Epoch  8, Batch 127 -Loss:   318.9115 Validation Accuracy: 0.792969\n","Epoch  8, Batch 128 -Loss:   283.5260 Validation Accuracy: 0.792969\n","Epoch  8, Batch 129 -Loss:   330.9030 Validation Accuracy: 0.792969\n","Epoch  8, Batch 130 -Loss:   225.3751 Validation Accuracy: 0.792969\n","Epoch  8, Batch 131 -Loss:   296.8828 Validation Accuracy: 0.796875\n","Epoch  8, Batch 132 -Loss:   418.2906 Validation Accuracy: 0.796875\n","Epoch  8, Batch 133 -Loss:   207.4011 Validation Accuracy: 0.796875\n","Epoch  8, Batch 134 -Loss:   397.1877 Validation Accuracy: 0.796875\n","Epoch  8, Batch 135 -Loss:   315.5707 Validation Accuracy: 0.800781\n","Epoch  8, Batch 136 -Loss:   331.5302 Validation Accuracy: 0.800781\n","Epoch  8, Batch 137 -Loss:   402.8607 Validation Accuracy: 0.800781\n","Epoch  8, Batch 138 -Loss:   205.8565 Validation Accuracy: 0.804688\n","Epoch  8, Batch 139 -Loss:   292.6166 Validation Accuracy: 0.804688\n","Epoch  8, Batch 140 -Loss:   318.3453 Validation Accuracy: 0.800781\n","Epoch  8, Batch 141 -Loss:   216.9300 Validation Accuracy: 0.800781\n","Epoch  8, Batch 142 -Loss:   330.3531 Validation Accuracy: 0.796875\n","Epoch  8, Batch 143 -Loss:   285.9506 Validation Accuracy: 0.804688\n","Epoch  8, Batch 144 -Loss:   232.8980 Validation Accuracy: 0.808594\n","Epoch  8, Batch 145 -Loss:   463.6897 Validation Accuracy: 0.800781\n","Epoch  8, Batch 146 -Loss:   136.7426 Validation Accuracy: 0.800781\n","Epoch  8, Batch 147 -Loss:   306.2678 Validation Accuracy: 0.800781\n","Epoch  8, Batch 148 -Loss:   278.4392 Validation Accuracy: 0.800781\n","Epoch  8, Batch 149 -Loss:   392.5479 Validation Accuracy: 0.800781\n","Epoch  8, Batch 150 -Loss:   329.0745 Validation Accuracy: 0.800781\n","Epoch  8, Batch 151 -Loss:   220.4243 Validation Accuracy: 0.804688\n","Epoch  8, Batch 152 -Loss:   298.1044 Validation Accuracy: 0.804688\n","Epoch  8, Batch 153 -Loss:   354.9961 Validation Accuracy: 0.804688\n","Epoch  8, Batch 154 -Loss:   369.2958 Validation Accuracy: 0.800781\n","Epoch  8, Batch 155 -Loss:   307.9967 Validation Accuracy: 0.796875\n","Epoch  8, Batch 156 -Loss:   256.2499 Validation Accuracy: 0.796875\n","Epoch  8, Batch 157 -Loss:   337.3244 Validation Accuracy: 0.796875\n","Epoch  8, Batch 158 -Loss:   403.0289 Validation Accuracy: 0.796875\n","Epoch  8, Batch 159 -Loss:   289.6250 Validation Accuracy: 0.796875\n","Epoch  8, Batch 160 -Loss:   256.2648 Validation Accuracy: 0.796875\n","Epoch  8, Batch 161 -Loss:   179.0811 Validation Accuracy: 0.796875\n","Epoch  8, Batch 162 -Loss:   399.1572 Validation Accuracy: 0.796875\n","Epoch  8, Batch 163 -Loss:   182.2790 Validation Accuracy: 0.796875\n","Epoch  8, Batch 164 -Loss:   164.0352 Validation Accuracy: 0.796875\n","Epoch  8, Batch 165 -Loss:   301.5429 Validation Accuracy: 0.796875\n","Epoch  8, Batch 166 -Loss:   247.3116 Validation Accuracy: 0.796875\n","Epoch  8, Batch 167 -Loss:   270.2278 Validation Accuracy: 0.792969\n","Epoch  8, Batch 168 -Loss:   345.8755 Validation Accuracy: 0.792969\n","Epoch  8, Batch 169 -Loss:   264.6388 Validation Accuracy: 0.792969\n","Epoch  8, Batch 170 -Loss:   410.9061 Validation Accuracy: 0.796875\n","Epoch  8, Batch 171 -Loss:   159.2924 Validation Accuracy: 0.792969\n","Epoch  8, Batch 172 -Loss:   312.5922 Validation Accuracy: 0.796875\n","Epoch  8, Batch 173 -Loss:   248.5785 Validation Accuracy: 0.796875\n","Epoch  8, Batch 174 -Loss:   278.1794 Validation Accuracy: 0.800781\n","Epoch  8, Batch 175 -Loss:   307.5174 Validation Accuracy: 0.800781\n","Epoch  8, Batch 176 -Loss:   419.1321 Validation Accuracy: 0.796875\n","Epoch  8, Batch 177 -Loss:   229.8745 Validation Accuracy: 0.796875\n","Epoch  8, Batch 178 -Loss:   512.7899 Validation Accuracy: 0.800781\n","Epoch  8, Batch 179 -Loss:   262.2760 Validation Accuracy: 0.804688\n","Epoch  8, Batch 180 -Loss:   245.2118 Validation Accuracy: 0.804688\n","Epoch  8, Batch 181 -Loss:   231.9170 Validation Accuracy: 0.804688\n","Epoch  8, Batch 182 -Loss:   225.6064 Validation Accuracy: 0.804688\n","Epoch  8, Batch 183 -Loss:   230.2062 Validation Accuracy: 0.804688\n","Epoch  8, Batch 184 -Loss:   274.1770 Validation Accuracy: 0.796875\n","Epoch  8, Batch 185 -Loss:   317.8952 Validation Accuracy: 0.796875\n","Epoch  8, Batch 186 -Loss:   261.4849 Validation Accuracy: 0.812500\n","Epoch  8, Batch 187 -Loss:   328.0749 Validation Accuracy: 0.808594\n","Epoch  8, Batch 188 -Loss:   299.7132 Validation Accuracy: 0.808594\n","Epoch  8, Batch 189 -Loss:   345.8411 Validation Accuracy: 0.812500\n","Epoch  8, Batch 190 -Loss:   319.5275 Validation Accuracy: 0.796875\n","Epoch  8, Batch 191 -Loss:   233.0008 Validation Accuracy: 0.796875\n","Epoch  8, Batch 192 -Loss:   270.1708 Validation Accuracy: 0.800781\n","Epoch  8, Batch 193 -Loss:   296.1165 Validation Accuracy: 0.796875\n","Epoch  8, Batch 194 -Loss:   244.7919 Validation Accuracy: 0.792969\n","Epoch  8, Batch 195 -Loss:   247.7794 Validation Accuracy: 0.792969\n","Epoch  8, Batch 196 -Loss:   321.4062 Validation Accuracy: 0.792969\n","Epoch  8, Batch 197 -Loss:   250.7956 Validation Accuracy: 0.789062\n","Epoch  8, Batch 198 -Loss:   132.0043 Validation Accuracy: 0.792969\n","Epoch  8, Batch 199 -Loss:   236.2204 Validation Accuracy: 0.792969\n","Epoch  8, Batch 200 -Loss:   327.6417 Validation Accuracy: 0.792969\n","Epoch  8, Batch 201 -Loss:   365.6233 Validation Accuracy: 0.792969\n","Epoch  8, Batch 202 -Loss:   232.6233 Validation Accuracy: 0.792969\n","Epoch  8, Batch 203 -Loss:   307.5291 Validation Accuracy: 0.792969\n","Epoch  8, Batch 204 -Loss:   331.1423 Validation Accuracy: 0.792969\n","Epoch  8, Batch 205 -Loss:   265.5861 Validation Accuracy: 0.792969\n","Epoch  8, Batch 206 -Loss:   358.1145 Validation Accuracy: 0.792969\n","Epoch  8, Batch 207 -Loss:   241.9670 Validation Accuracy: 0.792969\n","Epoch  8, Batch 208 -Loss:   407.1557 Validation Accuracy: 0.792969\n","Epoch  8, Batch 209 -Loss:   322.6344 Validation Accuracy: 0.796875\n","Epoch  8, Batch 210 -Loss:   236.9290 Validation Accuracy: 0.792969\n","Epoch  8, Batch 211 -Loss:   227.6254 Validation Accuracy: 0.796875\n","Epoch  8, Batch 212 -Loss:   306.7096 Validation Accuracy: 0.804688\n","Epoch  8, Batch 213 -Loss:   138.7795 Validation Accuracy: 0.804688\n","Epoch  8, Batch 214 -Loss:   240.0156 Validation Accuracy: 0.804688\n","Epoch  8, Batch 215 -Loss:   247.3226 Validation Accuracy: 0.804688\n","Epoch  8, Batch 216 -Loss:   227.9209 Validation Accuracy: 0.804688\n","Epoch  8, Batch 217 -Loss:   214.3453 Validation Accuracy: 0.804688\n","Epoch  8, Batch 218 -Loss:   288.9904 Validation Accuracy: 0.796875\n","Epoch  8, Batch 219 -Loss:   241.0074 Validation Accuracy: 0.796875\n","Epoch  8, Batch 220 -Loss:   436.1635 Validation Accuracy: 0.804688\n","Epoch  8, Batch 221 -Loss:   225.9400 Validation Accuracy: 0.804688\n","Epoch  8, Batch 222 -Loss:   362.1824 Validation Accuracy: 0.800781\n","Epoch  8, Batch 223 -Loss:   473.5416 Validation Accuracy: 0.800781\n","Epoch  8, Batch 224 -Loss:   391.8765 Validation Accuracy: 0.800781\n","Epoch  8, Batch 225 -Loss:   292.9470 Validation Accuracy: 0.800781\n","Epoch  8, Batch 226 -Loss:   208.5098 Validation Accuracy: 0.800781\n","Epoch  8, Batch 227 -Loss:   272.0479 Validation Accuracy: 0.800781\n","Epoch  8, Batch 228 -Loss:   219.4017 Validation Accuracy: 0.800781\n","Epoch  8, Batch 229 -Loss:   327.7415 Validation Accuracy: 0.804688\n","Epoch  8, Batch 230 -Loss:   385.0167 Validation Accuracy: 0.796875\n","Epoch  8, Batch 231 -Loss:   314.8864 Validation Accuracy: 0.800781\n","Epoch  8, Batch 232 -Loss:   203.5191 Validation Accuracy: 0.804688\n","Epoch  8, Batch 233 -Loss:   227.9024 Validation Accuracy: 0.804688\n","Epoch  8, Batch 234 -Loss:   156.1856 Validation Accuracy: 0.804688\n","Epoch  8, Batch 235 -Loss:   303.7971 Validation Accuracy: 0.800781\n","Epoch  8, Batch 236 -Loss:   297.6722 Validation Accuracy: 0.800781\n","Epoch  8, Batch 237 -Loss:   410.9869 Validation Accuracy: 0.804688\n","Epoch  8, Batch 238 -Loss:   271.7176 Validation Accuracy: 0.800781\n","Epoch  8, Batch 239 -Loss:   177.3607 Validation Accuracy: 0.804688\n","Epoch  8, Batch 240 -Loss:   307.0753 Validation Accuracy: 0.804688\n","Epoch  8, Batch 241 -Loss:   235.7061 Validation Accuracy: 0.796875\n","Epoch  8, Batch 242 -Loss:   248.8674 Validation Accuracy: 0.796875\n","Epoch  8, Batch 243 -Loss:   230.5057 Validation Accuracy: 0.796875\n","Epoch  8, Batch 244 -Loss:   379.3277 Validation Accuracy: 0.796875\n","Epoch  8, Batch 245 -Loss:   155.9637 Validation Accuracy: 0.796875\n","Epoch  8, Batch 246 -Loss:   230.1705 Validation Accuracy: 0.796875\n","Epoch  8, Batch 247 -Loss:   271.2430 Validation Accuracy: 0.796875\n","Epoch  8, Batch 248 -Loss:   295.5734 Validation Accuracy: 0.796875\n","Epoch  8, Batch 249 -Loss:   331.7401 Validation Accuracy: 0.796875\n","Epoch  8, Batch 250 -Loss:   335.6317 Validation Accuracy: 0.796875\n","Epoch  8, Batch 251 -Loss:   284.7550 Validation Accuracy: 0.796875\n","Epoch  8, Batch 252 -Loss:   236.0862 Validation Accuracy: 0.796875\n","Epoch  8, Batch 253 -Loss:   202.6835 Validation Accuracy: 0.796875\n","Epoch  8, Batch 254 -Loss:   348.0041 Validation Accuracy: 0.796875\n","Epoch  8, Batch 255 -Loss:   236.5842 Validation Accuracy: 0.796875\n","Epoch  8, Batch 256 -Loss:   377.6561 Validation Accuracy: 0.800781\n","Epoch  8, Batch 257 -Loss:   295.8324 Validation Accuracy: 0.796875\n","Epoch  8, Batch 258 -Loss:   229.0475 Validation Accuracy: 0.796875\n","Epoch  8, Batch 259 -Loss:   228.1671 Validation Accuracy: 0.796875\n","Epoch  8, Batch 260 -Loss:   244.3512 Validation Accuracy: 0.796875\n","Epoch  8, Batch 261 -Loss:   252.6390 Validation Accuracy: 0.796875\n","Epoch  8, Batch 262 -Loss:   157.8145 Validation Accuracy: 0.796875\n","Epoch  8, Batch 263 -Loss:   310.1302 Validation Accuracy: 0.796875\n","Epoch  8, Batch 264 -Loss:   314.8923 Validation Accuracy: 0.796875\n","Epoch  8, Batch 265 -Loss:   364.0513 Validation Accuracy: 0.796875\n","Epoch  8, Batch 266 -Loss:   434.8380 Validation Accuracy: 0.796875\n","Epoch  8, Batch 267 -Loss:   417.7141 Validation Accuracy: 0.796875\n","Epoch  8, Batch 268 -Loss:   300.8794 Validation Accuracy: 0.792969\n","Epoch  8, Batch 269 -Loss:   310.6435 Validation Accuracy: 0.792969\n","Epoch  8, Batch 270 -Loss:   418.6248 Validation Accuracy: 0.796875\n","Epoch  8, Batch 271 -Loss:   346.0558 Validation Accuracy: 0.796875\n","Epoch  8, Batch 272 -Loss:   291.7203 Validation Accuracy: 0.792969\n","Epoch  8, Batch 273 -Loss:   211.9872 Validation Accuracy: 0.796875\n","Epoch  8, Batch 274 -Loss:   286.4031 Validation Accuracy: 0.792969\n","Epoch  8, Batch 275 -Loss:   208.2186 Validation Accuracy: 0.796875\n","Epoch  8, Batch 276 -Loss:   471.1507 Validation Accuracy: 0.796875\n","Epoch  8, Batch 277 -Loss:   300.2755 Validation Accuracy: 0.796875\n","Epoch  8, Batch 278 -Loss:   301.7014 Validation Accuracy: 0.796875\n","Epoch  8, Batch 279 -Loss:   343.5525 Validation Accuracy: 0.796875\n","Epoch  8, Batch 280 -Loss:   278.9331 Validation Accuracy: 0.796875\n","Epoch  8, Batch 281 -Loss:   198.7806 Validation Accuracy: 0.796875\n","Epoch  8, Batch 282 -Loss:   184.9092 Validation Accuracy: 0.796875\n","Epoch  8, Batch 283 -Loss:   293.7375 Validation Accuracy: 0.796875\n","Epoch  8, Batch 284 -Loss:   277.2804 Validation Accuracy: 0.796875\n","Epoch  8, Batch 285 -Loss:   355.3196 Validation Accuracy: 0.796875\n","Epoch  8, Batch 286 -Loss:   183.9852 Validation Accuracy: 0.796875\n","Epoch  8, Batch 287 -Loss:   230.0402 Validation Accuracy: 0.796875\n","Epoch  8, Batch 288 -Loss:   208.7202 Validation Accuracy: 0.796875\n","Epoch  8, Batch 289 -Loss:   335.2400 Validation Accuracy: 0.796875\n","Epoch  8, Batch 290 -Loss:   235.2055 Validation Accuracy: 0.796875\n","Epoch  8, Batch 291 -Loss:   400.0325 Validation Accuracy: 0.800781\n","Epoch  8, Batch 292 -Loss:   359.5386 Validation Accuracy: 0.800781\n","Epoch  8, Batch 293 -Loss:   334.6414 Validation Accuracy: 0.796875\n","Epoch  8, Batch 294 -Loss:   302.3896 Validation Accuracy: 0.796875\n","Epoch  8, Batch 295 -Loss:   362.0453 Validation Accuracy: 0.796875\n","Epoch  8, Batch 296 -Loss:   306.5166 Validation Accuracy: 0.796875\n","Epoch  8, Batch 297 -Loss:   334.6693 Validation Accuracy: 0.796875\n","Epoch  8, Batch 298 -Loss:   422.3286 Validation Accuracy: 0.796875\n","Epoch  8, Batch 299 -Loss:   289.7831 Validation Accuracy: 0.792969\n","Epoch  8, Batch 300 -Loss:   175.1911 Validation Accuracy: 0.792969\n","Epoch  8, Batch 301 -Loss:   248.1294 Validation Accuracy: 0.792969\n","Epoch  8, Batch 302 -Loss:   260.6675 Validation Accuracy: 0.789062\n","Epoch  8, Batch 303 -Loss:   349.6419 Validation Accuracy: 0.792969\n","Epoch  8, Batch 304 -Loss:   317.1287 Validation Accuracy: 0.792969\n","Epoch  8, Batch 305 -Loss:   281.1218 Validation Accuracy: 0.789062\n","Epoch  8, Batch 306 -Loss:   189.9136 Validation Accuracy: 0.792969\n","Epoch  8, Batch 307 -Loss:   211.7235 Validation Accuracy: 0.789062\n","Epoch  8, Batch 308 -Loss:   210.8033 Validation Accuracy: 0.792969\n","Epoch  8, Batch 309 -Loss:   156.8431 Validation Accuracy: 0.792969\n","Epoch  8, Batch 310 -Loss:   184.6374 Validation Accuracy: 0.792969\n","Epoch  8, Batch 311 -Loss:   284.1989 Validation Accuracy: 0.796875\n","Epoch  8, Batch 312 -Loss:   278.5629 Validation Accuracy: 0.792969\n","Epoch  8, Batch 313 -Loss:   352.8476 Validation Accuracy: 0.792969\n","Epoch  8, Batch 314 -Loss:   319.8155 Validation Accuracy: 0.792969\n","Epoch  8, Batch 315 -Loss:   317.4243 Validation Accuracy: 0.792969\n","Epoch  8, Batch 316 -Loss:   204.7427 Validation Accuracy: 0.792969\n","Epoch  8, Batch 317 -Loss:   243.7855 Validation Accuracy: 0.792969\n","Epoch  8, Batch 318 -Loss:   261.7629 Validation Accuracy: 0.792969\n","Epoch  8, Batch 319 -Loss:   267.0919 Validation Accuracy: 0.792969\n","Epoch  8, Batch 320 -Loss:   355.9702 Validation Accuracy: 0.792969\n","Epoch  8, Batch 321 -Loss:   266.5946 Validation Accuracy: 0.792969\n","Epoch  8, Batch 322 -Loss:   149.4925 Validation Accuracy: 0.792969\n","Epoch  8, Batch 323 -Loss:   299.7300 Validation Accuracy: 0.792969\n","Epoch  8, Batch 324 -Loss:   339.3451 Validation Accuracy: 0.792969\n","Epoch  8, Batch 325 -Loss:   265.5693 Validation Accuracy: 0.796875\n","Epoch  8, Batch 326 -Loss:   230.0625 Validation Accuracy: 0.800781\n","Epoch  8, Batch 327 -Loss:   359.9333 Validation Accuracy: 0.800781\n","Epoch  8, Batch 328 -Loss:   266.8838 Validation Accuracy: 0.800781\n","Epoch  8, Batch 329 -Loss:   348.5612 Validation Accuracy: 0.800781\n","Epoch  8, Batch 330 -Loss:   307.8762 Validation Accuracy: 0.800781\n","Epoch  8, Batch 331 -Loss:   319.0288 Validation Accuracy: 0.796875\n","Epoch  8, Batch 332 -Loss:   246.9567 Validation Accuracy: 0.800781\n","Epoch  8, Batch 333 -Loss:   203.4169 Validation Accuracy: 0.800781\n","Epoch  8, Batch 334 -Loss:   183.1235 Validation Accuracy: 0.800781\n","Epoch  8, Batch 335 -Loss:   199.0332 Validation Accuracy: 0.800781\n","Epoch  8, Batch 336 -Loss:   316.3775 Validation Accuracy: 0.800781\n","Epoch  8, Batch 337 -Loss:   330.8152 Validation Accuracy: 0.800781\n","Epoch  8, Batch 338 -Loss:   278.5992 Validation Accuracy: 0.800781\n","Epoch  8, Batch 339 -Loss:   264.8281 Validation Accuracy: 0.796875\n","Epoch  8, Batch 340 -Loss:   225.1911 Validation Accuracy: 0.796875\n","Epoch  8, Batch 341 -Loss:   361.5141 Validation Accuracy: 0.796875\n","Epoch  8, Batch 342 -Loss:   136.7744 Validation Accuracy: 0.804688\n","Epoch  8, Batch 343 -Loss:   277.9712 Validation Accuracy: 0.796875\n","Epoch  8, Batch 344 -Loss:   264.9641 Validation Accuracy: 0.808594\n","Epoch  8, Batch 345 -Loss:   211.0417 Validation Accuracy: 0.800781\n","Epoch  8, Batch 346 -Loss:   246.0224 Validation Accuracy: 0.804688\n","Epoch  8, Batch 347 -Loss:   202.3783 Validation Accuracy: 0.804688\n","Epoch  8, Batch 348 -Loss:   324.2268 Validation Accuracy: 0.804688\n","Epoch  8, Batch 349 -Loss:   276.1743 Validation Accuracy: 0.804688\n","Epoch  8, Batch 350 -Loss:   388.0206 Validation Accuracy: 0.800781\n","Epoch  8, Batch 351 -Loss:   212.7423 Validation Accuracy: 0.804688\n","Epoch  8, Batch 352 -Loss:   316.9426 Validation Accuracy: 0.804688\n","Epoch  8, Batch 353 -Loss:   283.4708 Validation Accuracy: 0.804688\n","Epoch  8, Batch 354 -Loss:   226.9982 Validation Accuracy: 0.804688\n","Epoch  8, Batch 355 -Loss:   402.7829 Validation Accuracy: 0.804688\n","Epoch  8, Batch 356 -Loss:   298.8999 Validation Accuracy: 0.804688\n","Epoch  8, Batch 357 -Loss:   281.0032 Validation Accuracy: 0.804688\n","Epoch  8, Batch 358 -Loss:   281.6180 Validation Accuracy: 0.804688\n","Epoch  8, Batch 359 -Loss:   314.0305 Validation Accuracy: 0.800781\n","Epoch  8, Batch 360 -Loss:   261.8531 Validation Accuracy: 0.804688\n","Epoch  8, Batch 361 -Loss:   246.2470 Validation Accuracy: 0.804688\n","Epoch  8, Batch 362 -Loss:   265.2050 Validation Accuracy: 0.804688\n","Epoch  8, Batch 363 -Loss:   201.1341 Validation Accuracy: 0.804688\n","Epoch  8, Batch 364 -Loss:   260.3012 Validation Accuracy: 0.808594\n","Epoch  8, Batch 365 -Loss:   226.1352 Validation Accuracy: 0.804688\n","Epoch  8, Batch 366 -Loss:   322.0255 Validation Accuracy: 0.804688\n","Epoch  8, Batch 367 -Loss:   229.6282 Validation Accuracy: 0.796875\n","Epoch  8, Batch 368 -Loss:   310.3966 Validation Accuracy: 0.804688\n","Epoch  8, Batch 369 -Loss:   210.0244 Validation Accuracy: 0.804688\n","Epoch  8, Batch 370 -Loss:   219.9659 Validation Accuracy: 0.808594\n","Epoch  8, Batch 371 -Loss:   182.3942 Validation Accuracy: 0.804688\n","Epoch  8, Batch 372 -Loss:   159.7140 Validation Accuracy: 0.804688\n","Epoch  8, Batch 373 -Loss:   247.3278 Validation Accuracy: 0.804688\n","Epoch  8, Batch 374 -Loss:   318.9788 Validation Accuracy: 0.804688\n","Epoch  8, Batch 375 -Loss:   205.4524 Validation Accuracy: 0.804688\n","Epoch  8, Batch 376 -Loss:   326.0230 Validation Accuracy: 0.804688\n","Epoch  8, Batch 377 -Loss:   340.7731 Validation Accuracy: 0.808594\n","Epoch  8, Batch 378 -Loss:   257.4847 Validation Accuracy: 0.808594\n","Epoch  8, Batch 379 -Loss:   333.8846 Validation Accuracy: 0.804688\n","Epoch  8, Batch 380 -Loss:   150.0118 Validation Accuracy: 0.808594\n","Epoch  8, Batch 381 -Loss:   338.9523 Validation Accuracy: 0.808594\n","Epoch  8, Batch 382 -Loss:   263.8401 Validation Accuracy: 0.808594\n","Epoch  8, Batch 383 -Loss:   257.9102 Validation Accuracy: 0.808594\n","Epoch  8, Batch 384 -Loss:   152.2019 Validation Accuracy: 0.808594\n","Epoch  8, Batch 385 -Loss:   290.6753 Validation Accuracy: 0.808594\n","Epoch  8, Batch 386 -Loss:   369.6115 Validation Accuracy: 0.804688\n","Epoch  8, Batch 387 -Loss:   222.6247 Validation Accuracy: 0.800781\n","Epoch  8, Batch 388 -Loss:   346.7582 Validation Accuracy: 0.800781\n","Epoch  8, Batch 389 -Loss:   219.5514 Validation Accuracy: 0.800781\n","Epoch  8, Batch 390 -Loss:   282.5229 Validation Accuracy: 0.804688\n","Epoch  8, Batch 391 -Loss:   248.6333 Validation Accuracy: 0.804688\n","Epoch  8, Batch 392 -Loss:   231.9679 Validation Accuracy: 0.808594\n","Epoch  8, Batch 393 -Loss:   393.6780 Validation Accuracy: 0.812500\n","Epoch  8, Batch 394 -Loss:   332.1852 Validation Accuracy: 0.816406\n","Epoch  8, Batch 395 -Loss:   181.8575 Validation Accuracy: 0.820312\n","Epoch  8, Batch 396 -Loss:   177.1888 Validation Accuracy: 0.808594\n","Epoch  8, Batch 397 -Loss:   265.8978 Validation Accuracy: 0.804688\n","Epoch  8, Batch 398 -Loss:   367.0909 Validation Accuracy: 0.800781\n","Epoch  8, Batch 399 -Loss:   249.0364 Validation Accuracy: 0.800781\n","Epoch  8, Batch 400 -Loss:   270.1458 Validation Accuracy: 0.804688\n","Epoch  8, Batch 401 -Loss:   195.4590 Validation Accuracy: 0.804688\n","Epoch  8, Batch 402 -Loss:   361.6132 Validation Accuracy: 0.800781\n","Epoch  8, Batch 403 -Loss:   331.4165 Validation Accuracy: 0.804688\n","Epoch  8, Batch 404 -Loss:   271.5080 Validation Accuracy: 0.804688\n","Epoch  8, Batch 405 -Loss:   309.2398 Validation Accuracy: 0.804688\n","Epoch  8, Batch 406 -Loss:   238.5153 Validation Accuracy: 0.808594\n","Epoch  8, Batch 407 -Loss:   331.5648 Validation Accuracy: 0.808594\n","Epoch  8, Batch 408 -Loss:   374.5981 Validation Accuracy: 0.804688\n","Epoch  8, Batch 409 -Loss:   258.0146 Validation Accuracy: 0.800781\n","Epoch  8, Batch 410 -Loss:   182.6543 Validation Accuracy: 0.804688\n","Epoch  8, Batch 411 -Loss:   214.4570 Validation Accuracy: 0.804688\n","Epoch  8, Batch 412 -Loss:   254.7538 Validation Accuracy: 0.812500\n","Epoch  8, Batch 413 -Loss:   223.6859 Validation Accuracy: 0.804688\n","Epoch  8, Batch 414 -Loss:   289.4578 Validation Accuracy: 0.804688\n","Epoch  8, Batch 415 -Loss:   221.3897 Validation Accuracy: 0.808594\n","Epoch  8, Batch 416 -Loss:   208.7686 Validation Accuracy: 0.808594\n","Epoch  8, Batch 417 -Loss:   260.1329 Validation Accuracy: 0.808594\n","Epoch  8, Batch 418 -Loss:   253.6544 Validation Accuracy: 0.808594\n","Epoch  8, Batch 419 -Loss:   333.5645 Validation Accuracy: 0.808594\n","Epoch  8, Batch 420 -Loss:   182.1343 Validation Accuracy: 0.804688\n","Epoch  8, Batch 421 -Loss:   281.8490 Validation Accuracy: 0.804688\n","Epoch  8, Batch 422 -Loss:   324.1980 Validation Accuracy: 0.804688\n","Epoch  8, Batch 423 -Loss:   260.1730 Validation Accuracy: 0.808594\n","Epoch  8, Batch 424 -Loss:   298.9983 Validation Accuracy: 0.812500\n","Epoch  8, Batch 425 -Loss:   308.8412 Validation Accuracy: 0.812500\n","Epoch  8, Batch 426 -Loss:   260.0281 Validation Accuracy: 0.812500\n","Epoch  8, Batch 427 -Loss:   284.1699 Validation Accuracy: 0.808594\n","Epoch  8, Batch 428 -Loss:   400.3953 Validation Accuracy: 0.804688\n","Epoch  8, Batch 429 -Loss:   350.9467 Validation Accuracy: 0.804688\n","Epoch  9, Batch   1 -Loss:   287.3022 Validation Accuracy: 0.800781\n","Epoch  9, Batch   2 -Loss:   294.0806 Validation Accuracy: 0.808594\n","Epoch  9, Batch   3 -Loss:   342.1858 Validation Accuracy: 0.808594\n","Epoch  9, Batch   4 -Loss:   407.1336 Validation Accuracy: 0.804688\n","Epoch  9, Batch   5 -Loss:   285.0399 Validation Accuracy: 0.800781\n","Epoch  9, Batch   6 -Loss:   188.7332 Validation Accuracy: 0.800781\n","Epoch  9, Batch   7 -Loss:   255.7816 Validation Accuracy: 0.808594\n","Epoch  9, Batch   8 -Loss:   341.1366 Validation Accuracy: 0.808594\n","Epoch  9, Batch   9 -Loss:   251.9395 Validation Accuracy: 0.816406\n","Epoch  9, Batch  10 -Loss:   219.8537 Validation Accuracy: 0.816406\n","Epoch  9, Batch  11 -Loss:   125.2383 Validation Accuracy: 0.808594\n","Epoch  9, Batch  12 -Loss:   343.2485 Validation Accuracy: 0.808594\n","Epoch  9, Batch  13 -Loss:   305.4240 Validation Accuracy: 0.808594\n","Epoch  9, Batch  14 -Loss:   306.5800 Validation Accuracy: 0.812500\n","Epoch  9, Batch  15 -Loss:   255.8966 Validation Accuracy: 0.812500\n","Epoch  9, Batch  16 -Loss:   200.4181 Validation Accuracy: 0.812500\n","Epoch  9, Batch  17 -Loss:   410.5779 Validation Accuracy: 0.804688\n","Epoch  9, Batch  18 -Loss:   367.9567 Validation Accuracy: 0.804688\n","Epoch  9, Batch  19 -Loss:   221.7192 Validation Accuracy: 0.796875\n","Epoch  9, Batch  20 -Loss:   302.5314 Validation Accuracy: 0.792969\n","Epoch  9, Batch  21 -Loss:   320.9196 Validation Accuracy: 0.804688\n","Epoch  9, Batch  22 -Loss:   211.3126 Validation Accuracy: 0.800781\n","Epoch  9, Batch  23 -Loss:   163.5383 Validation Accuracy: 0.796875\n","Epoch  9, Batch  24 -Loss:   391.0132 Validation Accuracy: 0.796875\n","Epoch  9, Batch  25 -Loss:   263.0628 Validation Accuracy: 0.800781\n","Epoch  9, Batch  26 -Loss:   347.1917 Validation Accuracy: 0.796875\n","Epoch  9, Batch  27 -Loss:   295.1285 Validation Accuracy: 0.796875\n","Epoch  9, Batch  28 -Loss:   343.4883 Validation Accuracy: 0.796875\n","Epoch  9, Batch  29 -Loss:   329.0982 Validation Accuracy: 0.792969\n","Epoch  9, Batch  30 -Loss:   237.7631 Validation Accuracy: 0.796875\n","Epoch  9, Batch  31 -Loss:   244.6091 Validation Accuracy: 0.796875\n","Epoch  9, Batch  32 -Loss:   243.1950 Validation Accuracy: 0.804688\n","Epoch  9, Batch  33 -Loss:   235.4225 Validation Accuracy: 0.804688\n","Epoch  9, Batch  34 -Loss:   258.5758 Validation Accuracy: 0.804688\n","Epoch  9, Batch  35 -Loss:   259.6373 Validation Accuracy: 0.800781\n","Epoch  9, Batch  36 -Loss:   304.3226 Validation Accuracy: 0.796875\n","Epoch  9, Batch  37 -Loss:   237.0470 Validation Accuracy: 0.792969\n","Epoch  9, Batch  38 -Loss:   435.4728 Validation Accuracy: 0.792969\n","Epoch  9, Batch  39 -Loss:   311.4806 Validation Accuracy: 0.789062\n","Epoch  9, Batch  40 -Loss:   268.8823 Validation Accuracy: 0.792969\n","Epoch  9, Batch  41 -Loss:   261.1798 Validation Accuracy: 0.792969\n","Epoch  9, Batch  42 -Loss:   296.7862 Validation Accuracy: 0.789062\n","Epoch  9, Batch  43 -Loss:   113.4135 Validation Accuracy: 0.785156\n","Epoch  9, Batch  44 -Loss:   296.3910 Validation Accuracy: 0.785156\n","Epoch  9, Batch  45 -Loss:   264.8428 Validation Accuracy: 0.800781\n","Epoch  9, Batch  46 -Loss:   347.9381 Validation Accuracy: 0.804688\n","Epoch  9, Batch  47 -Loss:   303.2344 Validation Accuracy: 0.800781\n","Epoch  9, Batch  48 -Loss:   276.1082 Validation Accuracy: 0.796875\n","Epoch  9, Batch  49 -Loss:   262.5479 Validation Accuracy: 0.792969\n","Epoch  9, Batch  50 -Loss:   344.8851 Validation Accuracy: 0.796875\n","Epoch  9, Batch  51 -Loss:   230.6870 Validation Accuracy: 0.792969\n","Epoch  9, Batch  52 -Loss:   227.1235 Validation Accuracy: 0.800781\n","Epoch  9, Batch  53 -Loss:   180.2467 Validation Accuracy: 0.796875\n","Epoch  9, Batch  54 -Loss:   259.3362 Validation Accuracy: 0.792969\n","Epoch  9, Batch  55 -Loss:   253.0448 Validation Accuracy: 0.796875\n","Epoch  9, Batch  56 -Loss:   307.0498 Validation Accuracy: 0.789062\n","Epoch  9, Batch  57 -Loss:   267.1822 Validation Accuracy: 0.796875\n","Epoch  9, Batch  58 -Loss:   143.5721 Validation Accuracy: 0.792969\n","Epoch  9, Batch  59 -Loss:   174.2351 Validation Accuracy: 0.789062\n","Epoch  9, Batch  60 -Loss:   298.1827 Validation Accuracy: 0.792969\n","Epoch  9, Batch  61 -Loss:   301.4657 Validation Accuracy: 0.792969\n","Epoch  9, Batch  62 -Loss:   285.7744 Validation Accuracy: 0.792969\n","Epoch  9, Batch  63 -Loss:   347.1677 Validation Accuracy: 0.796875\n","Epoch  9, Batch  64 -Loss:   206.3725 Validation Accuracy: 0.800781\n","Epoch  9, Batch  65 -Loss:   230.0188 Validation Accuracy: 0.792969\n","Epoch  9, Batch  66 -Loss:   240.1089 Validation Accuracy: 0.796875\n","Epoch  9, Batch  67 -Loss:   152.8439 Validation Accuracy: 0.796875\n","Epoch  9, Batch  68 -Loss:   228.3050 Validation Accuracy: 0.796875\n","Epoch  9, Batch  69 -Loss:   254.7920 Validation Accuracy: 0.800781\n","Epoch  9, Batch  70 -Loss:   384.6544 Validation Accuracy: 0.796875\n","Epoch  9, Batch  71 -Loss:   155.4887 Validation Accuracy: 0.796875\n","Epoch  9, Batch  72 -Loss:   366.4113 Validation Accuracy: 0.808594\n","Epoch  9, Batch  73 -Loss:   264.5789 Validation Accuracy: 0.800781\n","Epoch  9, Batch  74 -Loss:   298.5171 Validation Accuracy: 0.796875\n","Epoch  9, Batch  75 -Loss:   264.1287 Validation Accuracy: 0.796875\n","Epoch  9, Batch  76 -Loss:   292.3304 Validation Accuracy: 0.800781\n","Epoch  9, Batch  77 -Loss:   283.2578 Validation Accuracy: 0.800781\n","Epoch  9, Batch  78 -Loss:   349.6207 Validation Accuracy: 0.800781\n","Epoch  9, Batch  79 -Loss:   285.7952 Validation Accuracy: 0.800781\n","Epoch  9, Batch  80 -Loss:   173.0885 Validation Accuracy: 0.800781\n","Epoch  9, Batch  81 -Loss:   210.3981 Validation Accuracy: 0.800781\n","Epoch  9, Batch  82 -Loss:   270.9578 Validation Accuracy: 0.800781\n","Epoch  9, Batch  83 -Loss:   268.7919 Validation Accuracy: 0.800781\n","Epoch  9, Batch  84 -Loss:   218.4758 Validation Accuracy: 0.796875\n","Epoch  9, Batch  85 -Loss:   217.0866 Validation Accuracy: 0.800781\n","Epoch  9, Batch  86 -Loss:   196.9149 Validation Accuracy: 0.800781\n","Epoch  9, Batch  87 -Loss:   311.3272 Validation Accuracy: 0.800781\n","Epoch  9, Batch  88 -Loss:   277.5436 Validation Accuracy: 0.804688\n","Epoch  9, Batch  89 -Loss:   377.7317 Validation Accuracy: 0.804688\n","Epoch  9, Batch  90 -Loss:   337.8026 Validation Accuracy: 0.800781\n","Epoch  9, Batch  91 -Loss:   157.1491 Validation Accuracy: 0.808594\n","Epoch  9, Batch  92 -Loss:   370.8196 Validation Accuracy: 0.804688\n","Epoch  9, Batch  93 -Loss:   426.2634 Validation Accuracy: 0.808594\n","Epoch  9, Batch  94 -Loss:   259.3436 Validation Accuracy: 0.808594\n","Epoch  9, Batch  95 -Loss:   263.0372 Validation Accuracy: 0.808594\n","Epoch  9, Batch  96 -Loss:   392.4653 Validation Accuracy: 0.804688\n","Epoch  9, Batch  97 -Loss:   274.5286 Validation Accuracy: 0.808594\n","Epoch  9, Batch  98 -Loss:   214.4545 Validation Accuracy: 0.812500\n","Epoch  9, Batch  99 -Loss:   229.8753 Validation Accuracy: 0.804688\n","Epoch  9, Batch 100 -Loss:   140.3233 Validation Accuracy: 0.812500\n","Epoch  9, Batch 101 -Loss:   148.5358 Validation Accuracy: 0.808594\n","Epoch  9, Batch 102 -Loss:   207.2050 Validation Accuracy: 0.812500\n","Epoch  9, Batch 103 -Loss:   100.8660 Validation Accuracy: 0.816406\n","Epoch  9, Batch 104 -Loss:   342.1506 Validation Accuracy: 0.816406\n","Epoch  9, Batch 105 -Loss:   234.9461 Validation Accuracy: 0.816406\n","Epoch  9, Batch 106 -Loss:   318.6162 Validation Accuracy: 0.816406\n","Epoch  9, Batch 107 -Loss:   256.6069 Validation Accuracy: 0.820312\n","Epoch  9, Batch 108 -Loss:   343.7747 Validation Accuracy: 0.820312\n","Epoch  9, Batch 109 -Loss:   237.1345 Validation Accuracy: 0.820312\n","Epoch  9, Batch 110 -Loss:   373.9329 Validation Accuracy: 0.820312\n","Epoch  9, Batch 111 -Loss:   247.1149 Validation Accuracy: 0.816406\n","Epoch  9, Batch 112 -Loss:   193.5029 Validation Accuracy: 0.816406\n","Epoch  9, Batch 113 -Loss:   213.2091 Validation Accuracy: 0.816406\n","Epoch  9, Batch 114 -Loss:    85.3266 Validation Accuracy: 0.820312\n","Epoch  9, Batch 115 -Loss:   226.6358 Validation Accuracy: 0.820312\n","Epoch  9, Batch 116 -Loss:   207.9162 Validation Accuracy: 0.816406\n","Epoch  9, Batch 117 -Loss:   333.4056 Validation Accuracy: 0.820312\n","Epoch  9, Batch 118 -Loss:   197.0526 Validation Accuracy: 0.820312\n","Epoch  9, Batch 119 -Loss:   232.7850 Validation Accuracy: 0.816406\n","Epoch  9, Batch 120 -Loss:   286.7480 Validation Accuracy: 0.816406\n","Epoch  9, Batch 121 -Loss:   256.2777 Validation Accuracy: 0.820312\n","Epoch  9, Batch 122 -Loss:   323.9120 Validation Accuracy: 0.820312\n","Epoch  9, Batch 123 -Loss:   162.6922 Validation Accuracy: 0.824219\n","Epoch  9, Batch 124 -Loss:   229.0802 Validation Accuracy: 0.816406\n","Epoch  9, Batch 125 -Loss:   306.7540 Validation Accuracy: 0.824219\n","Epoch  9, Batch 126 -Loss:   379.8630 Validation Accuracy: 0.820312\n","Epoch  9, Batch 127 -Loss:   260.9624 Validation Accuracy: 0.816406\n","Epoch  9, Batch 128 -Loss:   349.6697 Validation Accuracy: 0.820312\n","Epoch  9, Batch 129 -Loss:   285.5742 Validation Accuracy: 0.808594\n","Epoch  9, Batch 130 -Loss:   422.3733 Validation Accuracy: 0.808594\n","Epoch  9, Batch 131 -Loss:   315.6372 Validation Accuracy: 0.808594\n","Epoch  9, Batch 132 -Loss:   281.0407 Validation Accuracy: 0.816406\n","Epoch  9, Batch 133 -Loss:   199.2197 Validation Accuracy: 0.816406\n","Epoch  9, Batch 134 -Loss:   211.0489 Validation Accuracy: 0.816406\n","Epoch  9, Batch 135 -Loss:   245.0579 Validation Accuracy: 0.816406\n","Epoch  9, Batch 136 -Loss:   265.2823 Validation Accuracy: 0.820312\n","Epoch  9, Batch 137 -Loss:   108.6171 Validation Accuracy: 0.812500\n","Epoch  9, Batch 138 -Loss:   236.6054 Validation Accuracy: 0.804688\n","Epoch  9, Batch 139 -Loss:   262.4161 Validation Accuracy: 0.808594\n","Epoch  9, Batch 140 -Loss:   232.2887 Validation Accuracy: 0.808594\n","Epoch  9, Batch 141 -Loss:   285.9771 Validation Accuracy: 0.808594\n","Epoch  9, Batch 142 -Loss:   288.7185 Validation Accuracy: 0.804688\n","Epoch  9, Batch 143 -Loss:   361.1314 Validation Accuracy: 0.812500\n","Epoch  9, Batch 144 -Loss:   132.5005 Validation Accuracy: 0.812500\n","Epoch  9, Batch 145 -Loss:   395.0010 Validation Accuracy: 0.812500\n","Epoch  9, Batch 146 -Loss:   282.5826 Validation Accuracy: 0.804688\n","Epoch  9, Batch 147 -Loss:   123.0701 Validation Accuracy: 0.804688\n","Epoch  9, Batch 148 -Loss:   335.0033 Validation Accuracy: 0.804688\n","Epoch  9, Batch 149 -Loss:   299.5819 Validation Accuracy: 0.804688\n","Epoch  9, Batch 150 -Loss:   222.8680 Validation Accuracy: 0.800781\n","Epoch  9, Batch 151 -Loss:   275.3650 Validation Accuracy: 0.800781\n","Epoch  9, Batch 152 -Loss:   331.0203 Validation Accuracy: 0.804688\n","Epoch  9, Batch 153 -Loss:   163.9398 Validation Accuracy: 0.808594\n","Epoch  9, Batch 154 -Loss:   288.8149 Validation Accuracy: 0.800781\n","Epoch  9, Batch 155 -Loss:   319.1572 Validation Accuracy: 0.804688\n","Epoch  9, Batch 156 -Loss:   165.3015 Validation Accuracy: 0.808594\n","Epoch  9, Batch 157 -Loss:   321.7702 Validation Accuracy: 0.812500\n","Epoch  9, Batch 158 -Loss:   317.4697 Validation Accuracy: 0.816406\n","Epoch  9, Batch 159 -Loss:   205.1412 Validation Accuracy: 0.816406\n","Epoch  9, Batch 160 -Loss:   219.4123 Validation Accuracy: 0.816406\n","Epoch  9, Batch 161 -Loss:   161.9535 Validation Accuracy: 0.816406\n","Epoch  9, Batch 162 -Loss:   196.2180 Validation Accuracy: 0.816406\n","Epoch  9, Batch 163 -Loss:   239.4160 Validation Accuracy: 0.820312\n","Epoch  9, Batch 164 -Loss:   398.9450 Validation Accuracy: 0.820312\n","Epoch  9, Batch 165 -Loss:   212.5912 Validation Accuracy: 0.820312\n","Epoch  9, Batch 166 -Loss:   155.6507 Validation Accuracy: 0.820312\n","Epoch  9, Batch 167 -Loss:   277.5509 Validation Accuracy: 0.820312\n","Epoch  9, Batch 168 -Loss:   265.3000 Validation Accuracy: 0.816406\n","Epoch  9, Batch 169 -Loss:   274.8573 Validation Accuracy: 0.816406\n","Epoch  9, Batch 170 -Loss:   200.7159 Validation Accuracy: 0.824219\n","Epoch  9, Batch 171 -Loss:   288.2638 Validation Accuracy: 0.816406\n","Epoch  9, Batch 172 -Loss:   196.8015 Validation Accuracy: 0.816406\n","Epoch  9, Batch 173 -Loss:   190.7697 Validation Accuracy: 0.820312\n","Epoch  9, Batch 174 -Loss:   186.4809 Validation Accuracy: 0.816406\n","Epoch  9, Batch 175 -Loss:   327.2778 Validation Accuracy: 0.820312\n","Epoch  9, Batch 176 -Loss:   268.5135 Validation Accuracy: 0.824219\n","Epoch  9, Batch 177 -Loss:   265.5726 Validation Accuracy: 0.824219\n","Epoch  9, Batch 178 -Loss:   308.8238 Validation Accuracy: 0.812500\n","Epoch  9, Batch 179 -Loss:   136.5367 Validation Accuracy: 0.808594\n","Epoch  9, Batch 180 -Loss:   248.0069 Validation Accuracy: 0.808594\n","Epoch  9, Batch 181 -Loss:   228.9424 Validation Accuracy: 0.804688\n","Epoch  9, Batch 182 -Loss:   348.2436 Validation Accuracy: 0.808594\n","Epoch  9, Batch 183 -Loss:   234.0233 Validation Accuracy: 0.812500\n","Epoch  9, Batch 184 -Loss:   285.6329 Validation Accuracy: 0.804688\n","Epoch  9, Batch 185 -Loss:   337.2359 Validation Accuracy: 0.816406\n","Epoch  9, Batch 186 -Loss:   305.8100 Validation Accuracy: 0.816406\n","Epoch  9, Batch 187 -Loss:   199.9989 Validation Accuracy: 0.816406\n","Epoch  9, Batch 188 -Loss:   322.2173 Validation Accuracy: 0.816406\n","Epoch  9, Batch 189 -Loss:   288.5332 Validation Accuracy: 0.816406\n","Epoch  9, Batch 190 -Loss:   258.5485 Validation Accuracy: 0.816406\n","Epoch  9, Batch 191 -Loss:   295.7282 Validation Accuracy: 0.812500\n","Epoch  9, Batch 192 -Loss:   299.7168 Validation Accuracy: 0.816406\n","Epoch  9, Batch 193 -Loss:   211.4088 Validation Accuracy: 0.808594\n","Epoch  9, Batch 194 -Loss:   273.9922 Validation Accuracy: 0.812500\n","Epoch  9, Batch 195 -Loss:   229.2955 Validation Accuracy: 0.812500\n","Epoch  9, Batch 196 -Loss:   376.4102 Validation Accuracy: 0.812500\n","Epoch  9, Batch 197 -Loss:   204.4412 Validation Accuracy: 0.812500\n","Epoch  9, Batch 198 -Loss:   248.0670 Validation Accuracy: 0.812500\n","Epoch  9, Batch 199 -Loss:   260.8547 Validation Accuracy: 0.804688\n","Epoch  9, Batch 200 -Loss:   198.4820 Validation Accuracy: 0.812500\n","Epoch  9, Batch 201 -Loss:   190.3755 Validation Accuracy: 0.808594\n","Epoch  9, Batch 202 -Loss:   241.7177 Validation Accuracy: 0.816406\n","Epoch  9, Batch 203 -Loss:   289.0488 Validation Accuracy: 0.816406\n","Epoch  9, Batch 204 -Loss:   246.4835 Validation Accuracy: 0.812500\n","Epoch  9, Batch 205 -Loss:   270.0725 Validation Accuracy: 0.812500\n","Epoch  9, Batch 206 -Loss:   239.0893 Validation Accuracy: 0.808594\n","Epoch  9, Batch 207 -Loss:   219.8255 Validation Accuracy: 0.808594\n","Epoch  9, Batch 208 -Loss:   286.0436 Validation Accuracy: 0.804688\n","Epoch  9, Batch 209 -Loss:   257.2580 Validation Accuracy: 0.800781\n","Epoch  9, Batch 210 -Loss:   320.7885 Validation Accuracy: 0.800781\n","Epoch  9, Batch 211 -Loss:   254.9486 Validation Accuracy: 0.800781\n","Epoch  9, Batch 212 -Loss:   157.9689 Validation Accuracy: 0.800781\n","Epoch  9, Batch 213 -Loss:   336.7804 Validation Accuracy: 0.800781\n","Epoch  9, Batch 214 -Loss:   215.3240 Validation Accuracy: 0.808594\n","Epoch  9, Batch 215 -Loss:   267.6168 Validation Accuracy: 0.812500\n","Epoch  9, Batch 216 -Loss:   221.6158 Validation Accuracy: 0.808594\n","Epoch  9, Batch 217 -Loss:   157.8562 Validation Accuracy: 0.808594\n","Epoch  9, Batch 218 -Loss:   299.2371 Validation Accuracy: 0.808594\n","Epoch  9, Batch 219 -Loss:   225.7168 Validation Accuracy: 0.812500\n","Epoch  9, Batch 220 -Loss:   323.6851 Validation Accuracy: 0.812500\n","Epoch  9, Batch 221 -Loss:   217.8705 Validation Accuracy: 0.812500\n","Epoch  9, Batch 222 -Loss:   212.6007 Validation Accuracy: 0.812500\n","Epoch  9, Batch 223 -Loss:   270.9080 Validation Accuracy: 0.812500\n","Epoch  9, Batch 224 -Loss:   405.0263 Validation Accuracy: 0.812500\n","Epoch  9, Batch 225 -Loss:   181.8326 Validation Accuracy: 0.812500\n","Epoch  9, Batch 226 -Loss:   303.1221 Validation Accuracy: 0.812500\n","Epoch  9, Batch 227 -Loss:   365.8029 Validation Accuracy: 0.812500\n","Epoch  9, Batch 228 -Loss:   244.3781 Validation Accuracy: 0.812500\n","Epoch  9, Batch 229 -Loss:   159.4704 Validation Accuracy: 0.812500\n","Epoch  9, Batch 230 -Loss:   254.3680 Validation Accuracy: 0.816406\n","Epoch  9, Batch 231 -Loss:   271.0558 Validation Accuracy: 0.812500\n","Epoch  9, Batch 232 -Loss:   189.4558 Validation Accuracy: 0.812500\n","Epoch  9, Batch 233 -Loss:   186.1951 Validation Accuracy: 0.804688\n","Epoch  9, Batch 234 -Loss:   220.1218 Validation Accuracy: 0.808594\n","Epoch  9, Batch 235 -Loss:   212.9708 Validation Accuracy: 0.812500\n","Epoch  9, Batch 236 -Loss:   179.7306 Validation Accuracy: 0.804688\n","Epoch  9, Batch 237 -Loss:   276.5950 Validation Accuracy: 0.808594\n","Epoch  9, Batch 238 -Loss:   256.4509 Validation Accuracy: 0.808594\n","Epoch  9, Batch 239 -Loss:   218.9027 Validation Accuracy: 0.812500\n","Epoch  9, Batch 240 -Loss:   246.6357 Validation Accuracy: 0.808594\n","Epoch  9, Batch 241 -Loss:   217.1198 Validation Accuracy: 0.804688\n","Epoch  9, Batch 242 -Loss:   123.5121 Validation Accuracy: 0.804688\n","Epoch  9, Batch 243 -Loss:   201.1211 Validation Accuracy: 0.804688\n","Epoch  9, Batch 244 -Loss:   322.7745 Validation Accuracy: 0.808594\n","Epoch  9, Batch 245 -Loss:   279.1607 Validation Accuracy: 0.804688\n","Epoch  9, Batch 246 -Loss:   232.5442 Validation Accuracy: 0.808594\n","Epoch  9, Batch 247 -Loss:   225.1282 Validation Accuracy: 0.808594\n","Epoch  9, Batch 248 -Loss:   199.3373 Validation Accuracy: 0.804688\n","Epoch  9, Batch 249 -Loss:   272.3031 Validation Accuracy: 0.800781\n","Epoch  9, Batch 250 -Loss:   166.0363 Validation Accuracy: 0.804688\n","Epoch  9, Batch 251 -Loss:   216.2649 Validation Accuracy: 0.804688\n","Epoch  9, Batch 252 -Loss:   233.9368 Validation Accuracy: 0.812500\n","Epoch  9, Batch 253 -Loss:   275.9658 Validation Accuracy: 0.804688\n","Epoch  9, Batch 254 -Loss:   285.4467 Validation Accuracy: 0.812500\n","Epoch  9, Batch 255 -Loss:   312.6874 Validation Accuracy: 0.808594\n","Epoch  9, Batch 256 -Loss:   249.9964 Validation Accuracy: 0.804688\n","Epoch  9, Batch 257 -Loss:   265.3773 Validation Accuracy: 0.804688\n","Epoch  9, Batch 258 -Loss:   259.9261 Validation Accuracy: 0.804688\n","Epoch  9, Batch 259 -Loss:   258.2849 Validation Accuracy: 0.800781\n","Epoch  9, Batch 260 -Loss:   176.5955 Validation Accuracy: 0.800781\n","Epoch  9, Batch 261 -Loss:   246.4287 Validation Accuracy: 0.800781\n","Epoch  9, Batch 262 -Loss:   422.7003 Validation Accuracy: 0.800781\n","Epoch  9, Batch 263 -Loss:   336.3862 Validation Accuracy: 0.800781\n","Epoch  9, Batch 264 -Loss:   214.4089 Validation Accuracy: 0.796875\n","Epoch  9, Batch 265 -Loss:   240.6662 Validation Accuracy: 0.796875\n","Epoch  9, Batch 266 -Loss:   273.5687 Validation Accuracy: 0.800781\n","Epoch  9, Batch 267 -Loss:   173.7153 Validation Accuracy: 0.800781\n","Epoch  9, Batch 268 -Loss:   393.8553 Validation Accuracy: 0.796875\n","Epoch  9, Batch 269 -Loss:   142.2809 Validation Accuracy: 0.800781\n","Epoch  9, Batch 270 -Loss:   169.6824 Validation Accuracy: 0.800781\n","Epoch  9, Batch 271 -Loss:   318.7150 Validation Accuracy: 0.796875\n","Epoch  9, Batch 272 -Loss:   244.0752 Validation Accuracy: 0.796875\n","Epoch  9, Batch 273 -Loss:   255.8297 Validation Accuracy: 0.796875\n","Epoch  9, Batch 274 -Loss:   262.7702 Validation Accuracy: 0.796875\n","Epoch  9, Batch 275 -Loss:   204.3056 Validation Accuracy: 0.800781\n","Epoch  9, Batch 276 -Loss:   325.6278 Validation Accuracy: 0.804688\n","Epoch  9, Batch 277 -Loss:   230.1349 Validation Accuracy: 0.800781\n","Epoch  9, Batch 278 -Loss:   225.6795 Validation Accuracy: 0.804688\n","Epoch  9, Batch 279 -Loss:   356.5653 Validation Accuracy: 0.804688\n","Epoch  9, Batch 280 -Loss:   197.6711 Validation Accuracy: 0.804688\n","Epoch  9, Batch 281 -Loss:   246.8529 Validation Accuracy: 0.808594\n","Epoch  9, Batch 282 -Loss:   185.7668 Validation Accuracy: 0.812500\n","Epoch  9, Batch 283 -Loss:   293.8882 Validation Accuracy: 0.808594\n","Epoch  9, Batch 284 -Loss:   255.5766 Validation Accuracy: 0.812500\n","Epoch  9, Batch 285 -Loss:   312.4093 Validation Accuracy: 0.816406\n","Epoch  9, Batch 286 -Loss:   194.0258 Validation Accuracy: 0.816406\n","Epoch  9, Batch 287 -Loss:   127.2794 Validation Accuracy: 0.816406\n","Epoch  9, Batch 288 -Loss:   263.4592 Validation Accuracy: 0.816406\n","Epoch  9, Batch 289 -Loss:   243.4500 Validation Accuracy: 0.812500\n","Epoch  9, Batch 290 -Loss:   216.9094 Validation Accuracy: 0.816406\n","Epoch  9, Batch 291 -Loss:   236.7154 Validation Accuracy: 0.812500\n","Epoch  9, Batch 292 -Loss:   206.6051 Validation Accuracy: 0.812500\n","Epoch  9, Batch 293 -Loss:   248.6730 Validation Accuracy: 0.808594\n","Epoch  9, Batch 294 -Loss:   356.5530 Validation Accuracy: 0.812500\n","Epoch  9, Batch 295 -Loss:   244.8683 Validation Accuracy: 0.812500\n","Epoch  9, Batch 296 -Loss:   247.9079 Validation Accuracy: 0.808594\n","Epoch  9, Batch 297 -Loss:   273.7939 Validation Accuracy: 0.800781\n","Epoch  9, Batch 298 -Loss:   172.1124 Validation Accuracy: 0.800781\n","Epoch  9, Batch 299 -Loss:   273.9976 Validation Accuracy: 0.804688\n","Epoch  9, Batch 300 -Loss:   292.0181 Validation Accuracy: 0.792969\n","Epoch  9, Batch 301 -Loss:   176.1775 Validation Accuracy: 0.796875\n","Epoch  9, Batch 302 -Loss:   193.0480 Validation Accuracy: 0.800781\n","Epoch  9, Batch 303 -Loss:   321.7154 Validation Accuracy: 0.792969\n","Epoch  9, Batch 304 -Loss:   300.9357 Validation Accuracy: 0.792969\n","Epoch  9, Batch 305 -Loss:   264.4543 Validation Accuracy: 0.804688\n","Epoch  9, Batch 306 -Loss:   330.1823 Validation Accuracy: 0.789062\n","Epoch  9, Batch 307 -Loss:   154.6415 Validation Accuracy: 0.789062\n","Epoch  9, Batch 308 -Loss:   239.0297 Validation Accuracy: 0.792969\n","Epoch  9, Batch 309 -Loss:   294.8353 Validation Accuracy: 0.800781\n","Epoch  9, Batch 310 -Loss:   359.4900 Validation Accuracy: 0.796875\n","Epoch  9, Batch 311 -Loss:   271.5349 Validation Accuracy: 0.800781\n","Epoch  9, Batch 312 -Loss:   244.9773 Validation Accuracy: 0.804688\n","Epoch  9, Batch 313 -Loss:   246.2574 Validation Accuracy: 0.804688\n","Epoch  9, Batch 314 -Loss:   143.9872 Validation Accuracy: 0.804688\n","Epoch  9, Batch 315 -Loss:   286.2506 Validation Accuracy: 0.816406\n","Epoch  9, Batch 316 -Loss:   239.8726 Validation Accuracy: 0.816406\n","Epoch  9, Batch 317 -Loss:   158.6221 Validation Accuracy: 0.816406\n","Epoch  9, Batch 318 -Loss:   318.3451 Validation Accuracy: 0.816406\n","Epoch  9, Batch 319 -Loss:   272.1957 Validation Accuracy: 0.816406\n","Epoch  9, Batch 320 -Loss:   228.4624 Validation Accuracy: 0.816406\n","Epoch  9, Batch 321 -Loss:   152.0090 Validation Accuracy: 0.812500\n","Epoch  9, Batch 322 -Loss:   206.4955 Validation Accuracy: 0.812500\n","Epoch  9, Batch 323 -Loss:   269.1674 Validation Accuracy: 0.812500\n","Epoch  9, Batch 324 -Loss:   227.2365 Validation Accuracy: 0.812500\n","Epoch  9, Batch 325 -Loss:   232.9768 Validation Accuracy: 0.808594\n","Epoch  9, Batch 326 -Loss:   103.7411 Validation Accuracy: 0.812500\n","Epoch  9, Batch 327 -Loss:   284.2661 Validation Accuracy: 0.812500\n","Epoch  9, Batch 328 -Loss:   279.2616 Validation Accuracy: 0.808594\n","Epoch  9, Batch 329 -Loss:   281.6467 Validation Accuracy: 0.812500\n","Epoch  9, Batch 330 -Loss:   311.5870 Validation Accuracy: 0.816406\n","Epoch  9, Batch 331 -Loss:   359.2455 Validation Accuracy: 0.816406\n","Epoch  9, Batch 332 -Loss:   319.1400 Validation Accuracy: 0.816406\n","Epoch  9, Batch 333 -Loss:   360.7419 Validation Accuracy: 0.816406\n","Epoch  9, Batch 334 -Loss:   357.3723 Validation Accuracy: 0.816406\n","Epoch  9, Batch 335 -Loss:   287.6087 Validation Accuracy: 0.820312\n","Epoch  9, Batch 336 -Loss:   264.5015 Validation Accuracy: 0.816406\n","Epoch  9, Batch 337 -Loss:   128.1143 Validation Accuracy: 0.820312\n","Epoch  9, Batch 338 -Loss:   250.8607 Validation Accuracy: 0.816406\n","Epoch  9, Batch 339 -Loss:   186.4848 Validation Accuracy: 0.816406\n","Epoch  9, Batch 340 -Loss:   180.8383 Validation Accuracy: 0.816406\n","Epoch  9, Batch 341 -Loss:   205.8917 Validation Accuracy: 0.816406\n","Epoch  9, Batch 342 -Loss:   222.1205 Validation Accuracy: 0.820312\n","Epoch  9, Batch 343 -Loss:   238.6283 Validation Accuracy: 0.820312\n","Epoch  9, Batch 344 -Loss:   362.9921 Validation Accuracy: 0.816406\n","Epoch  9, Batch 345 -Loss:   233.1758 Validation Accuracy: 0.812500\n","Epoch  9, Batch 346 -Loss:   259.0319 Validation Accuracy: 0.812500\n","Epoch  9, Batch 347 -Loss:   258.4351 Validation Accuracy: 0.812500\n","Epoch  9, Batch 348 -Loss:   244.3002 Validation Accuracy: 0.812500\n","Epoch  9, Batch 349 -Loss:   282.7750 Validation Accuracy: 0.800781\n","Epoch  9, Batch 350 -Loss:   167.1440 Validation Accuracy: 0.800781\n","Epoch  9, Batch 351 -Loss:   275.3840 Validation Accuracy: 0.804688\n","Epoch  9, Batch 352 -Loss:   343.9079 Validation Accuracy: 0.804688\n","Epoch  9, Batch 353 -Loss:   166.4163 Validation Accuracy: 0.800781\n","Epoch  9, Batch 354 -Loss:   185.1874 Validation Accuracy: 0.800781\n","Epoch  9, Batch 355 -Loss:   219.2200 Validation Accuracy: 0.812500\n","Epoch  9, Batch 356 -Loss:   273.9125 Validation Accuracy: 0.812500\n","Epoch  9, Batch 357 -Loss:   248.7525 Validation Accuracy: 0.812500\n","Epoch  9, Batch 358 -Loss:   223.5029 Validation Accuracy: 0.812500\n","Epoch  9, Batch 359 -Loss:   174.8985 Validation Accuracy: 0.812500\n","Epoch  9, Batch 360 -Loss:   281.3746 Validation Accuracy: 0.808594\n","Epoch  9, Batch 361 -Loss:   172.7970 Validation Accuracy: 0.808594\n","Epoch  9, Batch 362 -Loss:   174.4435 Validation Accuracy: 0.808594\n","Epoch  9, Batch 363 -Loss:   253.2438 Validation Accuracy: 0.808594\n","Epoch  9, Batch 364 -Loss:   335.0055 Validation Accuracy: 0.808594\n","Epoch  9, Batch 365 -Loss:   285.5447 Validation Accuracy: 0.804688\n","Epoch  9, Batch 366 -Loss:   204.6913 Validation Accuracy: 0.808594\n","Epoch  9, Batch 367 -Loss:   161.5593 Validation Accuracy: 0.804688\n","Epoch  9, Batch 368 -Loss:   117.1522 Validation Accuracy: 0.808594\n","Epoch  9, Batch 369 -Loss:   219.1313 Validation Accuracy: 0.812500\n","Epoch  9, Batch 370 -Loss:   347.1333 Validation Accuracy: 0.812500\n","Epoch  9, Batch 371 -Loss:   176.7032 Validation Accuracy: 0.816406\n","Epoch  9, Batch 372 -Loss:   218.1383 Validation Accuracy: 0.812500\n","Epoch  9, Batch 373 -Loss:   304.2050 Validation Accuracy: 0.812500\n","Epoch  9, Batch 374 -Loss:   148.0423 Validation Accuracy: 0.812500\n","Epoch  9, Batch 375 -Loss:   164.9768 Validation Accuracy: 0.816406\n","Epoch  9, Batch 376 -Loss:   242.9782 Validation Accuracy: 0.816406\n","Epoch  9, Batch 377 -Loss:   315.3725 Validation Accuracy: 0.816406\n","Epoch  9, Batch 378 -Loss:   235.0761 Validation Accuracy: 0.812500\n","Epoch  9, Batch 379 -Loss:   137.3123 Validation Accuracy: 0.812500\n","Epoch  9, Batch 380 -Loss:   170.7535 Validation Accuracy: 0.816406\n","Epoch  9, Batch 381 -Loss:   132.6468 Validation Accuracy: 0.816406\n","Epoch  9, Batch 382 -Loss:   275.3988 Validation Accuracy: 0.816406\n","Epoch  9, Batch 383 -Loss:   252.9498 Validation Accuracy: 0.816406\n","Epoch  9, Batch 384 -Loss:   199.8477 Validation Accuracy: 0.816406\n","Epoch  9, Batch 385 -Loss:   263.7551 Validation Accuracy: 0.824219\n","Epoch  9, Batch 386 -Loss:   149.5441 Validation Accuracy: 0.824219\n","Epoch  9, Batch 387 -Loss:   176.5521 Validation Accuracy: 0.816406\n","Epoch  9, Batch 388 -Loss:   257.4464 Validation Accuracy: 0.812500\n","Epoch  9, Batch 389 -Loss:   154.5356 Validation Accuracy: 0.812500\n","Epoch  9, Batch 390 -Loss:   265.2819 Validation Accuracy: 0.812500\n","Epoch  9, Batch 391 -Loss:   197.1061 Validation Accuracy: 0.820312\n","Epoch  9, Batch 392 -Loss:   263.2332 Validation Accuracy: 0.820312\n","Epoch  9, Batch 393 -Loss:   185.7418 Validation Accuracy: 0.816406\n","Epoch  9, Batch 394 -Loss:   213.5817 Validation Accuracy: 0.816406\n","Epoch  9, Batch 395 -Loss:   145.9175 Validation Accuracy: 0.820312\n","Epoch  9, Batch 396 -Loss:   230.8877 Validation Accuracy: 0.816406\n","Epoch  9, Batch 397 -Loss:   213.2440 Validation Accuracy: 0.812500\n","Epoch  9, Batch 398 -Loss:   119.0496 Validation Accuracy: 0.812500\n","Epoch  9, Batch 399 -Loss:   238.6679 Validation Accuracy: 0.812500\n","Epoch  9, Batch 400 -Loss:   238.8398 Validation Accuracy: 0.808594\n","Epoch  9, Batch 401 -Loss:   150.8822 Validation Accuracy: 0.808594\n","Epoch  9, Batch 402 -Loss:   313.7115 Validation Accuracy: 0.812500\n","Epoch  9, Batch 403 -Loss:   281.3184 Validation Accuracy: 0.812500\n","Epoch  9, Batch 404 -Loss:   202.6091 Validation Accuracy: 0.808594\n","Epoch  9, Batch 405 -Loss:   310.7261 Validation Accuracy: 0.808594\n","Epoch  9, Batch 406 -Loss:   374.9258 Validation Accuracy: 0.812500\n","Epoch  9, Batch 407 -Loss:   290.6398 Validation Accuracy: 0.812500\n","Epoch  9, Batch 408 -Loss:   268.8379 Validation Accuracy: 0.812500\n","Epoch  9, Batch 409 -Loss:   314.4453 Validation Accuracy: 0.816406\n","Epoch  9, Batch 410 -Loss:   256.4987 Validation Accuracy: 0.816406\n","Epoch  9, Batch 411 -Loss:   336.8465 Validation Accuracy: 0.812500\n","Epoch  9, Batch 412 -Loss:   202.2746 Validation Accuracy: 0.812500\n","Epoch  9, Batch 413 -Loss:   319.1125 Validation Accuracy: 0.816406\n","Epoch  9, Batch 414 -Loss:   210.2042 Validation Accuracy: 0.820312\n","Epoch  9, Batch 415 -Loss:   283.1823 Validation Accuracy: 0.816406\n","Epoch  9, Batch 416 -Loss:   321.8337 Validation Accuracy: 0.804688\n","Epoch  9, Batch 417 -Loss:   309.9564 Validation Accuracy: 0.804688\n","Epoch  9, Batch 418 -Loss:   294.4443 Validation Accuracy: 0.808594\n","Epoch  9, Batch 419 -Loss:    91.9888 Validation Accuracy: 0.804688\n","Epoch  9, Batch 420 -Loss:   277.7557 Validation Accuracy: 0.808594\n","Epoch  9, Batch 421 -Loss:   167.1483 Validation Accuracy: 0.812500\n","Epoch  9, Batch 422 -Loss:   275.7845 Validation Accuracy: 0.816406\n","Epoch  9, Batch 423 -Loss:   221.3414 Validation Accuracy: 0.816406\n","Epoch  9, Batch 424 -Loss:   203.5025 Validation Accuracy: 0.816406\n","Epoch  9, Batch 425 -Loss:   369.1147 Validation Accuracy: 0.812500\n","Epoch  9, Batch 426 -Loss:   279.4378 Validation Accuracy: 0.812500\n","Epoch  9, Batch 427 -Loss:   165.5624 Validation Accuracy: 0.812500\n","Epoch  9, Batch 428 -Loss:   310.3093 Validation Accuracy: 0.812500\n","Epoch  9, Batch 429 -Loss:   331.8152 Validation Accuracy: 0.812500\n","Epoch 10, Batch   1 -Loss:   224.2917 Validation Accuracy: 0.808594\n","Epoch 10, Batch   2 -Loss:   210.0416 Validation Accuracy: 0.808594\n","Epoch 10, Batch   3 -Loss:   186.2718 Validation Accuracy: 0.812500\n","Epoch 10, Batch   4 -Loss:   232.8171 Validation Accuracy: 0.816406\n","Epoch 10, Batch   5 -Loss:   327.0984 Validation Accuracy: 0.804688\n","Epoch 10, Batch   6 -Loss:   292.1688 Validation Accuracy: 0.812500\n","Epoch 10, Batch   7 -Loss:   371.9839 Validation Accuracy: 0.808594\n","Epoch 10, Batch   8 -Loss:   300.6387 Validation Accuracy: 0.804688\n","Epoch 10, Batch   9 -Loss:   212.3453 Validation Accuracy: 0.812500\n","Epoch 10, Batch  10 -Loss:   277.7810 Validation Accuracy: 0.812500\n","Epoch 10, Batch  11 -Loss:   255.2995 Validation Accuracy: 0.812500\n","Epoch 10, Batch  12 -Loss:   472.9875 Validation Accuracy: 0.820312\n","Epoch 10, Batch  13 -Loss:   146.3757 Validation Accuracy: 0.812500\n","Epoch 10, Batch  14 -Loss:   332.0266 Validation Accuracy: 0.800781\n","Epoch 10, Batch  15 -Loss:   181.5515 Validation Accuracy: 0.804688\n","Epoch 10, Batch  16 -Loss:   180.1891 Validation Accuracy: 0.804688\n","Epoch 10, Batch  17 -Loss:   214.1958 Validation Accuracy: 0.800781\n","Epoch 10, Batch  18 -Loss:   137.3670 Validation Accuracy: 0.796875\n","Epoch 10, Batch  19 -Loss:   243.5650 Validation Accuracy: 0.796875\n","Epoch 10, Batch  20 -Loss:   156.5347 Validation Accuracy: 0.804688\n","Epoch 10, Batch  21 -Loss:   216.3347 Validation Accuracy: 0.800781\n","Epoch 10, Batch  22 -Loss:   365.1884 Validation Accuracy: 0.796875\n","Epoch 10, Batch  23 -Loss:   327.2609 Validation Accuracy: 0.796875\n","Epoch 10, Batch  24 -Loss:   324.4532 Validation Accuracy: 0.800781\n","Epoch 10, Batch  25 -Loss:   106.1558 Validation Accuracy: 0.808594\n","Epoch 10, Batch  26 -Loss:   293.0488 Validation Accuracy: 0.812500\n","Epoch 10, Batch  27 -Loss:   221.5260 Validation Accuracy: 0.820312\n","Epoch 10, Batch  28 -Loss:   150.3873 Validation Accuracy: 0.812500\n","Epoch 10, Batch  29 -Loss:   158.6206 Validation Accuracy: 0.812500\n","Epoch 10, Batch  30 -Loss:   195.9057 Validation Accuracy: 0.804688\n","Epoch 10, Batch  31 -Loss:   244.4427 Validation Accuracy: 0.808594\n","Epoch 10, Batch  32 -Loss:   297.8915 Validation Accuracy: 0.812500\n","Epoch 10, Batch  33 -Loss:   140.1848 Validation Accuracy: 0.816406\n","Epoch 10, Batch  34 -Loss:   216.5108 Validation Accuracy: 0.820312\n","Epoch 10, Batch  35 -Loss:   436.0234 Validation Accuracy: 0.820312\n","Epoch 10, Batch  36 -Loss:   118.2446 Validation Accuracy: 0.812500\n","Epoch 10, Batch  37 -Loss:   251.4626 Validation Accuracy: 0.820312\n","Epoch 10, Batch  38 -Loss:   260.4902 Validation Accuracy: 0.812500\n","Epoch 10, Batch  39 -Loss:   180.5034 Validation Accuracy: 0.812500\n","Epoch 10, Batch  40 -Loss:   186.8313 Validation Accuracy: 0.816406\n","Epoch 10, Batch  41 -Loss:   234.3582 Validation Accuracy: 0.816406\n","Epoch 10, Batch  42 -Loss:   260.6432 Validation Accuracy: 0.816406\n","Epoch 10, Batch  43 -Loss:   149.2640 Validation Accuracy: 0.816406\n","Epoch 10, Batch  44 -Loss:   269.7518 Validation Accuracy: 0.816406\n","Epoch 10, Batch  45 -Loss:   185.5318 Validation Accuracy: 0.820312\n","Epoch 10, Batch  46 -Loss:   292.8092 Validation Accuracy: 0.820312\n","Epoch 10, Batch  47 -Loss:   118.9529 Validation Accuracy: 0.820312\n","Epoch 10, Batch  48 -Loss:   230.7300 Validation Accuracy: 0.820312\n","Epoch 10, Batch  49 -Loss:   328.8601 Validation Accuracy: 0.816406\n","Epoch 10, Batch  50 -Loss:   324.6601 Validation Accuracy: 0.812500\n","Epoch 10, Batch  51 -Loss:   153.5148 Validation Accuracy: 0.812500\n","Epoch 10, Batch  52 -Loss:   221.0572 Validation Accuracy: 0.812500\n","Epoch 10, Batch  53 -Loss:   326.7778 Validation Accuracy: 0.812500\n","Epoch 10, Batch  54 -Loss:   148.5081 Validation Accuracy: 0.812500\n","Epoch 10, Batch  55 -Loss:   221.5930 Validation Accuracy: 0.812500\n","Epoch 10, Batch  56 -Loss:   304.7869 Validation Accuracy: 0.816406\n","Epoch 10, Batch  57 -Loss:   167.5474 Validation Accuracy: 0.816406\n","Epoch 10, Batch  58 -Loss:   243.4403 Validation Accuracy: 0.816406\n","Epoch 10, Batch  59 -Loss:   172.7837 Validation Accuracy: 0.816406\n","Epoch 10, Batch  60 -Loss:   182.3762 Validation Accuracy: 0.812500\n","Epoch 10, Batch  61 -Loss:   284.4119 Validation Accuracy: 0.812500\n","Epoch 10, Batch  62 -Loss:   251.1046 Validation Accuracy: 0.816406\n","Epoch 10, Batch  63 -Loss:   191.5519 Validation Accuracy: 0.812500\n","Epoch 10, Batch  64 -Loss:   318.1836 Validation Accuracy: 0.816406\n","Epoch 10, Batch  65 -Loss:   213.4109 Validation Accuracy: 0.812500\n","Epoch 10, Batch  66 -Loss:   238.1001 Validation Accuracy: 0.808594\n","Epoch 10, Batch  67 -Loss:   170.2466 Validation Accuracy: 0.824219\n","Epoch 10, Batch  68 -Loss:   238.5668 Validation Accuracy: 0.816406\n","Epoch 10, Batch  69 -Loss:   204.1325 Validation Accuracy: 0.812500\n","Epoch 10, Batch  70 -Loss:   167.7170 Validation Accuracy: 0.816406\n","Epoch 10, Batch  71 -Loss:   245.5385 Validation Accuracy: 0.820312\n","Epoch 10, Batch  72 -Loss:   227.9613 Validation Accuracy: 0.820312\n","Epoch 10, Batch  73 -Loss:   220.2449 Validation Accuracy: 0.812500\n","Epoch 10, Batch  74 -Loss:   239.2453 Validation Accuracy: 0.812500\n","Epoch 10, Batch  75 -Loss:   209.6836 Validation Accuracy: 0.820312\n","Epoch 10, Batch  76 -Loss:   320.3575 Validation Accuracy: 0.812500\n","Epoch 10, Batch  77 -Loss:   344.5896 Validation Accuracy: 0.816406\n","Epoch 10, Batch  78 -Loss:   143.4769 Validation Accuracy: 0.812500\n","Epoch 10, Batch  79 -Loss:   157.8655 Validation Accuracy: 0.820312\n","Epoch 10, Batch  80 -Loss:   191.7711 Validation Accuracy: 0.816406\n","Epoch 10, Batch  81 -Loss:   326.2703 Validation Accuracy: 0.816406\n","Epoch 10, Batch  82 -Loss:   232.3873 Validation Accuracy: 0.816406\n","Epoch 10, Batch  83 -Loss:   151.5341 Validation Accuracy: 0.816406\n","Epoch 10, Batch  84 -Loss:   318.4734 Validation Accuracy: 0.812500\n","Epoch 10, Batch  85 -Loss:   293.9126 Validation Accuracy: 0.812500\n","Epoch 10, Batch  86 -Loss:   200.6850 Validation Accuracy: 0.812500\n","Epoch 10, Batch  87 -Loss:   308.2755 Validation Accuracy: 0.816406\n","Epoch 10, Batch  88 -Loss:   287.5225 Validation Accuracy: 0.812500\n","Epoch 10, Batch  89 -Loss:   273.5844 Validation Accuracy: 0.808594\n","Epoch 10, Batch  90 -Loss:   271.5439 Validation Accuracy: 0.808594\n","Epoch 10, Batch  91 -Loss:   248.0801 Validation Accuracy: 0.812500\n","Epoch 10, Batch  92 -Loss:   267.4341 Validation Accuracy: 0.816406\n","Epoch 10, Batch  93 -Loss:   256.9176 Validation Accuracy: 0.808594\n","Epoch 10, Batch  94 -Loss:   176.9027 Validation Accuracy: 0.808594\n","Epoch 10, Batch  95 -Loss:   152.8683 Validation Accuracy: 0.816406\n","Epoch 10, Batch  96 -Loss:   271.2587 Validation Accuracy: 0.816406\n","Epoch 10, Batch  97 -Loss:   205.7185 Validation Accuracy: 0.816406\n","Epoch 10, Batch  98 -Loss:   236.1730 Validation Accuracy: 0.812500\n","Epoch 10, Batch  99 -Loss:   320.8773 Validation Accuracy: 0.816406\n","Epoch 10, Batch 100 -Loss:   239.0093 Validation Accuracy: 0.816406\n","Epoch 10, Batch 101 -Loss:   230.4069 Validation Accuracy: 0.816406\n","Epoch 10, Batch 102 -Loss:   264.6817 Validation Accuracy: 0.816406\n","Epoch 10, Batch 103 -Loss:   332.8264 Validation Accuracy: 0.816406\n","Epoch 10, Batch 104 -Loss:   204.0694 Validation Accuracy: 0.816406\n","Epoch 10, Batch 105 -Loss:   202.1517 Validation Accuracy: 0.816406\n","Epoch 10, Batch 106 -Loss:   253.2104 Validation Accuracy: 0.816406\n","Epoch 10, Batch 107 -Loss:   212.4017 Validation Accuracy: 0.816406\n","Epoch 10, Batch 108 -Loss:   192.7457 Validation Accuracy: 0.816406\n","Epoch 10, Batch 109 -Loss:   209.3569 Validation Accuracy: 0.816406\n","Epoch 10, Batch 110 -Loss:   249.1269 Validation Accuracy: 0.816406\n","Epoch 10, Batch 111 -Loss:   229.0794 Validation Accuracy: 0.812500\n","Epoch 10, Batch 112 -Loss:   269.9913 Validation Accuracy: 0.812500\n","Epoch 10, Batch 113 -Loss:   213.8361 Validation Accuracy: 0.820312\n","Epoch 10, Batch 114 -Loss:   382.9825 Validation Accuracy: 0.820312\n","Epoch 10, Batch 115 -Loss:   236.3798 Validation Accuracy: 0.820312\n","Epoch 10, Batch 116 -Loss:   262.0431 Validation Accuracy: 0.820312\n","Epoch 10, Batch 117 -Loss:   150.1838 Validation Accuracy: 0.816406\n","Epoch 10, Batch 118 -Loss:   143.6542 Validation Accuracy: 0.820312\n","Epoch 10, Batch 119 -Loss:   306.2513 Validation Accuracy: 0.820312\n","Epoch 10, Batch 120 -Loss:   327.7695 Validation Accuracy: 0.816406\n","Epoch 10, Batch 121 -Loss:    84.6346 Validation Accuracy: 0.820312\n","Epoch 10, Batch 122 -Loss:   152.5928 Validation Accuracy: 0.812500\n","Epoch 10, Batch 123 -Loss:   222.4493 Validation Accuracy: 0.812500\n","Epoch 10, Batch 124 -Loss:   267.7782 Validation Accuracy: 0.812500\n","Epoch 10, Batch 125 -Loss:   257.9775 Validation Accuracy: 0.816406\n","Epoch 10, Batch 126 -Loss:   294.9797 Validation Accuracy: 0.820312\n","Epoch 10, Batch 127 -Loss:   212.8488 Validation Accuracy: 0.820312\n","Epoch 10, Batch 128 -Loss:   259.3423 Validation Accuracy: 0.820312\n","Epoch 10, Batch 129 -Loss:   200.9480 Validation Accuracy: 0.820312\n","Epoch 10, Batch 130 -Loss:   201.1151 Validation Accuracy: 0.816406\n","Epoch 10, Batch 131 -Loss:   198.6365 Validation Accuracy: 0.820312\n","Epoch 10, Batch 132 -Loss:   185.1522 Validation Accuracy: 0.820312\n","Epoch 10, Batch 133 -Loss:   186.9474 Validation Accuracy: 0.820312\n","Epoch 10, Batch 134 -Loss:   175.7833 Validation Accuracy: 0.812500\n","Epoch 10, Batch 135 -Loss:   277.0739 Validation Accuracy: 0.816406\n","Epoch 10, Batch 136 -Loss:   195.4055 Validation Accuracy: 0.812500\n","Epoch 10, Batch 137 -Loss:   302.7366 Validation Accuracy: 0.812500\n","Epoch 10, Batch 138 -Loss:   183.6420 Validation Accuracy: 0.816406\n","Epoch 10, Batch 139 -Loss:   258.2157 Validation Accuracy: 0.820312\n","Epoch 10, Batch 140 -Loss:   319.8628 Validation Accuracy: 0.820312\n","Epoch 10, Batch 141 -Loss:   262.7085 Validation Accuracy: 0.816406\n","Epoch 10, Batch 142 -Loss:   348.3691 Validation Accuracy: 0.820312\n","Epoch 10, Batch 143 -Loss:   234.2422 Validation Accuracy: 0.816406\n","Epoch 10, Batch 144 -Loss:   172.4312 Validation Accuracy: 0.812500\n","Epoch 10, Batch 145 -Loss:   215.0111 Validation Accuracy: 0.816406\n","Epoch 10, Batch 146 -Loss:   225.2437 Validation Accuracy: 0.808594\n","Epoch 10, Batch 147 -Loss:   228.1032 Validation Accuracy: 0.812500\n","Epoch 10, Batch 148 -Loss:   151.5547 Validation Accuracy: 0.808594\n","Epoch 10, Batch 149 -Loss:   244.3567 Validation Accuracy: 0.808594\n","Epoch 10, Batch 150 -Loss:   203.3616 Validation Accuracy: 0.808594\n","Epoch 10, Batch 151 -Loss:   270.9788 Validation Accuracy: 0.808594\n","Epoch 10, Batch 152 -Loss:   167.3407 Validation Accuracy: 0.804688\n","Epoch 10, Batch 153 -Loss:   225.6678 Validation Accuracy: 0.800781\n","Epoch 10, Batch 154 -Loss:   182.4460 Validation Accuracy: 0.804688\n","Epoch 10, Batch 155 -Loss:   188.4450 Validation Accuracy: 0.812500\n","Epoch 10, Batch 156 -Loss:   382.7171 Validation Accuracy: 0.812500\n","Epoch 10, Batch 157 -Loss:   180.8423 Validation Accuracy: 0.812500\n","Epoch 10, Batch 158 -Loss:   164.3793 Validation Accuracy: 0.812500\n","Epoch 10, Batch 159 -Loss:   242.5080 Validation Accuracy: 0.812500\n","Epoch 10, Batch 160 -Loss:   304.1525 Validation Accuracy: 0.812500\n","Epoch 10, Batch 161 -Loss:   193.0060 Validation Accuracy: 0.812500\n","Epoch 10, Batch 162 -Loss:   286.8989 Validation Accuracy: 0.812500\n","Epoch 10, Batch 163 -Loss:   123.6840 Validation Accuracy: 0.816406\n","Epoch 10, Batch 164 -Loss:   368.9453 Validation Accuracy: 0.816406\n","Epoch 10, Batch 165 -Loss:   287.6208 Validation Accuracy: 0.816406\n","Epoch 10, Batch 166 -Loss:   231.6295 Validation Accuracy: 0.816406\n","Epoch 10, Batch 167 -Loss:   299.4766 Validation Accuracy: 0.816406\n","Epoch 10, Batch 168 -Loss:   247.2960 Validation Accuracy: 0.816406\n","Epoch 10, Batch 169 -Loss:   186.3591 Validation Accuracy: 0.812500\n","Epoch 10, Batch 170 -Loss:   276.6480 Validation Accuracy: 0.812500\n","Epoch 10, Batch 171 -Loss:    95.0444 Validation Accuracy: 0.812500\n","Epoch 10, Batch 172 -Loss:   295.1709 Validation Accuracy: 0.812500\n","Epoch 10, Batch 173 -Loss:   323.9809 Validation Accuracy: 0.812500\n","Epoch 10, Batch 174 -Loss:   180.9785 Validation Accuracy: 0.812500\n","Epoch 10, Batch 175 -Loss:   148.0148 Validation Accuracy: 0.816406\n","Epoch 10, Batch 176 -Loss:   203.2154 Validation Accuracy: 0.816406\n","Epoch 10, Batch 177 -Loss:   242.9408 Validation Accuracy: 0.812500\n","Epoch 10, Batch 178 -Loss:   133.5287 Validation Accuracy: 0.816406\n","Epoch 10, Batch 179 -Loss:   293.6956 Validation Accuracy: 0.816406\n","Epoch 10, Batch 180 -Loss:   196.3580 Validation Accuracy: 0.820312\n","Epoch 10, Batch 181 -Loss:   311.9571 Validation Accuracy: 0.816406\n","Epoch 10, Batch 182 -Loss:   213.8345 Validation Accuracy: 0.820312\n","Epoch 10, Batch 183 -Loss:   272.6954 Validation Accuracy: 0.820312\n","Epoch 10, Batch 184 -Loss:   247.2657 Validation Accuracy: 0.812500\n","Epoch 10, Batch 185 -Loss:   233.5112 Validation Accuracy: 0.812500\n","Epoch 10, Batch 186 -Loss:   319.2507 Validation Accuracy: 0.812500\n","Epoch 10, Batch 187 -Loss:   162.7715 Validation Accuracy: 0.812500\n","Epoch 10, Batch 188 -Loss:   219.2999 Validation Accuracy: 0.812500\n","Epoch 10, Batch 189 -Loss:   312.0783 Validation Accuracy: 0.808594\n","Epoch 10, Batch 190 -Loss:   284.3298 Validation Accuracy: 0.808594\n","Epoch 10, Batch 191 -Loss:   162.5110 Validation Accuracy: 0.808594\n","Epoch 10, Batch 192 -Loss:   200.9335 Validation Accuracy: 0.812500\n","Epoch 10, Batch 193 -Loss:   236.1679 Validation Accuracy: 0.808594\n","Epoch 10, Batch 194 -Loss:   326.0493 Validation Accuracy: 0.808594\n","Epoch 10, Batch 195 -Loss:   137.9197 Validation Accuracy: 0.812500\n","Epoch 10, Batch 196 -Loss:   162.3850 Validation Accuracy: 0.816406\n","Epoch 10, Batch 197 -Loss:   231.0999 Validation Accuracy: 0.816406\n","Epoch 10, Batch 198 -Loss:   177.2446 Validation Accuracy: 0.816406\n","Epoch 10, Batch 199 -Loss:   326.4804 Validation Accuracy: 0.816406\n","Epoch 10, Batch 200 -Loss:   264.2185 Validation Accuracy: 0.812500\n","Epoch 10, Batch 201 -Loss:   254.8140 Validation Accuracy: 0.808594\n","Epoch 10, Batch 202 -Loss:   272.5819 Validation Accuracy: 0.812500\n","Epoch 10, Batch 203 -Loss:   189.0519 Validation Accuracy: 0.812500\n","Epoch 10, Batch 204 -Loss:   217.1897 Validation Accuracy: 0.808594\n","Epoch 10, Batch 205 -Loss:   243.8032 Validation Accuracy: 0.808594\n","Epoch 10, Batch 206 -Loss:   157.4195 Validation Accuracy: 0.808594\n","Epoch 10, Batch 207 -Loss:   259.9459 Validation Accuracy: 0.812500\n","Epoch 10, Batch 208 -Loss:   304.3799 Validation Accuracy: 0.812500\n","Epoch 10, Batch 209 -Loss:   262.0655 Validation Accuracy: 0.812500\n","Epoch 10, Batch 210 -Loss:   254.3001 Validation Accuracy: 0.808594\n","Epoch 10, Batch 211 -Loss:   207.7242 Validation Accuracy: 0.812500\n","Epoch 10, Batch 212 -Loss:   313.0676 Validation Accuracy: 0.808594\n","Epoch 10, Batch 213 -Loss:   344.2049 Validation Accuracy: 0.808594\n","Epoch 10, Batch 214 -Loss:   222.6366 Validation Accuracy: 0.812500\n","Epoch 10, Batch 215 -Loss:   265.4711 Validation Accuracy: 0.804688\n","Epoch 10, Batch 216 -Loss:   205.4662 Validation Accuracy: 0.812500\n","Epoch 10, Batch 217 -Loss:   210.4593 Validation Accuracy: 0.816406\n","Epoch 10, Batch 218 -Loss:   196.0353 Validation Accuracy: 0.812500\n","Epoch 10, Batch 219 -Loss:   225.2834 Validation Accuracy: 0.808594\n","Epoch 10, Batch 220 -Loss:   215.5072 Validation Accuracy: 0.812500\n","Epoch 10, Batch 221 -Loss:   160.9150 Validation Accuracy: 0.808594\n","Epoch 10, Batch 222 -Loss:   319.7757 Validation Accuracy: 0.808594\n","Epoch 10, Batch 223 -Loss:   215.4862 Validation Accuracy: 0.808594\n","Epoch 10, Batch 224 -Loss:   136.7892 Validation Accuracy: 0.808594\n","Epoch 10, Batch 225 -Loss:   316.6166 Validation Accuracy: 0.816406\n","Epoch 10, Batch 226 -Loss:   254.6134 Validation Accuracy: 0.812500\n","Epoch 10, Batch 227 -Loss:   259.3740 Validation Accuracy: 0.812500\n","Epoch 10, Batch 228 -Loss:   268.7879 Validation Accuracy: 0.816406\n","Epoch 10, Batch 229 -Loss:   273.0269 Validation Accuracy: 0.808594\n","Epoch 10, Batch 230 -Loss:   216.6732 Validation Accuracy: 0.808594\n","Epoch 10, Batch 231 -Loss:   285.6902 Validation Accuracy: 0.808594\n","Epoch 10, Batch 232 -Loss:   190.8750 Validation Accuracy: 0.816406\n","Epoch 10, Batch 233 -Loss:   272.2231 Validation Accuracy: 0.812500\n","Epoch 10, Batch 234 -Loss:   298.0425 Validation Accuracy: 0.812500\n","Epoch 10, Batch 235 -Loss:   216.0151 Validation Accuracy: 0.808594\n","Epoch 10, Batch 236 -Loss:   301.3698 Validation Accuracy: 0.808594\n","Epoch 10, Batch 237 -Loss:   203.3000 Validation Accuracy: 0.808594\n","Epoch 10, Batch 238 -Loss:   218.5218 Validation Accuracy: 0.812500\n","Epoch 10, Batch 239 -Loss:   219.2490 Validation Accuracy: 0.812500\n","Epoch 10, Batch 240 -Loss:   340.5356 Validation Accuracy: 0.808594\n","Epoch 10, Batch 241 -Loss:   294.5986 Validation Accuracy: 0.804688\n","Epoch 10, Batch 242 -Loss:   204.6429 Validation Accuracy: 0.804688\n","Epoch 10, Batch 243 -Loss:   296.4509 Validation Accuracy: 0.804688\n","Epoch 10, Batch 244 -Loss:   326.3898 Validation Accuracy: 0.804688\n","Epoch 10, Batch 245 -Loss:   115.9569 Validation Accuracy: 0.804688\n","Epoch 10, Batch 246 -Loss:   111.3787 Validation Accuracy: 0.804688\n","Epoch 10, Batch 247 -Loss:   310.1591 Validation Accuracy: 0.808594\n","Epoch 10, Batch 248 -Loss:   247.2818 Validation Accuracy: 0.804688\n","Epoch 10, Batch 249 -Loss:   308.3017 Validation Accuracy: 0.804688\n","Epoch 10, Batch 250 -Loss:   254.4170 Validation Accuracy: 0.804688\n","Epoch 10, Batch 251 -Loss:   195.3386 Validation Accuracy: 0.800781\n","Epoch 10, Batch 252 -Loss:   213.1522 Validation Accuracy: 0.804688\n","Epoch 10, Batch 253 -Loss:   157.8086 Validation Accuracy: 0.808594\n","Epoch 10, Batch 254 -Loss:   278.0154 Validation Accuracy: 0.812500\n","Epoch 10, Batch 255 -Loss:   124.8281 Validation Accuracy: 0.812500\n","Epoch 10, Batch 256 -Loss:   241.4186 Validation Accuracy: 0.812500\n","Epoch 10, Batch 257 -Loss:   281.7164 Validation Accuracy: 0.816406\n","Epoch 10, Batch 258 -Loss:   216.5867 Validation Accuracy: 0.812500\n","Epoch 10, Batch 259 -Loss:   274.8441 Validation Accuracy: 0.816406\n","Epoch 10, Batch 260 -Loss:   295.6198 Validation Accuracy: 0.816406\n","Epoch 10, Batch 261 -Loss:   191.6557 Validation Accuracy: 0.816406\n","Epoch 10, Batch 262 -Loss:   246.3923 Validation Accuracy: 0.812500\n","Epoch 10, Batch 263 -Loss:   196.5017 Validation Accuracy: 0.820312\n","Epoch 10, Batch 264 -Loss:   290.8529 Validation Accuracy: 0.816406\n","Epoch 10, Batch 265 -Loss:   224.9639 Validation Accuracy: 0.816406\n","Epoch 10, Batch 266 -Loss:   364.6631 Validation Accuracy: 0.812500\n","Epoch 10, Batch 267 -Loss:   201.6469 Validation Accuracy: 0.812500\n","Epoch 10, Batch 268 -Loss:   207.5590 Validation Accuracy: 0.812500\n","Epoch 10, Batch 269 -Loss:   257.1223 Validation Accuracy: 0.808594\n","Epoch 10, Batch 270 -Loss:   191.3849 Validation Accuracy: 0.812500\n","Epoch 10, Batch 271 -Loss:   207.7719 Validation Accuracy: 0.812500\n","Epoch 10, Batch 272 -Loss:   160.2054 Validation Accuracy: 0.812500\n","Epoch 10, Batch 273 -Loss:   189.3240 Validation Accuracy: 0.808594\n","Epoch 10, Batch 274 -Loss:   204.0133 Validation Accuracy: 0.812500\n","Epoch 10, Batch 275 -Loss:   187.3199 Validation Accuracy: 0.812500\n","Epoch 10, Batch 276 -Loss:   150.6845 Validation Accuracy: 0.812500\n","Epoch 10, Batch 277 -Loss:   135.2054 Validation Accuracy: 0.812500\n","Epoch 10, Batch 278 -Loss:   321.2278 Validation Accuracy: 0.808594\n","Epoch 10, Batch 279 -Loss:   422.4458 Validation Accuracy: 0.812500\n","Epoch 10, Batch 280 -Loss:   138.0548 Validation Accuracy: 0.812500\n","Epoch 10, Batch 281 -Loss:    93.6419 Validation Accuracy: 0.812500\n","Epoch 10, Batch 282 -Loss:   263.8535 Validation Accuracy: 0.812500\n","Epoch 10, Batch 283 -Loss:   229.8027 Validation Accuracy: 0.812500\n","Epoch 10, Batch 284 -Loss:   232.4663 Validation Accuracy: 0.812500\n","Epoch 10, Batch 285 -Loss:   295.1735 Validation Accuracy: 0.812500\n","Epoch 10, Batch 286 -Loss:   346.6459 Validation Accuracy: 0.808594\n","Epoch 10, Batch 287 -Loss:   303.2018 Validation Accuracy: 0.812500\n","Epoch 10, Batch 288 -Loss:   289.3162 Validation Accuracy: 0.808594\n","Epoch 10, Batch 289 -Loss:   327.4958 Validation Accuracy: 0.808594\n","Epoch 10, Batch 290 -Loss:   141.3625 Validation Accuracy: 0.804688\n","Epoch 10, Batch 291 -Loss:   289.2092 Validation Accuracy: 0.812500\n","Epoch 10, Batch 292 -Loss:   155.7111 Validation Accuracy: 0.808594\n","Epoch 10, Batch 293 -Loss:   286.9607 Validation Accuracy: 0.808594\n","Epoch 10, Batch 294 -Loss:   258.8724 Validation Accuracy: 0.812500\n","Epoch 10, Batch 295 -Loss:   224.2622 Validation Accuracy: 0.812500\n","Epoch 10, Batch 296 -Loss:   193.6928 Validation Accuracy: 0.812500\n","Epoch 10, Batch 297 -Loss:   244.5815 Validation Accuracy: 0.812500\n","Epoch 10, Batch 298 -Loss:   209.5241 Validation Accuracy: 0.812500\n","Epoch 10, Batch 299 -Loss:   289.8619 Validation Accuracy: 0.812500\n","Epoch 10, Batch 300 -Loss:   125.5991 Validation Accuracy: 0.812500\n","Epoch 10, Batch 301 -Loss:   271.1967 Validation Accuracy: 0.812500\n","Epoch 10, Batch 302 -Loss:   316.6044 Validation Accuracy: 0.808594\n","Epoch 10, Batch 303 -Loss:   153.2307 Validation Accuracy: 0.808594\n","Epoch 10, Batch 304 -Loss:   208.3827 Validation Accuracy: 0.812500\n","Epoch 10, Batch 305 -Loss:   191.8281 Validation Accuracy: 0.812500\n","Epoch 10, Batch 306 -Loss:   217.4711 Validation Accuracy: 0.812500\n","Epoch 10, Batch 307 -Loss:   137.5589 Validation Accuracy: 0.812500\n","Epoch 10, Batch 308 -Loss:   263.1536 Validation Accuracy: 0.804688\n","Epoch 10, Batch 309 -Loss:   189.1070 Validation Accuracy: 0.808594\n","Epoch 10, Batch 310 -Loss:   238.5446 Validation Accuracy: 0.812500\n","Epoch 10, Batch 311 -Loss:   186.1777 Validation Accuracy: 0.812500\n","Epoch 10, Batch 312 -Loss:   212.8812 Validation Accuracy: 0.816406\n","Epoch 10, Batch 313 -Loss:   230.5135 Validation Accuracy: 0.816406\n","Epoch 10, Batch 314 -Loss:   172.1477 Validation Accuracy: 0.812500\n","Epoch 10, Batch 315 -Loss:   191.8918 Validation Accuracy: 0.808594\n","Epoch 10, Batch 316 -Loss:   280.2251 Validation Accuracy: 0.808594\n","Epoch 10, Batch 317 -Loss:   297.7747 Validation Accuracy: 0.808594\n","Epoch 10, Batch 318 -Loss:   176.5512 Validation Accuracy: 0.808594\n","Epoch 10, Batch 319 -Loss:   138.2571 Validation Accuracy: 0.812500\n","Epoch 10, Batch 320 -Loss:   163.4294 Validation Accuracy: 0.808594\n","Epoch 10, Batch 321 -Loss:   366.9480 Validation Accuracy: 0.812500\n","Epoch 10, Batch 322 -Loss:   237.4655 Validation Accuracy: 0.812500\n","Epoch 10, Batch 323 -Loss:   166.0415 Validation Accuracy: 0.816406\n","Epoch 10, Batch 324 -Loss:   257.5469 Validation Accuracy: 0.816406\n","Epoch 10, Batch 325 -Loss:   115.0076 Validation Accuracy: 0.812500\n","Epoch 10, Batch 326 -Loss:   179.4087 Validation Accuracy: 0.812500\n","Epoch 10, Batch 327 -Loss:   202.0577 Validation Accuracy: 0.816406\n","Epoch 10, Batch 328 -Loss:   172.0553 Validation Accuracy: 0.812500\n","Epoch 10, Batch 329 -Loss:   131.9985 Validation Accuracy: 0.812500\n","Epoch 10, Batch 330 -Loss:   244.9050 Validation Accuracy: 0.816406\n","Epoch 10, Batch 331 -Loss:   185.5196 Validation Accuracy: 0.816406\n","Epoch 10, Batch 332 -Loss:   213.8009 Validation Accuracy: 0.816406\n","Epoch 10, Batch 333 -Loss:   103.3386 Validation Accuracy: 0.816406\n","Epoch 10, Batch 334 -Loss:   170.2592 Validation Accuracy: 0.816406\n","Epoch 10, Batch 335 -Loss:   171.8576 Validation Accuracy: 0.816406\n","Epoch 10, Batch 336 -Loss:   272.9949 Validation Accuracy: 0.816406\n","Epoch 10, Batch 337 -Loss:   263.5323 Validation Accuracy: 0.816406\n","Epoch 10, Batch 338 -Loss:   321.6862 Validation Accuracy: 0.816406\n","Epoch 10, Batch 339 -Loss:   180.1088 Validation Accuracy: 0.816406\n","Epoch 10, Batch 340 -Loss:   225.8692 Validation Accuracy: 0.820312\n","Epoch 10, Batch 341 -Loss:   230.7720 Validation Accuracy: 0.820312\n","Epoch 10, Batch 342 -Loss:   257.9020 Validation Accuracy: 0.820312\n","Epoch 10, Batch 343 -Loss:   218.7067 Validation Accuracy: 0.820312\n","Epoch 10, Batch 344 -Loss:   201.1919 Validation Accuracy: 0.820312\n","Epoch 10, Batch 345 -Loss:   229.0916 Validation Accuracy: 0.820312\n","Epoch 10, Batch 346 -Loss:   230.2265 Validation Accuracy: 0.820312\n","Epoch 10, Batch 347 -Loss:   285.6998 Validation Accuracy: 0.820312\n","Epoch 10, Batch 348 -Loss:   319.5151 Validation Accuracy: 0.820312\n","Epoch 10, Batch 349 -Loss:   165.4986 Validation Accuracy: 0.816406\n","Epoch 10, Batch 350 -Loss:   164.5208 Validation Accuracy: 0.816406\n","Epoch 10, Batch 351 -Loss:   145.7174 Validation Accuracy: 0.816406\n","Epoch 10, Batch 352 -Loss:   179.6868 Validation Accuracy: 0.816406\n","Epoch 10, Batch 353 -Loss:   202.3547 Validation Accuracy: 0.816406\n","Epoch 10, Batch 354 -Loss:   244.3943 Validation Accuracy: 0.816406\n","Epoch 10, Batch 355 -Loss:   320.2098 Validation Accuracy: 0.816406\n","Epoch 10, Batch 356 -Loss:   187.4330 Validation Accuracy: 0.816406\n","Epoch 10, Batch 357 -Loss:   222.3094 Validation Accuracy: 0.820312\n","Epoch 10, Batch 358 -Loss:   260.2650 Validation Accuracy: 0.820312\n","Epoch 10, Batch 359 -Loss:   270.3577 Validation Accuracy: 0.820312\n","Epoch 10, Batch 360 -Loss:   198.3950 Validation Accuracy: 0.820312\n","Epoch 10, Batch 361 -Loss:   250.1584 Validation Accuracy: 0.820312\n","Epoch 10, Batch 362 -Loss:   206.5789 Validation Accuracy: 0.820312\n","Epoch 10, Batch 363 -Loss:   343.0881 Validation Accuracy: 0.820312\n","Epoch 10, Batch 364 -Loss:   209.9941 Validation Accuracy: 0.820312\n","Epoch 10, Batch 365 -Loss:   187.1402 Validation Accuracy: 0.820312\n","Epoch 10, Batch 366 -Loss:   211.5354 Validation Accuracy: 0.820312\n","Epoch 10, Batch 367 -Loss:   160.5249 Validation Accuracy: 0.820312\n","Epoch 10, Batch 368 -Loss:   205.2065 Validation Accuracy: 0.820312\n","Epoch 10, Batch 369 -Loss:   352.1306 Validation Accuracy: 0.820312\n","Epoch 10, Batch 370 -Loss:   188.0510 Validation Accuracy: 0.816406\n","Epoch 10, Batch 371 -Loss:   203.7710 Validation Accuracy: 0.816406\n","Epoch 10, Batch 372 -Loss:   257.4426 Validation Accuracy: 0.816406\n","Epoch 10, Batch 373 -Loss:   284.7412 Validation Accuracy: 0.820312\n","Epoch 10, Batch 374 -Loss:   237.0715 Validation Accuracy: 0.816406\n","Epoch 10, Batch 375 -Loss:   172.4034 Validation Accuracy: 0.820312\n","Epoch 10, Batch 376 -Loss:   217.8265 Validation Accuracy: 0.816406\n","Epoch 10, Batch 377 -Loss:   140.4753 Validation Accuracy: 0.816406\n","Epoch 10, Batch 378 -Loss:   275.9127 Validation Accuracy: 0.816406\n","Epoch 10, Batch 379 -Loss:   391.9963 Validation Accuracy: 0.816406\n","Epoch 10, Batch 380 -Loss:   168.8877 Validation Accuracy: 0.816406\n","Epoch 10, Batch 381 -Loss:   139.4541 Validation Accuracy: 0.816406\n","Epoch 10, Batch 382 -Loss:   182.5656 Validation Accuracy: 0.820312\n","Epoch 10, Batch 383 -Loss:   219.8013 Validation Accuracy: 0.816406\n","Epoch 10, Batch 384 -Loss:   162.8884 Validation Accuracy: 0.816406\n","Epoch 10, Batch 385 -Loss:   214.9382 Validation Accuracy: 0.816406\n","Epoch 10, Batch 386 -Loss:   255.2030 Validation Accuracy: 0.812500\n","Epoch 10, Batch 387 -Loss:   228.7877 Validation Accuracy: 0.816406\n","Epoch 10, Batch 388 -Loss:   220.1774 Validation Accuracy: 0.816406\n","Epoch 10, Batch 389 -Loss:   393.4195 Validation Accuracy: 0.816406\n","Epoch 10, Batch 390 -Loss:   253.8516 Validation Accuracy: 0.820312\n","Epoch 10, Batch 391 -Loss:   205.0887 Validation Accuracy: 0.820312\n","Epoch 10, Batch 392 -Loss:   211.6819 Validation Accuracy: 0.816406\n","Epoch 10, Batch 393 -Loss:   166.4684 Validation Accuracy: 0.812500\n","Epoch 10, Batch 394 -Loss:   284.2484 Validation Accuracy: 0.816406\n","Epoch 10, Batch 395 -Loss:   262.8151 Validation Accuracy: 0.812500\n","Epoch 10, Batch 396 -Loss:   136.2912 Validation Accuracy: 0.812500\n","Epoch 10, Batch 397 -Loss:   219.5385 Validation Accuracy: 0.812500\n","Epoch 10, Batch 398 -Loss:   158.1221 Validation Accuracy: 0.812500\n","Epoch 10, Batch 399 -Loss:   170.6715 Validation Accuracy: 0.812500\n","Epoch 10, Batch 400 -Loss:   213.3221 Validation Accuracy: 0.812500\n","Epoch 10, Batch 401 -Loss:   156.0828 Validation Accuracy: 0.820312\n","Epoch 10, Batch 402 -Loss:   146.5028 Validation Accuracy: 0.808594\n","Epoch 10, Batch 403 -Loss:   197.9906 Validation Accuracy: 0.812500\n","Epoch 10, Batch 404 -Loss:   215.8273 Validation Accuracy: 0.816406\n","Epoch 10, Batch 405 -Loss:   156.7296 Validation Accuracy: 0.812500\n","Epoch 10, Batch 406 -Loss:   366.0844 Validation Accuracy: 0.820312\n","Epoch 10, Batch 407 -Loss:   267.3533 Validation Accuracy: 0.816406\n","Epoch 10, Batch 408 -Loss:   250.8277 Validation Accuracy: 0.816406\n","Epoch 10, Batch 409 -Loss:   255.4550 Validation Accuracy: 0.820312\n","Epoch 10, Batch 410 -Loss:   150.3601 Validation Accuracy: 0.820312\n","Epoch 10, Batch 411 -Loss:   228.2813 Validation Accuracy: 0.820312\n","Epoch 10, Batch 412 -Loss:   312.3259 Validation Accuracy: 0.816406\n","Epoch 10, Batch 413 -Loss:   258.3522 Validation Accuracy: 0.816406\n","Epoch 10, Batch 414 -Loss:   185.4146 Validation Accuracy: 0.812500\n","Epoch 10, Batch 415 -Loss:   272.8280 Validation Accuracy: 0.816406\n","Epoch 10, Batch 416 -Loss:   384.2652 Validation Accuracy: 0.816406\n","Epoch 10, Batch 417 -Loss:   226.5157 Validation Accuracy: 0.816406\n","Epoch 10, Batch 418 -Loss:   235.2767 Validation Accuracy: 0.820312\n","Epoch 10, Batch 419 -Loss:   302.5580 Validation Accuracy: 0.816406\n","Epoch 10, Batch 420 -Loss:   115.5034 Validation Accuracy: 0.820312\n","Epoch 10, Batch 421 -Loss:   201.4667 Validation Accuracy: 0.820312\n","Epoch 10, Batch 422 -Loss:   234.6543 Validation Accuracy: 0.820312\n","Epoch 10, Batch 423 -Loss:   263.4776 Validation Accuracy: 0.816406\n","Epoch 10, Batch 424 -Loss:   109.2669 Validation Accuracy: 0.820312\n","Epoch 10, Batch 425 -Loss:   142.9355 Validation Accuracy: 0.820312\n","Epoch 10, Batch 426 -Loss:   303.6199 Validation Accuracy: 0.820312\n","Epoch 10, Batch 427 -Loss:   180.5312 Validation Accuracy: 0.820312\n","Epoch 10, Batch 428 -Loss:   244.2197 Validation Accuracy: 0.820312\n","Epoch 10, Batch 429 -Loss:   226.1884 Validation Accuracy: 0.816406\n","Testing Accuracy: 0.84765625\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JBA7IQbU24lv","colab_type":"code","colab":{}},"source":["\"\"\"\n","Setup the strides, padding and filter weight/bias such that\n","the output shape is (1, 2, 2, 3).\n","\"\"\"\n","import tensorflow as tf\n","import numpy as np\n","\n","# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n","# (1, 4, 4, 1)\n","x = np.array([\n","    [0, 1, 0.5, 10],\n","    [2, 2.5, 1, -8],\n","    [4, 0, 5, 6],\n","    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n","X = tf.constant(x)\n","\n","\n","def conv2d(input):\n","    # Filter (weights and bias)\n","    # The shape of the filter weight is (height, width, input_depth, output_depth)\n","    # The shape of the filter bias is (output_depth,)\n","    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n","    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n","    F_W = tf.Variable(tf.truncated_normal((2, 2, 1, 3)))\n","    F_b = tf.Variable(tf.zeros(3))\n","    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n","    strides = [1, 2, 2, 1]\n","    # TODO: set the padding, either 'VALID' or 'SAME'.\n","    padding = 'VALID'\n","    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n","    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n","    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n","\n","out = conv2d(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gymLhXxO5FB1","colab_type":"code","outputId":"7543754a-3a5d-45b8-b1d6-c5c2131b450f","executionInfo":{"status":"ok","timestamp":1573935938249,"user_tz":-330,"elapsed":878,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["out.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([Dimension(1), Dimension(2), Dimension(2), Dimension(3)])"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"lHziUdnD5Hak","colab_type":"code","outputId":"1ba00bb3-633d-43ab-e06f-440edab134ee","executionInfo":{"status":"ok","timestamp":1573936068164,"user_tz":-330,"elapsed":973,"user":{"displayName":"Iyon Kingo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDhq98QqJiXINH7ESjFH7z3vH9Es7Mv5M40Rn71=s64","userId":"04777749448336901890"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\"\"\"\n","Set the values to `strides` and `ksize` such that\n","the output shape after pooling is (1, 2, 2, 1).\n","\"\"\"\n","import tensorflow as tf\n","import numpy as np\n","\n","# `tf.nn.max_pool` requires the input be 4D (batch_size, height, width, depth)\n","# (1, 4, 4, 1)\n","x = np.array([\n","    [0, 1, 0.5, 10],\n","    [2, 2.5, 1, -8],\n","    [4, 0, 5, 6],\n","    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n","X = tf.constant(x)\n","\n","def maxpool(input):\n","    # TODO: Set the ksize (filter size) for each dimension (batch_size, height, width, depth)\n","    ksize = [1, 2, 2, 1]\n","    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n","    strides = [1, 2, 2, 1]\n","    # TODO: set the padding, either 'VALID' or 'SAME'.\n","    padding = 'VALID'\n","    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#max_pool\n","    return tf.nn.max_pool(input, ksize, strides, padding)\n","    \n","out = maxpool(X)\n","out.get_shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Tensor.get_shape of <tf.Tensor 'MaxPool_2:0' shape=(1, 2, 2, 1) dtype=float32>>"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"t9QG983p5nFR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}